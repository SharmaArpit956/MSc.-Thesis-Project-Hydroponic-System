{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "for_different_models_tinyML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCZBFzjClURz"
      },
      "source": [
        "# Train the model for the 'Intelligent Hydroponic System' using TensorFlow Lite to be run on the microcontroller\n",
        " \n",
        "The training of the neural model happens in this notebook, after fetching the data from the Arduinoâ€™s serial monitor, the data-set is made by data collected from the serial monitor of the Arduino IDE by manually sliding the potentiometer to control the pump speed to achieve the desired pH value. The data set is stored in a CSV file which is used for training the neural Model.\n",
        "\n",
        "Deep learning networks learn to model patterns in underlying data. Here, we're going to train a network to model data generated by the pH sensor to control the speed of the pump. This will result in a model that can take a pH value, `x`, and predict its corresponding pump speed, `y`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Cz6uV1zU_hV"
      },
      "source": [
        "**Training is much faster using GPU acceleration.** Before you proceed, ensure you are using a GPU runtime by going to **Runtime -> Change runtime type** and set **Hardware accelerator: GPU**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UQblnrLd_ET"
      },
      "source": [
        "## Configure Defaults"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddOjdy0F-FfD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PYwRFppd-WB"
      },
      "source": [
        "# Define paths to model files\n",
        "import os\n",
        "MODELS_DIR = 'models/'\n",
        "\n",
        "if not os.path.isdir(MODELS_DIR):\n",
        "  os.mkdir(MODELS_DIR)\n",
        "MODEL_TF = MODELS_DIR + 'model.pb'\n",
        "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
        "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
        "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dh4AXGuHWeu1"
      },
      "source": [
        "## Setup Environment\n",
        "\n",
        "Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr1VLfotanf6"
      },
      "source": [
        "# ! pip install -q tensorflow==2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rLYpvtg9P4o"
      },
      "source": [
        "Set Seed for Repeatable Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIH9NN1c9PJn"
      },
      "source": [
        "# Set a \"seed\" value, so we get the same random numbers each time we run this\n",
        "# notebook for reproducible results.\n",
        "# Numpy is a math library\n",
        "import numpy as np\n",
        "np.random.seed(1) # numpy seed\n",
        "# TensorFlow is an open source machine learning library\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(1) # tensorflow global random seed"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tx9lOPWh9grN"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53PBJBv1jEtJ"
      },
      "source": [
        "# Keras is TensorFlow's high-level API for deep learning\n",
        "from tensorflow import keras\n",
        "# Matplotlib is a graphing library\n",
        "import matplotlib.pyplot as plt\n",
        "# Math is Python's math library\n",
        "import math\n",
        "import csv"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4-DmQORzOLb"
      },
      "source": [
        "# Read the dataset file from the google drive\n",
        "\n",
        "After importing all the important libraries, the data is read from the dataset file using a custom method, read-file.  All the columns in the data set are stored in individual arrays.  Then, (X, Y) pairs are formed to prepare the data for training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_4nd3lOEcqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602ba33f-752f-4e7d-a71c-3bfa1f9ea516"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VL_BOt4BpM0"
      },
      "source": [
        "corpus_name = \"tinyML\"\n",
        "corpus = os.path.join(\"/content/drive/My Drive/Colab Notebooks/data\", corpus_name)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCSZx2q1Cozx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57cf81e1-5763-43ec-8e65-26335bd6c1b5"
      },
      "source": [
        "import csv\n",
        "csvfile = os.path.join(corpus, \"ph_dataset.csv\")\n",
        "feature_names = ['Time (in milliseconds)','Pump speed','Water level (in mm)','pH']\n",
        "# time_array=[]\n",
        "speed_array=[]\n",
        "# water_level_array=[]\n",
        "ph_array=[]\n",
        "rows_array=[]\n",
        "line_count = 0\n",
        "\n",
        "def read_file():\n",
        "  global line_count\n",
        "  with open(csvfile, 'r', encoding='iso-8859-1') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    \n",
        "    # rows_array.append(feature_names)\n",
        "    for row in csv_reader:\n",
        "          row_array=[]\n",
        "          # row is a type list \n",
        "          if line_count != 0:\n",
        "            for field in row:\n",
        "              row_array.append(field)\n",
        "            rows_array.append(row_array) \n",
        "          line_count += 1\n",
        "\n",
        "    # becuase first line a column names\n",
        "    line_count -= 1\n",
        "\n",
        "    print(f'Processed {line_count} lines.')\n",
        "    for row in rows_array:      \n",
        "      # time_array.append(float(row[0]))\n",
        "      speed_array.append(float(row[0]))\n",
        "      # water_level_array.append(float(row[2]))\n",
        "      ph_array.append(float(row[1]))\n",
        "\n",
        "read_file()\n",
        "\n",
        "# print(rows_array)\n",
        "# print(time_array)\n",
        "print(speed_array)\n",
        "# print(water_level_array)\n",
        "print(ph_array)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 1000 lines.\n",
            "[20.0, 20.4, 20.8, 21.2, 21.6, 22.0, 22.4, 22.8, 23.2, 23.6, 24.0, 24.4, 24.8, 25.2, 25.6, 26.0, 26.4, 26.8, 27.2, 27.6, 28.0, 28.4, 28.8, 29.2, 29.6, 30.0, 30.4, 30.8, 31.2, 31.6, 32.0, 32.4, 32.8, 33.2, 33.6, 34.0, 34.4, 34.8, 35.2, 35.6, 36.0, 36.4, 36.8, 37.2, 37.6, 38.0, 38.4, 38.8, 39.2, 39.6, 40.0, 40.4, 40.8, 41.2, 41.6, 42.0, 42.4, 42.8, 43.2, 43.6, 44.0, 44.4, 44.8, 45.2, 45.6, 46.0, 46.4, 46.8, 47.2, 47.6, 48.0, 48.4, 48.8, 49.2, 49.6, 50.0, 50.4, 50.8, 51.2, 51.6, 52.0, 52.4, 52.8, 53.2, 53.6, 54.0, 54.4, 54.8, 55.2, 55.6, 56.0, 56.4, 56.8, 57.2, 57.6, 58.0, 58.4, 58.8, 59.2, 59.6, 60.0, 60.4, 60.8, 61.2, 61.6, 62.0, 62.4, 62.8, 63.2, 63.6, 64.0, 64.4, 64.8, 65.2, 65.6, 66.0, 66.4, 66.8, 67.2, 67.6, 68.0, 68.4, 68.8, 69.2, 69.6, 70.0, 70.4, 70.8, 71.2, 71.6, 72.0, 72.4, 72.8, 73.2, 73.6, 74.0, 74.4, 74.8, 75.2, 75.6, 76.0, 76.4, 76.8, 77.2, 77.6, 78.0, 78.4, 78.8, 79.2, 79.6, 80.0, 80.4, 80.8, 81.2, 81.6, 82.0, 82.4, 82.8, 83.2, 83.6, 84.0, 84.4, 84.8, 85.2, 85.6, 86.0, 86.4, 86.8, 87.2, 87.6, 88.0, 88.4, 88.8, 89.2, 89.6, 90.0, 90.4, 90.8, 91.2, 91.6, 92.0, 92.4, 92.8, 93.2, 93.6, 94.0, 94.4, 94.8, 95.2, 95.6, 96.0, 96.4, 96.8, 97.2, 97.6, 98.0, 98.4, 98.8, 99.2, 99.6, 100.0, 99.7, 99.4, 99.1, 98.8, 98.5, 98.2, 97.9, 97.6, 97.3, 97.0, 96.7, 96.4, 96.1, 95.8, 95.5, 95.2, 94.9, 94.6, 94.3, 94.0, 93.7, 93.4, 93.1, 92.8, 92.5, 92.2, 91.9, 91.6, 91.3, 91.0, 90.7, 90.4, 90.1, 89.8, 89.5, 89.2, 88.9, 88.6, 88.3, 88.0, 87.7, 87.4, 87.1, 86.8, 86.5, 86.2, 85.9, 85.6, 85.3, 85.0, 84.7, 84.4, 84.1, 83.8, 83.5, 83.2, 82.9, 82.6, 82.3, 82.0, 81.7, 81.4, 81.1, 80.8, 80.5, 80.2, 79.9, 79.6, 79.3, 79.0, 78.7, 78.4, 78.1, 77.8, 77.5, 77.2, 76.9, 76.6, 76.3, 76.0, 75.7, 75.4, 75.1, 74.8, 74.5, 74.2, 73.9, 73.6, 73.3, 73.0, 72.7, 72.4, 72.1, 71.8, 71.5, 71.2, 70.9, 70.6, 70.3, 70.0, 69.7, 69.4, 69.1, 68.8, 68.5, 68.2, 67.9, 67.6, 67.3, 67.0, 66.7, 66.4, 66.1, 65.8, 65.5, 65.2, 64.9, 64.6, 64.3, 64.0, 63.7, 63.4, 63.1, 62.8, 62.5, 62.2, 61.9, 61.6, 61.3, 61.0, 60.7, 60.4, 60.1, 59.8, 59.5, 59.2, 58.9, 58.6, 58.3, 58.0, 57.7, 57.4, 57.1, 56.8, 56.5, 56.2, 55.9, 55.6, 55.3, 55.0, 54.7, 54.4, 54.1, 53.8, 53.5, 53.2, 52.9, 52.6, 52.3, 52.0, 51.7, 51.4, 51.1, 50.8, 50.5, 50.2, 49.9, 49.6, 49.3, 49.0, 48.7, 48.4, 48.1, 47.8, 47.5, 47.2, 46.9, 46.6, 46.3, 46.0, 45.7, 45.4, 45.1, 44.8, 44.5, 44.2, 43.9, 43.6, 43.3, 43.0, 42.7, 42.4, 42.1, 41.8, 41.5, 41.2, 40.9, 40.6, 40.3, 40.0, 39.95, 39.9, 39.85, 39.8, 39.75, 39.7, 39.65, 39.6, 39.55, 39.5, 39.45, 39.4, 39.35, 39.3, 39.25, 39.2, 39.15, 39.1, 39.05, 39.0, 38.95, 38.9, 38.85, 38.8, 38.75, 38.7, 38.65, 38.6, 38.55, 38.5, 38.45, 38.4, 38.35, 38.3, 38.25, 38.2, 38.15, 38.1, 38.05, 38.0, 37.95, 37.9, 37.85, 37.8, 37.75, 37.7, 37.65, 37.6, 37.55, 37.5, 37.45, 37.4, 37.35, 37.3, 37.25, 37.2, 37.15, 37.1, 37.05, 37.0, 36.95, 36.9, 36.85, 36.8, 36.75, 36.7, 36.65, 36.6, 36.55, 36.5, 36.45, 36.4, 36.35, 36.3, 36.25, 36.2, 36.15, 36.1, 36.05, 36.0, 35.95, 35.9, 35.85, 35.8, 35.75, 35.7, 35.65, 35.6, 35.55, 35.5, 35.45, 35.4, 35.35, 35.3, 35.25, 35.2, 35.15, 35.1, 35.05, 35.0, 34.95, 34.9, 34.85, 34.8, 34.75, 34.7, 34.65, 34.6, 34.55, 34.5, 34.45, 34.4, 34.35, 34.3, 34.25, 34.2, 34.15, 34.1, 34.05, 34.0, 33.95, 33.9, 33.85, 33.8, 33.75, 33.7, 33.65, 33.6, 33.55, 33.5, 33.45, 33.4, 33.35, 33.3, 33.25, 33.2, 33.15, 33.1, 33.05, 33.0, 32.95, 32.9, 32.85, 32.8, 32.75, 32.7, 32.65, 32.6, 32.55, 32.5, 32.45, 32.4, 32.35, 32.3, 32.25, 32.2, 32.15, 32.1, 32.05, 32.0, 31.95, 31.9, 31.85, 31.8, 31.75, 31.7, 31.65, 31.6, 31.55, 31.5, 31.45, 31.4, 31.35, 31.3, 31.25, 31.2, 31.15, 31.1, 31.05, 31.0, 30.95, 30.9, 30.85, 30.8, 30.75, 30.7, 30.65, 30.6, 30.55, 30.5, 30.45, 30.4, 30.35, 30.3, 30.25, 30.2, 30.15, 30.1, 30.05, 30.0, 29.95, 29.9, 29.85, 29.8, 29.75, 29.7, 29.65, 29.6, 29.55, 29.5, 29.45, 29.4, 29.35, 29.3, 29.25, 29.2, 29.15, 29.1, 29.05, 29.0, 28.95, 28.9, 28.85, 28.8, 28.75, 28.7, 28.65, 28.6, 28.55, 28.5, 28.45, 28.4, 28.35, 28.3, 28.25, 28.2, 28.15, 28.1, 28.05, 28.0, 27.95, 27.9, 27.85, 27.8, 27.75, 27.7, 27.65, 27.6, 27.55, 27.5, 27.45, 27.4, 27.35, 27.3, 27.25, 27.2, 27.15, 27.1, 27.05, 27.0, 26.95, 26.9, 26.85, 26.8, 26.75, 26.7, 26.65, 26.6, 26.55, 26.5, 26.45, 26.4, 26.35, 26.3, 26.25, 26.2, 26.15, 26.1, 26.05, 26.0, 25.95, 25.9, 25.85, 25.8, 25.75, 25.7, 25.65, 25.6, 25.55, 25.5, 25.45, 25.4, 25.35, 25.3, 25.25, 25.2, 25.15, 25.1, 25.05, 25.0, 24.95, 24.9, 24.85, 24.8, 24.75, 24.7, 24.65, 24.6, 24.55, 24.5, 24.45, 24.4, 24.35, 24.3, 24.25, 24.2, 24.15, 24.1, 24.05, 24.0, 23.95, 23.9, 23.85, 23.8, 23.75, 23.7, 23.65, 23.6, 23.55, 23.5, 23.45, 23.4, 23.35, 23.3, 23.25, 23.2, 23.15, 23.1, 23.05, 23.0, 22.95, 22.9, 22.85, 22.8, 22.75, 22.7, 22.65, 22.6, 22.55, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.5, 22.05, 21.6, 21.15, 20.7, 20.25, 19.8, 19.35, 18.9, 18.45, 18.0, 17.55, 17.1, 16.65, 16.2, 15.75, 15.3, 14.85, 14.4, 13.95, 13.5, 13.05, 12.6, 12.15, 11.7, 11.25, 10.8, 10.35, 9.9, 9.45, 9.0, 8.55, 8.1, 7.65, 7.2, 6.75, 6.3, 5.85, 5.4, 4.95, 4.5, 4.05, 3.6, 3.15, 2.7, 2.25, 1.8, 1.35, 0.9, 0.45, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "[14.0, 13.99, 13.98, 13.97, 13.96, 13.95, 13.94, 13.93, 13.92, 13.91, 13.9, 13.89, 13.88, 13.87, 13.86, 13.85, 13.84, 13.83, 13.82, 13.81, 13.8, 13.79, 13.78, 13.77, 13.76, 13.75, 13.74, 13.73, 13.72, 13.71, 13.7, 13.69, 13.68, 13.67, 13.66, 13.65, 13.64, 13.63, 13.62, 13.61, 13.6, 13.59, 13.58, 13.57, 13.56, 13.55, 13.54, 13.53, 13.52, 13.51, 13.5, 13.49, 13.48, 13.47, 13.46, 13.45, 13.44, 13.43, 13.42, 13.41, 13.4, 13.39, 13.38, 13.37, 13.36, 13.35, 13.34, 13.33, 13.32, 13.31, 13.3, 13.29, 13.28, 13.27, 13.26, 13.25, 13.24, 13.23, 13.22, 13.21, 13.2, 13.19, 13.18, 13.17, 13.16, 13.15, 13.14, 13.13, 13.12, 13.11, 13.1, 13.09, 13.08, 13.07, 13.06, 13.05, 13.04, 13.03, 13.02, 13.01, 13.0, 12.99, 12.98, 12.97, 12.96, 12.95, 12.94, 12.93, 12.92, 12.91, 12.9, 12.89, 12.88, 12.87, 12.86, 12.85, 12.84, 12.83, 12.82, 12.81, 12.8, 12.79, 12.78, 12.77, 12.76, 12.75, 12.74, 12.73, 12.72, 12.71, 12.7, 12.69, 12.68, 12.67, 12.66, 12.65, 12.64, 12.63, 12.62, 12.61, 12.6, 12.59, 12.58, 12.57, 12.56, 12.55, 12.54, 12.53, 12.52, 12.51, 12.5, 12.49, 12.48, 12.47, 12.46, 12.45, 12.44, 12.43, 12.42, 12.41, 12.4, 12.39, 12.38, 12.37, 12.36, 12.35, 12.34, 12.33, 12.32, 12.31, 12.3, 12.29, 12.28, 12.27, 12.26, 12.25, 12.24, 12.23, 12.22, 12.21, 12.2, 12.19, 12.18, 12.17, 12.16, 12.15, 12.14, 12.13, 12.12, 12.11, 12.1, 12.09, 12.08, 12.07, 12.06, 12.05, 12.04, 12.03, 12.02, 12.01, 12.0, 11.99, 11.98, 11.97, 11.96, 11.95, 11.94, 11.93, 11.92, 11.91, 11.9, 11.89, 11.88, 11.87, 11.86, 11.85, 11.84, 11.83, 11.82, 11.81, 11.8, 11.79, 11.78, 11.77, 11.76, 11.75, 11.74, 11.73, 11.72, 11.71, 11.7, 11.69, 11.68, 11.67, 11.66, 11.65, 11.64, 11.63, 11.62, 11.61, 11.6, 11.59, 11.58, 11.57, 11.56, 11.55, 11.54, 11.53, 11.52, 11.51, 11.5, 11.49, 11.48, 11.47, 11.46, 11.45, 11.44, 11.43, 11.42, 11.41, 11.4, 11.39, 11.38, 11.37, 11.36, 11.35, 11.34, 11.33, 11.32, 11.31, 11.3, 11.29, 11.28, 11.27, 11.26, 11.25, 11.24, 11.23, 11.22, 11.21, 11.2, 11.19, 11.18, 11.17, 11.16, 11.15, 11.14, 11.13, 11.12, 11.11, 11.1, 11.09, 11.08, 11.07, 11.06, 11.05, 11.04, 11.03, 11.02, 11.01, 11.0, 10.99, 10.98, 10.97, 10.96, 10.95, 10.94, 10.93, 10.92, 10.91, 10.9, 10.89, 10.88, 10.87, 10.86, 10.85, 10.84, 10.83, 10.82, 10.81, 10.8, 10.79, 10.78, 10.77, 10.76, 10.75, 10.74, 10.73, 10.72, 10.71, 10.7, 10.69, 10.68, 10.67, 10.66, 10.65, 10.64, 10.63, 10.62, 10.61, 10.6, 10.59, 10.58, 10.57, 10.56, 10.55, 10.54, 10.53, 10.52, 10.51, 10.5, 10.49, 10.48, 10.47, 10.46, 10.45, 10.44, 10.43, 10.42, 10.41, 10.4, 10.39, 10.38, 10.37, 10.36, 10.35, 10.34, 10.33, 10.32, 10.31, 10.3, 10.29, 10.28, 10.27, 10.26, 10.25, 10.24, 10.23, 10.22, 10.21, 10.2, 10.19, 10.18, 10.17, 10.16, 10.15, 10.14, 10.13, 10.12, 10.11, 10.1, 10.09, 10.08, 10.07, 10.06, 10.05, 10.04, 10.03, 10.02, 10.01, 10.0, 9.99, 9.98, 9.97, 9.96, 9.95, 9.94, 9.93, 9.92, 9.91, 9.9, 9.89, 9.88, 9.87, 9.86, 9.85, 9.84, 9.83, 9.82, 9.81, 9.8, 9.79, 9.78, 9.77, 9.76, 9.75, 9.74, 9.73, 9.72, 9.71, 9.7, 9.69, 9.68, 9.67, 9.66, 9.65, 9.64, 9.63, 9.62, 9.61, 9.6, 9.59, 9.58, 9.57, 9.56, 9.55, 9.54, 9.53, 9.52, 9.51, 9.5, 9.49, 9.48, 9.47, 9.46, 9.45, 9.44, 9.43, 9.42, 9.41, 9.4, 9.39, 9.38, 9.37, 9.36, 9.35, 9.34, 9.33, 9.32, 9.31, 9.3, 9.29, 9.28, 9.27, 9.26, 9.25, 9.24, 9.23, 9.22, 9.21, 9.2, 9.19, 9.18, 9.17, 9.16, 9.15, 9.14, 9.13, 9.12, 9.11, 9.1, 9.09, 9.08, 9.07, 9.06, 9.05, 9.04, 9.03, 9.02, 9.01, 9.0, 8.99, 8.98, 8.97, 8.96, 8.95, 8.94, 8.93, 8.92, 8.91, 8.9, 8.89, 8.88, 8.87, 8.86, 8.85, 8.84, 8.83, 8.82, 8.81, 8.8, 8.79, 8.78, 8.77, 8.76, 8.75, 8.74, 8.73, 8.72, 8.71, 8.7, 8.69, 8.68, 8.67, 8.66, 8.65, 8.64, 8.63, 8.62, 8.61, 8.6, 8.59, 8.58, 8.57, 8.56, 8.55, 8.54, 8.53, 8.52, 8.51, 8.5, 8.49, 8.48, 8.47, 8.46, 8.45, 8.44, 8.43, 8.42, 8.41, 8.4, 8.39, 8.38, 8.37, 8.36, 8.35, 8.34, 8.33, 8.32, 8.31, 8.3, 8.29, 8.28, 8.27, 8.26, 8.25, 8.24, 8.23, 8.22, 8.21, 8.2, 8.19, 8.18, 8.17, 8.16, 8.15, 8.14, 8.13, 8.12, 8.11, 8.1, 8.09, 8.08, 8.07, 8.06, 8.05, 8.04, 8.03, 8.02, 8.01, 8.0, 7.99, 7.98, 7.97, 7.96, 7.95, 7.94, 7.93, 7.92, 7.91, 7.9, 7.89, 7.88, 7.87, 7.86, 7.85, 7.84, 7.83, 7.82, 7.81, 7.8, 7.79, 7.78, 7.77, 7.76, 7.75, 7.74, 7.73, 7.72, 7.71, 7.7, 7.69, 7.68, 7.67, 7.66, 7.65, 7.64, 7.63, 7.62, 7.61, 7.6, 7.59, 7.58, 7.57, 7.56, 7.55, 7.54, 7.53, 7.52, 7.51, 7.5, 7.49, 7.48, 7.47, 7.46, 7.45, 7.44, 7.43, 7.42, 7.41, 7.4, 7.39, 7.38, 7.37, 7.36, 7.35, 7.34, 7.33, 7.32, 7.31, 7.3, 7.29, 7.28, 7.27, 7.26, 7.25, 7.24, 7.23, 7.22, 7.21, 7.2, 7.19, 7.18, 7.17, 7.16, 7.15, 7.14, 7.13, 7.12, 7.11, 7.1, 7.09, 7.08, 7.07, 7.06, 7.05, 7.04, 7.03, 7.02, 7.01, 7.0, 6.99, 6.98, 6.97, 6.96, 6.95, 6.94, 6.93, 6.92, 6.91, 6.9, 6.89, 6.88, 6.87, 6.86, 6.85, 6.84, 6.83, 6.82, 6.81, 6.8, 6.79, 6.78, 6.77, 6.76, 6.75, 6.74, 6.73, 6.72, 6.71, 6.7, 6.69, 6.68, 6.67, 6.66, 6.65, 6.64, 6.63, 6.62, 6.61, 6.6, 6.59, 6.58, 6.57, 6.56, 6.55, 6.54, 6.53, 6.52, 6.51, 6.5, 6.49, 6.48, 6.47, 6.46, 6.45, 6.44, 6.43, 6.42, 6.41, 6.4, 6.39, 6.38, 6.37, 6.36, 6.35, 6.34, 6.33, 6.32, 6.31, 6.3, 6.29, 6.28, 6.27, 6.26, 6.25, 6.24, 6.23, 6.22, 6.21, 6.2, 6.19, 6.18, 6.17, 6.16, 6.15, 6.14, 6.13, 6.12, 6.11, 6.1, 6.09, 6.08, 6.07, 6.06, 6.05, 6.04, 6.03, 6.02, 6.01, 6.0, 5.99, 5.98, 5.97, 5.96, 5.95, 5.94, 5.93, 5.92, 5.91, 5.9, 5.89, 5.88, 5.87, 5.86, 5.85, 5.84, 5.83, 5.82, 5.81, 5.8, 5.79, 5.78, 5.77, 5.76, 5.75, 5.74, 5.73, 5.72, 5.71, 5.7, 5.69, 5.68, 5.67, 5.66, 5.65, 5.64, 5.63, 5.62, 5.61, 5.6, 5.59, 5.58, 5.57, 5.56, 5.55, 5.54, 5.53, 5.52, 5.51, 5.5, 5.49, 5.48, 5.47, 5.46, 5.45, 5.44, 5.43, 5.42, 5.41, 5.4, 5.39, 5.38, 5.37, 5.36, 5.35, 5.34, 5.33, 5.32, 5.31, 5.3, 5.29, 5.28, 5.27, 5.26, 5.25, 5.24, 5.23, 5.22, 5.21, 5.2, 5.19, 5.18, 5.17, 5.16, 5.15, 5.14, 5.13, 5.12, 5.11, 5.1, 5.09, 5.08, 5.07, 5.06, 5.05, 5.04, 5.03, 5.02, 5.01, 5.0, 4.99, 4.98, 4.97, 4.96, 4.95, 4.94, 4.93, 4.92, 4.91, 4.9, 4.89, 4.88, 4.87, 4.86, 4.85, 4.84, 4.83, 4.82, 4.81, 4.8, 4.79, 4.78, 4.77, 4.76, 4.75, 4.74, 4.73, 4.72, 4.71, 4.7, 4.69, 4.68, 4.67, 4.66, 4.65, 4.64, 4.63, 4.62, 4.61, 4.6, 4.59, 4.58, 4.57, 4.56, 4.55, 4.54, 4.53, 4.52, 4.51, 4.5, 4.49, 4.48, 4.47, 4.46, 4.45, 4.44, 4.43, 4.42, 4.41, 4.4, 4.39, 4.38, 4.37, 4.36, 4.35, 4.34, 4.33, 4.32, 4.31, 4.3, 4.29, 4.28, 4.27, 4.26, 4.25, 4.24, 4.23, 4.22, 4.21, 4.2, 4.19, 4.18, 4.17, 4.16, 4.15, 4.14, 4.13, 4.12, 4.11, 4.1, 4.09, 4.08, 4.07, 4.06, 4.05, 4.04, 4.03, 4.02, 4.01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-PuBEb6CMeo"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gB0-dlNmLT-"
      },
      "source": [
        "### 1. Generate Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKjg7QeMDsDx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1761858-9c5e-4f3e-f472-ae33780a26c1"
      },
      "source": [
        "# Number of sample data points\n",
        "SAMPLES = line_count\n",
        "\n",
        "# FOR pH MONITORING\n",
        "ph_array = np.array(ph_array, dtype=np.float32)\n",
        "speed_array = np.array(speed_array, dtype=np.float32)\n",
        "\n",
        "# Shuffle the values to guarantee they're not in order\n",
        "xy=[]\n",
        "for x, y in zip(ph_array, speed_array):\n",
        "  xy.append([x,y])\n",
        "np.random.shuffle(xy)\n",
        "\n",
        "x_values=[]\n",
        "y_values=[]\n",
        "for pair in xy:\n",
        "  x_values.append(pair[0])\n",
        "  y_values.append(pair[1])\n",
        "\n",
        "\n",
        "print(len(x_values))\n",
        "print(len(y_values))\n",
        "# print(x_values)\n",
        "print(xy)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n",
            "1000\n",
            "[[8.93, 34.65], [5.82, 18.9], [9.48, 37.4], [10.32, 49.6], [11.58, 87.4], [4.71, 0.0], [11.38, 81.4], [5.9, 22.5], [10.82, 64.6], [13.51, 39.6], [9.54, 37.7], [12.58, 76.8], [4.32, 0.0], [10.55, 56.5], [4.29, 0.0], [12.67, 73.2], [12.96, 61.6], [13.94, 22.4], [8.0, 30.0], [9.04, 35.2], [6.98, 24.9], [9.28, 36.4], [8.02, 30.1], [8.98, 34.9], [9.67, 38.35], [12.81, 67.6], [12.92, 63.2], [7.53, 27.65], [8.11, 30.55], [10.26, 47.8], [4.9, 0.0], [6.82, 24.1], [6.56, 22.8], [9.06, 35.3], [9.96, 39.8], [11.26, 77.8], [13.22, 51.2], [6.79, 23.95], [7.56, 27.8], [7.86, 29.3], [5.28, 0.0], [7.09, 25.45], [13.1, 56.0], [12.99, 60.4], [13.06, 57.6], [8.23, 31.15], [8.63, 33.15], [13.59, 36.4], [9.47, 37.35], [4.05, 0.0], [6.87, 24.35], [13.66, 33.6], [7.61, 28.05], [13.65, 34.0], [12.52, 79.2], [9.45, 37.25], [5.15, 0.0], [7.23, 26.15], [9.14, 35.7], [7.15, 25.75], [10.93, 67.9], [11.62, 88.6], [10.05, 41.5], [6.66, 23.3], [5.78, 17.1], [5.88, 21.6], [9.36, 36.8], [5.84, 19.8], [8.72, 33.6], [13.83, 26.8], [6.91, 24.55], [10.3, 49.0], [11.59, 87.7], [4.36, 0.0], [9.43, 37.15], [13.35, 46.0], [12.09, 96.4], [5.62, 9.9], [10.69, 60.7], [7.62, 28.1], [11.45, 83.5], [6.58, 22.9], [6.44, 22.5], [6.43, 22.5], [4.49, 0.0], [4.08, 0.0], [9.37, 36.85], [5.57, 7.65], [8.27, 31.35], [8.73, 33.65], [7.46, 27.3], [12.11, 95.6], [8.83, 34.15], [4.44, 0.0], [9.86, 39.3], [7.29, 26.45], [8.41, 32.05], [8.07, 30.35], [11.42, 82.6], [12.46, 81.6], [10.65, 59.5], [13.87, 25.2], [4.89, 0.0], [12.44, 82.4], [9.72, 38.6], [5.76, 16.2], [11.33, 79.9], [8.62, 33.1], [11.64, 89.2], [4.56, 0.0], [9.21, 36.05], [6.15, 22.5], [4.5, 0.0], [13.41, 43.6], [5.32, 0.0], [12.25, 90.0], [6.89, 24.45], [9.51, 37.55], [12.8, 68.0], [6.06, 22.5], [12.2, 92.0], [10.89, 66.7], [13.97, 21.2], [12.06, 97.6], [9.63, 38.15], [7.17, 25.85], [6.01, 22.5], [6.54, 22.7], [7.75, 28.75], [7.08, 25.4], [8.49, 32.45], [11.52, 85.6], [7.41, 27.05], [13.98, 20.8], [4.03, 0.0], [5.4, 0.0], [6.24, 22.5], [5.43, 1.35], [10.42, 52.6], [6.31, 22.5], [13.27, 49.2], [12.83, 66.8], [4.62, 0.0], [8.65, 33.25], [12.89, 64.4], [8.91, 34.55], [8.88, 34.4], [4.84, 0.0], [8.45, 32.25], [8.48, 32.4], [10.46, 53.8], [4.3, 0.0], [13.92, 23.2], [8.19, 30.95], [13.44, 42.4], [8.24, 31.2], [6.95, 24.75], [7.49, 27.45], [13.16, 53.6], [11.72, 91.6], [12.41, 83.6], [11.95, 98.5], [12.75, 70.0], [7.12, 25.6], [5.13, 0.0], [9.27, 36.35], [11.56, 86.8], [8.03, 30.15], [6.03, 22.5], [12.05, 98.0], [11.98, 99.4], [13.19, 52.4], [9.16, 35.8], [9.57, 37.85], [8.22, 31.1], [11.99, 99.7], [12.14, 94.4], [8.84, 34.2], [5.79, 17.55], [4.33, 0.0], [11.84, 95.2], [13.5, 40.0], [6.17, 22.5], [7.28, 26.4], [8.69, 33.45], [10.86, 65.8], [12.0, 100.0], [11.77, 93.1], [8.13, 30.65], [4.17, 0.0], [7.01, 25.05], [5.74, 15.3], [11.67, 90.1], [8.16, 30.8], [4.26, 0.0], [9.7, 38.5], [5.26, 0.0], [8.5, 32.5], [7.92, 29.6], [11.93, 97.9], [10.18, 45.4], [4.06, 0.0], [4.18, 0.0], [13.53, 38.8], [8.79, 33.95], [7.64, 28.2], [13.81, 27.6], [10.34, 50.2], [10.6, 58.0], [4.48, 0.0], [7.25, 26.25], [10.94, 68.2], [5.65, 11.25], [9.71, 38.55], [5.77, 16.65], [10.96, 68.8], [10.45, 53.5], [12.23, 90.8], [4.55, 0.0], [13.4, 44.0], [10.91, 67.3], [5.08, 0.0], [10.99, 69.7], [4.8, 0.0], [8.06, 30.3], [6.39, 22.5], [12.93, 62.8], [6.53, 22.65], [4.12, 0.0], [5.94, 22.5], [13.01, 59.6], [11.5, 85.0], [5.67, 12.15], [9.26, 36.3], [6.97, 24.85], [4.59, 0.0], [10.17, 45.1], [7.2, 26.0], [12.19, 92.4], [13.88, 24.8], [7.87, 29.35], [13.15, 54.0], [10.8, 64.0], [7.51, 27.55], [6.9, 24.5], [10.15, 44.5], [5.1, 0.0], [9.61, 38.05], [12.65, 74.0], [8.33, 31.65], [11.02, 70.6], [12.4, 84.0], [11.32, 79.6], [7.42, 27.1], [4.04, 0.0], [7.59, 27.95], [4.94, 0.0], [5.95, 22.5], [5.07, 0.0], [10.11, 43.3], [12.79, 68.4], [5.63, 10.35], [12.13, 94.8], [13.84, 26.4], [6.27, 22.5], [9.07, 35.35], [10.59, 57.7], [9.74, 38.7], [9.33, 36.65], [12.94, 62.4], [9.92, 39.6], [13.77, 29.2], [5.69, 13.05], [13.31, 47.6], [5.0, 0.0], [7.24, 26.2], [5.99, 22.5], [8.01, 30.05], [7.57, 27.85], [10.61, 58.3], [6.99, 24.95], [5.27, 0.0], [13.26, 49.6], [11.82, 94.6], [8.75, 33.75], [11.35, 80.5], [5.09, 0.0], [12.9, 64.0], [9.65, 38.25], [4.2, 0.0], [7.68, 28.4], [12.15, 94.0], [11.14, 74.2], [8.18, 30.9], [5.01, 0.0], [9.41, 37.05], [9.85, 39.25], [13.39, 44.4], [10.53, 55.9], [10.51, 55.3], [6.69, 23.45], [6.84, 24.2], [7.6, 28.0], [5.96, 22.5], [6.63, 23.15], [10.71, 61.3], [4.73, 0.0], [12.66, 73.6], [6.13, 22.5], [6.36, 22.5], [6.16, 22.5], [13.43, 42.8], [5.75, 15.75], [4.72, 0.0], [5.41, 0.45], [6.14, 22.5], [11.09, 72.7], [13.54, 38.4], [11.23, 76.9], [5.59, 8.55], [4.74, 0.0], [11.76, 92.8], [8.7, 33.5], [11.2, 76.0], [14.0, 20.0], [5.83, 19.35], [9.05, 35.25], [13.34, 46.4], [9.97, 39.85], [8.37, 31.85], [9.19, 35.95], [8.29, 31.45], [5.18, 0.0], [11.06, 71.8], [7.81, 29.05], [6.57, 22.85], [11.55, 86.5], [11.43, 82.9], [12.39, 84.4], [6.74, 23.7], [7.95, 29.75], [4.47, 0.0], [9.64, 38.2], [5.45, 2.25], [6.32, 22.5], [11.53, 85.9], [8.59, 32.95], [11.61, 88.3], [11.8, 94.0], [4.43, 0.0], [13.08, 56.8], [12.86, 65.6], [6.02, 22.5], [4.21, 0.0], [13.24, 50.4], [4.19, 0.0], [10.14, 44.2], [12.68, 72.8], [5.37, 0.0], [4.1, 0.0], [13.42, 43.2], [11.11, 73.3], [11.54, 86.2], [10.36, 50.8], [5.29, 0.0], [13.6, 36.0], [13.11, 55.6], [12.08, 96.8], [9.78, 38.9], [13.32, 47.2], [7.39, 26.95], [10.28, 48.4], [12.61, 75.6], [10.12, 43.6], [5.68, 12.6], [12.82, 67.2], [8.21, 31.05], [4.78, 0.0], [6.09, 22.5], [10.5, 55.0], [5.89, 22.05], [9.66, 38.3], [7.31, 26.55], [4.69, 0.0], [4.52, 0.0], [13.86, 25.6], [10.25, 47.5], [13.18, 52.8], [9.09, 35.45], [7.03, 25.15], [5.21, 0.0], [4.64, 0.0], [13.12, 55.2], [10.37, 51.1], [11.27, 78.1], [12.28, 88.8], [8.46, 32.3], [12.97, 61.2], [6.46, 22.5], [7.27, 26.35], [10.29, 48.7], [13.55, 38.0], [8.4, 32.0], [6.52, 22.6], [9.81, 39.05], [7.96, 29.8], [6.75, 23.75], [13.89, 24.4], [11.86, 95.8], [10.56, 56.8], [7.0, 25.0], [6.8, 24.0], [12.53, 78.8], [11.01, 70.3], [11.17, 75.1], [6.55, 22.75], [9.88, 39.4], [7.71, 28.55], [6.05, 22.5], [6.59, 22.95], [5.14, 0.0], [6.65, 23.25], [12.27, 89.2], [9.68, 38.4], [4.15, 0.0], [11.74, 92.2], [10.95, 68.5], [13.69, 32.4], [6.81, 24.05], [9.17, 35.85], [6.34, 22.5], [11.15, 74.5], [4.82, 0.0], [9.18, 35.9], [4.87, 0.0], [4.23, 0.0], [12.84, 66.4], [7.82, 29.1], [7.48, 27.4], [6.96, 24.8], [13.05, 58.0], [11.39, 81.7], [7.65, 28.25], [8.08, 30.4], [8.26, 31.3], [4.46, 0.0], [12.98, 60.8], [13.38, 44.8], [11.96, 98.8], [7.37, 26.85], [7.14, 25.7], [12.16, 93.6], [7.22, 26.1], [6.67, 23.35], [13.09, 56.4], [4.58, 0.0], [6.92, 24.6], [6.64, 23.2], [5.64, 10.8], [6.7, 23.5], [9.89, 39.45], [10.54, 56.2], [9.2, 36.0], [5.86, 20.7], [13.71, 31.6], [13.46, 41.6], [9.13, 35.65], [13.61, 35.6], [12.43, 82.8], [5.06, 0.0], [12.54, 78.4], [11.79, 93.7], [7.16, 25.8], [6.28, 22.5], [7.98, 29.9], [6.0, 22.5], [10.06, 41.8], [13.48, 40.8], [7.78, 28.9], [7.26, 26.3], [10.41, 52.3], [8.96, 34.8], [9.98, 39.9], [6.3, 22.5], [9.79, 38.95], [9.52, 37.6], [12.35, 86.0], [11.16, 74.8], [13.2, 52.0], [11.73, 91.9], [9.53, 37.65], [10.47, 54.1], [10.9, 67.0], [6.73, 23.65], [11.41, 82.3], [10.77, 63.1], [13.91, 23.6], [7.21, 26.05], [8.71, 33.55], [13.7, 32.0], [6.11, 22.5], [12.21, 91.6], [13.73, 30.8], [13.67, 33.2], [10.66, 59.8], [10.39, 51.7], [11.07, 72.1], [6.18, 22.5], [4.41, 0.0], [13.95, 22.0], [12.03, 98.8], [6.1, 22.5], [10.08, 42.4], [8.57, 32.85], [6.12, 22.5], [7.69, 28.45], [5.35, 0.0], [8.9, 34.5], [12.78, 68.8], [10.22, 46.6], [13.62, 35.2], [8.54, 32.7], [8.77, 33.85], [12.38, 84.8], [13.33, 46.8], [12.76, 69.6], [13.96, 21.6], [5.66, 11.7], [6.41, 22.5], [9.73, 38.65], [4.34, 0.0], [8.47, 32.35], [8.94, 34.7], [4.25, 0.0], [10.01, 40.3], [5.98, 22.5], [10.48, 54.4], [5.61, 9.45], [5.52, 5.4], [11.4, 82.0], [10.67, 60.1], [12.47, 81.2], [10.04, 41.2], [8.99, 34.95], [10.27, 48.1], [10.88, 66.4], [13.58, 36.8], [6.42, 22.5], [8.78, 33.9], [7.5, 27.5], [5.54, 6.3], [7.77, 28.85], [7.18, 25.9], [7.66, 28.3], [6.5, 22.5], [6.45, 22.5], [6.2, 22.5], [8.1, 30.5], [9.55, 37.75], [11.28, 78.4], [5.23, 0.0], [8.81, 34.05], [10.23, 46.9], [9.02, 35.1], [5.22, 0.0], [4.7, 0.0], [4.53, 0.0], [13.03, 58.8], [12.72, 71.2], [8.56, 32.8], [10.21, 46.3], [11.97, 99.1], [10.57, 57.1], [5.12, 0.0], [5.92, 22.5], [8.82, 34.1], [6.21, 22.5], [9.12, 35.6], [11.63, 88.9], [8.51, 32.55], [10.0, 40.0], [8.3, 31.5], [11.68, 90.4], [9.58, 37.9], [13.02, 59.2], [5.25, 0.0], [4.22, 0.0], [8.89, 34.45], [7.88, 29.4], [11.83, 94.9], [10.4, 52.0], [8.42, 32.1], [4.81, 0.0], [4.42, 0.0], [11.75, 92.5], [13.82, 27.2], [12.32, 87.2], [11.08, 72.4], [7.93, 29.65], [10.03, 40.9], [8.6, 33.0], [10.72, 61.6], [5.38, 0.0], [7.33, 26.65], [13.07, 57.2], [11.87, 96.1], [10.63, 58.9], [9.75, 38.75], [5.97, 22.5], [12.85, 66.0], [12.42, 83.2], [4.11, 0.0], [12.88, 64.8], [13.64, 34.4], [12.95, 62.0], [10.38, 51.4], [10.35, 50.5], [9.59, 37.95], [8.35, 31.75], [10.49, 54.7], [4.27, 0.0], [11.51, 85.3], [5.48, 3.6], [6.04, 22.5], [9.94, 39.7], [5.47, 3.15], [12.36, 85.6], [5.24, 0.0], [5.39, 0.0], [5.72, 14.4], [13.17, 53.2], [7.02, 25.1], [11.05, 71.5], [13.3, 48.0], [7.9, 29.5], [7.36, 26.8], [4.77, 0.0], [4.37, 0.0], [4.98, 0.0], [6.76, 23.8], [12.73, 70.8], [5.6, 9.0], [13.99, 20.4], [5.03, 0.0], [8.61, 33.05], [7.99, 29.95], [10.92, 67.6], [8.15, 30.75], [9.9, 39.5], [12.29, 88.4], [9.83, 39.15], [6.37, 22.5], [4.65, 0.0], [7.97, 29.85], [9.4, 37.0], [5.34, 0.0], [7.63, 28.15], [9.77, 38.85], [10.85, 65.5], [10.24, 47.2], [8.76, 33.8], [5.33, 0.0], [9.62, 38.1], [6.61, 23.05], [12.5, 80.0], [4.01, 0.0], [8.44, 32.2], [5.81, 18.45], [5.93, 22.5], [9.91, 39.55], [12.57, 77.2], [8.74, 33.7], [5.42, 0.9], [4.14, 0.0], [5.73, 14.85], [11.92, 97.6], [9.6, 38.0], [12.69, 72.4], [10.2, 46.0], [12.26, 89.6], [8.67, 33.35], [11.3, 79.0], [9.93, 39.65], [5.31, 0.0], [12.77, 69.2], [12.62, 75.2], [13.49, 40.4], [7.76, 28.8], [11.25, 77.5], [4.35, 0.0], [10.58, 57.4], [11.44, 83.2], [12.18, 92.8], [7.83, 29.15], [11.0, 70.0], [7.1, 25.5], [6.35, 22.5], [11.6, 88.0], [11.7, 91.0], [4.85, 0.0], [10.74, 62.2], [9.42, 37.1], [7.19, 25.95], [7.38, 26.9], [6.38, 22.5], [9.35, 36.75], [12.37, 85.2], [12.33, 86.8], [12.55, 78.0], [11.94, 98.2], [9.0, 35.0], [12.12, 95.2], [10.76, 62.8], [7.43, 27.15], [6.6, 23.0], [5.7, 13.5], [5.5, 4.5], [4.09, 0.0], [5.05, 0.0], [8.25, 31.25], [13.21, 51.6], [5.91, 22.5], [7.13, 25.65], [4.61, 0.0], [5.56, 7.2], [11.71, 91.3], [6.77, 23.85], [4.88, 0.0], [13.0, 60.0], [11.1, 73.0], [9.56, 37.8], [4.54, 0.0], [13.47, 41.2], [10.09, 42.7], [4.38, 0.0], [4.02, 0.0], [7.34, 26.7], [11.49, 84.7], [9.01, 35.05], [9.25, 36.25], [7.3, 26.5], [11.29, 78.7], [13.56, 37.6], [12.87, 65.2], [13.76, 29.6], [11.89, 96.7], [7.8, 29.0], [12.31, 87.6], [8.09, 30.45], [4.31, 0.0], [8.04, 30.2], [8.8, 34.0], [13.68, 32.8], [7.89, 29.45], [12.91, 63.6], [12.64, 74.4], [10.7, 61.0], [11.78, 93.4], [13.72, 31.2], [11.13, 73.9], [6.78, 23.9], [13.45, 42.0], [4.13, 0.0], [5.19, 0.0], [4.99, 0.0], [13.52, 39.2], [4.96, 0.0], [4.24, 0.0], [7.58, 27.9], [8.55, 32.75], [9.23, 36.15], [8.53, 32.65], [13.37, 45.2], [9.87, 39.35], [10.16, 44.8], [5.11, 0.0], [10.78, 63.4], [9.49, 37.45], [6.19, 22.5], [11.66, 89.8], [7.44, 27.2], [8.43, 32.15], [9.38, 36.9], [9.76, 38.8], [5.2, 0.0], [10.97, 69.1], [5.16, 0.0], [7.11, 25.55], [11.81, 94.3], [5.3, 0.0], [11.04, 71.2], [13.79, 28.4], [6.4, 22.5], [9.8, 39.0], [10.75, 62.5], [12.01, 99.6], [9.5, 37.5], [12.63, 74.8], [8.64, 33.2], [7.04, 25.2], [6.83, 24.15], [7.54, 27.7], [7.72, 28.6], [11.88, 96.4], [4.39, 0.0], [4.66, 0.0], [4.79, 0.0], [8.95, 34.75], [5.85, 20.25], [11.69, 90.7], [9.95, 39.75], [6.71, 23.55], [8.32, 31.6], [10.83, 64.9], [12.17, 93.2], [5.44, 1.8], [5.46, 2.7], [7.07, 25.35], [7.91, 29.55], [7.74, 28.7], [9.15, 35.75], [11.22, 76.6], [7.7, 28.5], [13.8, 28.0], [12.3, 88.0], [9.99, 39.95], [4.76, 0.0], [8.34, 31.7], [12.24, 90.4], [10.73, 61.9], [6.94, 24.7], [12.02, 99.2], [9.3, 36.5], [5.58, 8.1], [7.06, 25.3], [11.34, 80.2], [7.85, 29.25], [6.68, 23.4], [9.08, 35.4], [12.7, 72.0], [10.62, 58.6], [5.49, 4.05], [9.11, 35.55], [8.28, 31.4], [7.94, 29.7], [12.07, 97.2], [12.6, 76.0], [9.84, 39.2], [7.4, 27.0], [9.24, 36.2], [6.86, 24.3], [12.48, 80.8], [5.51, 4.95], [5.02, 0.0], [13.9, 24.0], [11.31, 79.3], [13.04, 58.4], [11.9, 97.0], [4.16, 0.0], [6.48, 22.5], [8.31, 31.55], [5.87, 21.15], [6.25, 22.5], [8.52, 32.6], [4.57, 0.0], [8.68, 33.4], [4.67, 0.0], [10.68, 60.4], [13.25, 50.0], [6.88, 24.4], [13.23, 50.8], [11.37, 81.1], [4.07, 0.0], [12.51, 79.6], [4.68, 0.0], [8.86, 34.3], [4.6, 0.0], [9.31, 36.55], [8.36, 31.8], [6.26, 22.5], [9.39, 36.95], [11.47, 84.1], [6.29, 22.5], [5.55, 6.75], [10.31, 49.3], [10.79, 63.7], [7.05, 25.25], [12.49, 80.4], [4.51, 0.0], [10.98, 69.4], [12.1, 96.0], [8.14, 30.7], [10.52, 55.6], [11.57, 87.1], [6.07, 22.5], [13.13, 54.8], [6.49, 22.5], [7.45, 27.25], [4.91, 0.0], [6.22, 22.5], [9.82, 39.1], [11.12, 73.6], [7.52, 27.6], [12.34, 86.4], [8.05, 30.25], [4.63, 0.0], [12.45, 82.0], [10.44, 53.2], [10.19, 45.7], [11.21, 76.3], [12.74, 70.4], [6.93, 24.65], [6.23, 22.5], [13.78, 28.8], [7.84, 29.2], [7.35, 26.75], [11.18, 75.4], [4.97, 0.0], [9.29, 36.45], [6.62, 23.1], [10.33, 49.9], [13.75, 30.0], [12.04, 98.4], [13.36, 45.6], [13.85, 26.0], [9.34, 36.7], [11.03, 70.9], [5.17, 0.0], [7.79, 28.95], [10.64, 59.2], [5.8, 18.0], [13.74, 30.4], [8.12, 30.6], [13.57, 37.2], [9.03, 35.15], [6.08, 22.5], [8.85, 34.25], [4.45, 0.0], [8.39, 31.95], [4.83, 0.0], [9.46, 37.3], [10.13, 43.9], [13.29, 48.4], [8.58, 32.9], [9.44, 37.2], [7.67, 28.35], [9.69, 38.45], [7.73, 28.65], [7.47, 27.35], [6.72, 23.6], [11.36, 80.8], [11.91, 97.3], [10.84, 65.2], [5.04, 0.0], [8.87, 34.35], [10.87, 66.1], [8.66, 33.3], [5.71, 13.95], [10.81, 64.3], [13.93, 22.8], [10.07, 42.1], [12.59, 76.4], [13.14, 54.4], [5.36, 0.0], [9.22, 36.1], [8.97, 34.85], [6.47, 22.5], [11.85, 95.5], [8.2, 31.0], [8.38, 31.9], [10.02, 40.6], [4.75, 0.0], [7.32, 26.6], [9.1, 35.5], [11.48, 84.4], [4.93, 0.0], [9.32, 36.6], [4.86, 0.0], [10.43, 52.9], [11.46, 83.8], [11.24, 77.2], [12.22, 91.2], [11.19, 75.7], [10.1, 43.0], [8.92, 34.6], [6.51, 22.55], [8.17, 30.85], [4.28, 0.0], [12.71, 71.6], [12.56, 77.6], [4.4, 0.0], [5.53, 5.85], [7.55, 27.75], [6.85, 24.25], [4.95, 0.0], [6.33, 22.5], [13.28, 48.8], [4.92, 0.0], [11.65, 89.5], [13.63, 34.8]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHwJTuwcVh5S"
      },
      "source": [
        "#Plot\n",
        "\n",
        "The data is plotted to visualize its nature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "JtIWKTbXVfez",
        "outputId": "b1f7e269-cc60-418a-f196-49d5620795be"
      },
      "source": [
        "# Plot our data. The 'b.' argument tells the library to print blue dots.\n",
        "plt.plot(x_values, y_values, 'b.')\n",
        "plt.xlabel('pH value')\n",
        "plt.ylabel('Pump speed')\n",
        "plt.xlim(max(x_values), min(x_values))\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Up8Xk_pMH4Rt"
      },
      "source": [
        "### 3. Split the Data\n",
        "\n",
        "To evaluate the accuracy of the model we train, we'll need to compare its predictions to real data and check how well they match up. This evaluation happens during training (where it is referred to as validation) and after training (referred to as testing) It's important in both cases that we use fresh data that was not already used to train the model.\n",
        "\n",
        "The data is split as follows:\n",
        "  1. Training: 60%\n",
        "  2. Validation: 20%\n",
        "  3. Testing: 20% \n",
        "\n",
        "It is made sure that the total number of samples is equal to their sum, to be on a safer side.  All the sections of the datasets are individually plotted on the same graph to ensure the random assignment of data to each category. \n",
        "\n",
        "The following code will split our data and then plots each set as a different color:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNYko5L1keqZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "853e5a6e-19be-443a-e3f7-2e2c34372712"
      },
      "source": [
        "# We'll use 60% of our data for training and 20% for testing. The remaining 20%\n",
        "# will be used for validation. Calculate the indices of each section.\n",
        "TRAIN_SPLIT =  int(0.6 * SAMPLES)\n",
        "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
        "\n",
        "# Use np.split to chop our data into three parts.\n",
        "# The second argument to np.split is an array of indices where the data will be\n",
        "# split. We provide two indices, so the data will be divided into three chunks.\n",
        "x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
        "\n",
        "# Double check that our splits add up correctly\n",
        "assert (x_train.size + x_validate.size + x_test.size) ==  SAMPLES\n",
        "\n",
        "# Plot the data in each partition in different colors:\n",
        "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
        "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
        "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
        "plt.xlabel('pH value')\n",
        "plt.ylabel('Pump speed')\n",
        "plt.xlim(max(x_values), min(x_values))\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7sL-hWtoAZC"
      },
      "source": [
        "## Training a Larger Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQd0JSdOoAbw"
      },
      "source": [
        "### 1. Design the Model\n",
        "To make our model bigger, let's add an additional layer of neurons. The following cell redefines our model in the same way as earlier, but with 16 neurons in the first layer and an additional layer of 16 neurons in the middle:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW0xus6AF-4o"
      },
      "source": [
        "model_2 = tf.keras.Sequential()\n",
        "\n",
        "# First layer takes a scalar input and feeds it through 16 \"neurons\". The\n",
        "# neurons decide whether to activate based on the 'relu' activation function.\n",
        "\n",
        "# model_2.add(keras.layers.Dense(8, activation='relu', input_shape=(1,)))\n",
        "model_2.add(keras.layers.Dense(32, activation='relu', input_shape=(1,)))\n",
        "model_2.add(keras.layers.Dense(64, activation='relu', input_shape=(1,)))\n",
        "model_2.add(keras.layers.Dense(32, activation='relu', input_shape=(1,)))\n",
        "\n",
        "\n",
        "# Final layer is a single neuron, since we want to output a single value\n",
        "model_2.add(keras.layers.Dense(1))\n",
        "\n",
        "# Compile the model using a standard optimizer and loss function for regression\n",
        "model_2.compile(optimizer='adam', loss='mse', metrics=['mae'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv2SC409Grap"
      },
      "source": [
        "### 2. Train the Model ###\n",
        "\n",
        "We'll now train the new model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPAUrdkmGq1M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7efb64ea-c628-4514-887c-7ff19bd2e27b"
      },
      "source": [
        "history_2 = model_2.fit(x_train, y_train, epochs=1650, batch_size=64,\n",
        "                    validation_data=(x_validate, y_validate))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1650\n",
            "10/10 [==============================] - 1s 24ms/step - loss: 2265.6636 - mae: 39.2815 - val_loss: 2270.8630 - val_mae: 38.8244\n",
            "Epoch 2/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2149.0891 - mae: 38.1050 - val_loss: 2165.8457 - val_mae: 37.8293\n",
            "Epoch 3/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2044.7069 - mae: 37.0662 - val_loss: 2059.7798 - val_mae: 36.7944\n",
            "Epoch 4/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1936.3213 - mae: 35.9910 - val_loss: 1941.4419 - val_mae: 35.6076\n",
            "Epoch 5/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1804.7264 - mae: 34.6361 - val_loss: 1788.8428 - val_mae: 34.0218\n",
            "Epoch 6/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 1632.7661 - mae: 32.7050 - val_loss: 1582.6176 - val_mae: 31.7583\n",
            "Epoch 7/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1406.0421 - mae: 29.9653 - val_loss: 1317.9155 - val_mae: 28.6049\n",
            "Epoch 8/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1125.1681 - mae: 26.1964 - val_loss: 1006.4612 - val_mae: 24.4049\n",
            "Epoch 9/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 818.3134 - mae: 21.5774 - val_loss: 696.8603 - val_mae: 19.5769\n",
            "Epoch 10/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 544.6307 - mae: 16.4969 - val_loss: 468.3377 - val_mae: 14.7602\n",
            "Epoch 11/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 387.3899 - mae: 13.8372 - val_loss: 375.5319 - val_mae: 15.2181\n",
            "Epoch 12/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 353.7779 - mae: 15.1091 - val_loss: 368.8706 - val_mae: 16.2622\n",
            "Epoch 13/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 361.0020 - mae: 15.7679 - val_loss: 368.6530 - val_mae: 16.2799\n",
            "Epoch 14/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 356.4619 - mae: 15.4236 - val_loss: 367.4543 - val_mae: 15.7020\n",
            "Epoch 15/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 352.2019 - mae: 14.8520 - val_loss: 369.6716 - val_mae: 15.4021\n",
            "Epoch 16/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 352.1644 - mae: 14.6747 - val_loss: 369.8927 - val_mae: 15.3402\n",
            "Epoch 17/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 352.2158 - mae: 14.6965 - val_loss: 367.5073 - val_mae: 15.4691\n",
            "Epoch 18/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 351.2240 - mae: 14.8367 - val_loss: 366.2198 - val_mae: 15.5352\n",
            "Epoch 19/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 350.7125 - mae: 14.8576 - val_loss: 365.8421 - val_mae: 15.5038\n",
            "Epoch 20/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 350.4989 - mae: 14.7683 - val_loss: 365.9496 - val_mae: 15.4228\n",
            "Epoch 21/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 350.1702 - mae: 14.6938 - val_loss: 366.1187 - val_mae: 15.3444\n",
            "Epoch 22/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 349.3961 - mae: 14.7761 - val_loss: 363.2559 - val_mae: 15.5784\n",
            "Epoch 23/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 349.0977 - mae: 14.8682 - val_loss: 363.1509 - val_mae: 15.4970\n",
            "Epoch 24/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 348.4574 - mae: 14.7984 - val_loss: 362.8865 - val_mae: 15.4414\n",
            "Epoch 25/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 347.9251 - mae: 14.7615 - val_loss: 362.4139 - val_mae: 15.4098\n",
            "Epoch 26/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 347.4421 - mae: 14.6998 - val_loss: 362.2296 - val_mae: 15.3489\n",
            "Epoch 27/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 347.3086 - mae: 14.5966 - val_loss: 363.1632 - val_mae: 15.2054\n",
            "Epoch 28/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 346.6841 - mae: 14.5454 - val_loss: 361.3674 - val_mae: 15.2870\n",
            "Epoch 29/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 346.2455 - mae: 14.6736 - val_loss: 359.7506 - val_mae: 15.3734\n",
            "Epoch 30/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 345.4360 - mae: 14.6635 - val_loss: 359.9940 - val_mae: 15.2639\n",
            "Epoch 31/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 345.2381 - mae: 14.5453 - val_loss: 359.7845 - val_mae: 15.2086\n",
            "Epoch 32/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 344.5211 - mae: 14.5194 - val_loss: 359.3310 - val_mae: 15.1764\n",
            "Epoch 33/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 343.9196 - mae: 14.5040 - val_loss: 358.2832 - val_mae: 15.1950\n",
            "Epoch 34/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 345.5657 - mae: 14.7040 - val_loss: 356.1837 - val_mae: 15.3336\n",
            "Epoch 35/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 342.3789 - mae: 14.4912 - val_loss: 359.2982 - val_mae: 14.9896\n",
            "Epoch 36/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 343.7293 - mae: 14.2311 - val_loss: 359.1131 - val_mae: 14.9439\n",
            "Epoch 37/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 342.6243 - mae: 14.4417 - val_loss: 354.4968 - val_mae: 15.2383\n",
            "Epoch 38/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 342.4646 - mae: 14.6942 - val_loss: 353.0291 - val_mae: 15.3381\n",
            "Epoch 39/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 340.9835 - mae: 14.6229 - val_loss: 353.4806 - val_mae: 15.1585\n",
            "Epoch 40/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 340.4082 - mae: 14.4348 - val_loss: 353.2892 - val_mae: 15.0838\n",
            "Epoch 41/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 339.5868 - mae: 14.3853 - val_loss: 353.0103 - val_mae: 15.0265\n",
            "Epoch 42/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 339.5968 - mae: 14.4593 - val_loss: 351.3793 - val_mae: 15.0899\n",
            "Epoch 43/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 338.3845 - mae: 14.4052 - val_loss: 351.5115 - val_mae: 14.9858\n",
            "Epoch 44/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 338.1240 - mae: 14.2646 - val_loss: 351.7779 - val_mae: 14.8885\n",
            "Epoch 45/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 337.5753 - mae: 14.1666 - val_loss: 351.7801 - val_mae: 14.8195\n",
            "Epoch 46/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 337.2305 - mae: 14.2952 - val_loss: 348.2587 - val_mae: 15.0325\n",
            "Epoch 47/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 336.5266 - mae: 14.4324 - val_loss: 347.5741 - val_mae: 15.0035\n",
            "Epoch 48/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 335.7720 - mae: 14.3052 - val_loss: 347.6570 - val_mae: 14.8956\n",
            "Epoch 49/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 334.9141 - mae: 14.1478 - val_loss: 349.1609 - val_mae: 14.7074\n",
            "Epoch 50/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 335.9388 - mae: 14.2057 - val_loss: 345.8171 - val_mae: 14.8811\n",
            "Epoch 51/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 334.1096 - mae: 14.1309 - val_loss: 346.2155 - val_mae: 14.7611\n",
            "Epoch 52/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 333.9253 - mae: 14.1190 - val_loss: 345.2514 - val_mae: 14.7510\n",
            "Epoch 53/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 333.9673 - mae: 13.9852 - val_loss: 345.8370 - val_mae: 14.6348\n",
            "Epoch 54/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 332.6273 - mae: 14.1490 - val_loss: 342.0909 - val_mae: 14.8614\n",
            "Epoch 55/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 331.5451 - mae: 14.1429 - val_loss: 342.6078 - val_mae: 14.7127\n",
            "Epoch 56/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 331.1112 - mae: 14.0227 - val_loss: 342.5153 - val_mae: 14.6327\n",
            "Epoch 57/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 329.8165 - mae: 14.0830 - val_loss: 339.4898 - val_mae: 14.8146\n",
            "Epoch 58/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 330.3299 - mae: 14.1961 - val_loss: 339.5174 - val_mae: 14.6961\n",
            "Epoch 59/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 330.0946 - mae: 14.2205 - val_loss: 337.7481 - val_mae: 14.7753\n",
            "Epoch 60/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 328.6710 - mae: 13.9567 - val_loss: 340.6721 - val_mae: 14.4310\n",
            "Epoch 61/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 327.7001 - mae: 13.8716 - val_loss: 336.8955 - val_mae: 14.6284\n",
            "Epoch 62/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 326.8723 - mae: 13.9956 - val_loss: 336.2468 - val_mae: 14.5798\n",
            "Epoch 63/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 326.5272 - mae: 13.9968 - val_loss: 335.6259 - val_mae: 14.5213\n",
            "Epoch 64/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 325.8212 - mae: 13.9483 - val_loss: 334.2270 - val_mae: 14.5378\n",
            "Epoch 65/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 325.0838 - mae: 13.8362 - val_loss: 335.0745 - val_mae: 14.3728\n",
            "Epoch 66/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 324.7249 - mae: 13.8362 - val_loss: 332.2624 - val_mae: 14.4991\n",
            "Epoch 67/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 323.5616 - mae: 13.9109 - val_loss: 332.0194 - val_mae: 14.4031\n",
            "Epoch 68/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 323.3135 - mae: 13.8014 - val_loss: 331.5081 - val_mae: 14.3453\n",
            "Epoch 69/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 322.3146 - mae: 13.6752 - val_loss: 332.8233 - val_mae: 14.1597\n",
            "Epoch 70/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 322.6966 - mae: 13.4606 - val_loss: 331.4174 - val_mae: 14.1632\n",
            "Epoch 71/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 321.9668 - mae: 13.8374 - val_loss: 326.6677 - val_mae: 14.5256\n",
            "Epoch 72/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 321.3043 - mae: 13.7863 - val_loss: 327.8214 - val_mae: 14.2231\n",
            "Epoch 73/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 319.1984 - mae: 13.6778 - val_loss: 325.7444 - val_mae: 14.2984\n",
            "Epoch 74/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 318.5994 - mae: 13.5439 - val_loss: 327.4758 - val_mae: 14.0428\n",
            "Epoch 75/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 318.2684 - mae: 13.4755 - val_loss: 325.7841 - val_mae: 14.0520\n",
            "Epoch 76/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 317.0629 - mae: 13.4335 - val_loss: 325.2460 - val_mae: 13.9884\n",
            "Epoch 77/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 316.3834 - mae: 13.3509 - val_loss: 324.1938 - val_mae: 13.9599\n",
            "Epoch 78/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 316.3745 - mae: 13.5260 - val_loss: 320.8090 - val_mae: 14.1278\n",
            "Epoch 79/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 314.5800 - mae: 13.4446 - val_loss: 321.9174 - val_mae: 13.9161\n",
            "Epoch 80/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 314.5994 - mae: 13.3650 - val_loss: 320.5700 - val_mae: 13.9077\n",
            "Epoch 81/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 313.3985 - mae: 13.2549 - val_loss: 320.1544 - val_mae: 13.8324\n",
            "Epoch 82/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 312.3205 - mae: 13.2633 - val_loss: 317.8973 - val_mae: 13.9099\n",
            "Epoch 83/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 312.4633 - mae: 13.3324 - val_loss: 318.0482 - val_mae: 13.7954\n",
            "Epoch 84/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 311.4463 - mae: 13.1389 - val_loss: 317.4380 - val_mae: 13.7221\n",
            "Epoch 85/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 310.1013 - mae: 13.2953 - val_loss: 313.4791 - val_mae: 13.9411\n",
            "Epoch 86/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 310.2382 - mae: 13.3969 - val_loss: 313.0826 - val_mae: 13.8130\n",
            "Epoch 87/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 308.9810 - mae: 13.0682 - val_loss: 315.8441 - val_mae: 13.4950\n",
            "Epoch 88/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 308.4321 - mae: 12.8728 - val_loss: 314.5537 - val_mae: 13.4494\n",
            "Epoch 89/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 307.3354 - mae: 12.9917 - val_loss: 311.1352 - val_mae: 13.5216\n",
            "Epoch 90/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 306.1606 - mae: 13.0124 - val_loss: 309.3005 - val_mae: 13.4827\n",
            "Epoch 91/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 306.4265 - mae: 13.1498 - val_loss: 307.4619 - val_mae: 13.4702\n",
            "Epoch 92/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 304.1759 - mae: 12.8446 - val_loss: 308.6932 - val_mae: 13.2298\n",
            "Epoch 93/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 303.3228 - mae: 12.7401 - val_loss: 304.9371 - val_mae: 13.3238\n",
            "Epoch 94/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 301.8546 - mae: 12.8444 - val_loss: 303.5497 - val_mae: 13.2809\n",
            "Epoch 95/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 302.0393 - mae: 12.8776 - val_loss: 301.7715 - val_mae: 13.2271\n",
            "Epoch 96/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 301.4305 - mae: 12.4538 - val_loss: 304.5714 - val_mae: 12.9165\n",
            "Epoch 97/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 298.7153 - mae: 12.4077 - val_loss: 299.5170 - val_mae: 13.0483\n",
            "Epoch 98/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 297.6664 - mae: 12.6235 - val_loss: 296.2759 - val_mae: 13.1043\n",
            "Epoch 99/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 297.1483 - mae: 12.5694 - val_loss: 296.9344 - val_mae: 12.8357\n",
            "Epoch 100/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 297.4595 - mae: 12.6358 - val_loss: 294.1595 - val_mae: 12.9397\n",
            "Epoch 101/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 294.7651 - mae: 12.1354 - val_loss: 298.6061 - val_mae: 12.4966\n",
            "Epoch 102/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 295.2437 - mae: 11.9922 - val_loss: 293.6936 - val_mae: 12.5593\n",
            "Epoch 103/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 293.3187 - mae: 12.2905 - val_loss: 289.8487 - val_mae: 12.6544\n",
            "Epoch 104/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 292.1738 - mae: 12.0574 - val_loss: 292.1306 - val_mae: 12.3946\n",
            "Epoch 105/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 290.5323 - mae: 12.0468 - val_loss: 286.3846 - val_mae: 12.5282\n",
            "Epoch 106/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 289.1827 - mae: 12.0526 - val_loss: 286.1154 - val_mae: 12.3477\n",
            "Epoch 107/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 290.8291 - mae: 12.2694 - val_loss: 282.3999 - val_mae: 12.3981\n",
            "Epoch 108/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 286.8116 - mae: 11.7809 - val_loss: 285.8309 - val_mae: 12.0503\n",
            "Epoch 109/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 286.3247 - mae: 11.7044 - val_loss: 280.9078 - val_mae: 12.0514\n",
            "Epoch 110/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 283.9135 - mae: 11.7161 - val_loss: 278.7636 - val_mae: 12.0180\n",
            "Epoch 111/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 282.5747 - mae: 11.6436 - val_loss: 277.3174 - val_mae: 11.9368\n",
            "Epoch 112/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 281.9252 - mae: 11.6024 - val_loss: 276.4385 - val_mae: 11.8111\n",
            "Epoch 113/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 280.5276 - mae: 11.5154 - val_loss: 274.5240 - val_mae: 11.6939\n",
            "Epoch 114/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 279.1096 - mae: 11.4390 - val_loss: 272.1472 - val_mae: 11.6467\n",
            "Epoch 115/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 278.7015 - mae: 11.4806 - val_loss: 269.6244 - val_mae: 11.5564\n",
            "Epoch 116/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 276.6347 - mae: 11.2821 - val_loss: 269.9212 - val_mae: 11.4264\n",
            "Epoch 117/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 277.1024 - mae: 11.1026 - val_loss: 269.8508 - val_mae: 11.4715\n",
            "Epoch 118/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 277.4355 - mae: 11.4007 - val_loss: 264.6589 - val_mae: 11.3143\n",
            "Epoch 119/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 274.4879 - mae: 11.2026 - val_loss: 263.4479 - val_mae: 11.2699\n",
            "Epoch 120/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 273.0648 - mae: 10.9521 - val_loss: 266.2422 - val_mae: 11.0942\n",
            "Epoch 121/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 272.2026 - mae: 10.9095 - val_loss: 261.5282 - val_mae: 11.0760\n",
            "Epoch 122/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 272.1366 - mae: 10.9926 - val_loss: 258.7145 - val_mae: 11.0287\n",
            "Epoch 123/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 271.3806 - mae: 10.9964 - val_loss: 259.2867 - val_mae: 10.9215\n",
            "Epoch 124/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 270.5638 - mae: 10.8878 - val_loss: 255.5048 - val_mae: 10.9254\n",
            "Epoch 125/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 269.2347 - mae: 10.8770 - val_loss: 255.9591 - val_mae: 10.8098\n",
            "Epoch 126/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 269.2952 - mae: 10.7721 - val_loss: 257.3107 - val_mae: 10.7861\n",
            "Epoch 127/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 267.7693 - mae: 10.7660 - val_loss: 252.2971 - val_mae: 10.7268\n",
            "Epoch 128/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 267.6922 - mae: 10.7069 - val_loss: 253.7867 - val_mae: 10.7184\n",
            "Epoch 129/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 267.7286 - mae: 10.7357 - val_loss: 252.4853 - val_mae: 10.6123\n",
            "Epoch 130/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 267.0205 - mae: 10.6641 - val_loss: 254.8204 - val_mae: 10.6388\n",
            "Epoch 131/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 265.9973 - mae: 10.6323 - val_loss: 249.9144 - val_mae: 10.6173\n",
            "Epoch 132/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 266.3535 - mae: 10.6898 - val_loss: 248.2801 - val_mae: 10.5235\n",
            "Epoch 133/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 266.4358 - mae: 10.7147 - val_loss: 250.4805 - val_mae: 10.4864\n",
            "Epoch 134/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 269.7219 - mae: 10.6549 - val_loss: 256.9276 - val_mae: 10.7797\n",
            "Epoch 135/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 268.3012 - mae: 10.8584 - val_loss: 250.9859 - val_mae: 10.6827\n",
            "Epoch 136/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 265.9846 - mae: 10.6296 - val_loss: 250.3230 - val_mae: 10.5417\n",
            "Epoch 137/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 265.2059 - mae: 10.5961 - val_loss: 251.7290 - val_mae: 10.5307\n",
            "Epoch 138/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 265.9135 - mae: 10.6130 - val_loss: 248.1531 - val_mae: 10.4429\n",
            "Epoch 139/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 263.9346 - mae: 10.5126 - val_loss: 250.2114 - val_mae: 10.4366\n",
            "Epoch 140/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 264.0349 - mae: 10.5328 - val_loss: 248.2871 - val_mae: 10.3857\n",
            "Epoch 141/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 263.5025 - mae: 10.4881 - val_loss: 246.4350 - val_mae: 10.4019\n",
            "Epoch 142/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 264.0494 - mae: 10.5286 - val_loss: 245.9315 - val_mae: 10.3786\n",
            "Epoch 143/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 263.8419 - mae: 10.5867 - val_loss: 244.2124 - val_mae: 10.2927\n",
            "Epoch 144/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 264.2023 - mae: 10.5120 - val_loss: 248.4114 - val_mae: 10.4687\n",
            "Epoch 145/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 264.6147 - mae: 10.5140 - val_loss: 248.4689 - val_mae: 10.3741\n",
            "Epoch 146/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 264.0733 - mae: 10.5434 - val_loss: 244.1490 - val_mae: 10.2727\n",
            "Epoch 147/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 264.6726 - mae: 10.5539 - val_loss: 246.2757 - val_mae: 10.2848\n",
            "Epoch 148/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 265.2282 - mae: 10.4838 - val_loss: 252.7275 - val_mae: 10.5403\n",
            "Epoch 149/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 264.6997 - mae: 10.6732 - val_loss: 246.2593 - val_mae: 10.4326\n",
            "Epoch 150/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 263.5300 - mae: 10.5123 - val_loss: 246.7759 - val_mae: 10.3853\n",
            "Epoch 151/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 263.8571 - mae: 10.6308 - val_loss: 246.5295 - val_mae: 10.3855\n",
            "Epoch 152/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 265.0849 - mae: 10.4995 - val_loss: 251.2537 - val_mae: 10.5235\n",
            "Epoch 153/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 263.5947 - mae: 10.5909 - val_loss: 246.5143 - val_mae: 10.4498\n",
            "Epoch 154/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 263.6873 - mae: 10.5731 - val_loss: 245.2871 - val_mae: 10.3812\n",
            "Epoch 155/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 262.1589 - mae: 10.4857 - val_loss: 245.9667 - val_mae: 10.2780\n",
            "Epoch 156/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 262.2911 - mae: 10.4219 - val_loss: 244.5941 - val_mae: 10.2876\n",
            "Epoch 157/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 261.4705 - mae: 10.4353 - val_loss: 243.0893 - val_mae: 10.1998\n",
            "Epoch 158/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 261.3136 - mae: 10.3967 - val_loss: 245.6436 - val_mae: 10.2891\n",
            "Epoch 159/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 262.4232 - mae: 10.4390 - val_loss: 243.1048 - val_mae: 10.2126\n",
            "Epoch 160/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 261.1716 - mae: 10.3965 - val_loss: 246.9855 - val_mae: 10.3337\n",
            "Epoch 161/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 261.4227 - mae: 10.4775 - val_loss: 243.5685 - val_mae: 10.2188\n",
            "Epoch 162/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 261.2611 - mae: 10.4416 - val_loss: 242.5046 - val_mae: 10.2223\n",
            "Epoch 163/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 260.4205 - mae: 10.3935 - val_loss: 243.7489 - val_mae: 10.2713\n",
            "Epoch 164/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 261.4589 - mae: 10.4343 - val_loss: 243.2242 - val_mae: 10.2134\n",
            "Epoch 165/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 260.4435 - mae: 10.4061 - val_loss: 241.9330 - val_mae: 10.2286\n",
            "Epoch 166/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 260.5870 - mae: 10.3860 - val_loss: 245.2168 - val_mae: 10.3036\n",
            "Epoch 167/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 260.3671 - mae: 10.4366 - val_loss: 243.1578 - val_mae: 10.2144\n",
            "Epoch 168/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 260.0690 - mae: 10.4204 - val_loss: 240.7899 - val_mae: 10.1972\n",
            "Epoch 169/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 259.9404 - mae: 10.3989 - val_loss: 243.2177 - val_mae: 10.2797\n",
            "Epoch 170/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 260.1259 - mae: 10.3981 - val_loss: 242.3398 - val_mae: 10.2233\n",
            "Epoch 171/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 259.5780 - mae: 10.3968 - val_loss: 241.5240 - val_mae: 10.2056\n",
            "Epoch 172/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 260.0389 - mae: 10.3903 - val_loss: 240.5560 - val_mae: 10.2127\n",
            "Epoch 173/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 259.4008 - mae: 10.3864 - val_loss: 240.5873 - val_mae: 10.1979\n",
            "Epoch 174/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 259.0992 - mae: 10.4059 - val_loss: 241.5689 - val_mae: 10.1895\n",
            "Epoch 175/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 259.6112 - mae: 10.4244 - val_loss: 243.7195 - val_mae: 10.2543\n",
            "Epoch 176/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 259.5665 - mae: 10.3781 - val_loss: 243.3684 - val_mae: 10.3502\n",
            "Epoch 177/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 259.4727 - mae: 10.4507 - val_loss: 240.7683 - val_mae: 10.1552\n",
            "Epoch 178/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 259.1697 - mae: 10.3821 - val_loss: 241.2385 - val_mae: 10.2924\n",
            "Epoch 179/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 259.2464 - mae: 10.4113 - val_loss: 240.8721 - val_mae: 10.1779\n",
            "Epoch 180/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 259.1387 - mae: 10.3809 - val_loss: 248.0417 - val_mae: 10.3485\n",
            "Epoch 181/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 259.6100 - mae: 10.3880 - val_loss: 240.4210 - val_mae: 10.1815\n",
            "Epoch 182/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 258.4550 - mae: 10.3754 - val_loss: 240.6515 - val_mae: 10.2618\n",
            "Epoch 183/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 258.0195 - mae: 10.3801 - val_loss: 240.2321 - val_mae: 10.1753\n",
            "Epoch 184/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 258.7059 - mae: 10.3719 - val_loss: 241.2779 - val_mae: 10.2257\n",
            "Epoch 185/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 258.7443 - mae: 10.3801 - val_loss: 239.3068 - val_mae: 10.1360\n",
            "Epoch 186/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 258.5906 - mae: 10.3738 - val_loss: 241.4142 - val_mae: 10.2270\n",
            "Epoch 187/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 258.2415 - mae: 10.3872 - val_loss: 242.5226 - val_mae: 10.2381\n",
            "Epoch 188/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 257.4825 - mae: 10.3964 - val_loss: 238.6172 - val_mae: 10.1439\n",
            "Epoch 189/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 258.2675 - mae: 10.4193 - val_loss: 240.1419 - val_mae: 10.1312\n",
            "Epoch 190/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 258.2980 - mae: 10.4228 - val_loss: 243.0779 - val_mae: 10.3052\n",
            "Epoch 191/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 257.5689 - mae: 10.3662 - val_loss: 239.6113 - val_mae: 10.1808\n",
            "Epoch 192/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 257.1657 - mae: 10.3640 - val_loss: 238.8800 - val_mae: 10.1709\n",
            "Epoch 193/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 257.0976 - mae: 10.3506 - val_loss: 238.8676 - val_mae: 10.2136\n",
            "Epoch 194/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 257.0128 - mae: 10.3862 - val_loss: 240.1445 - val_mae: 10.1664\n",
            "Epoch 195/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 257.1920 - mae: 10.3672 - val_loss: 236.2677 - val_mae: 10.1203\n",
            "Epoch 196/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 257.2831 - mae: 10.3483 - val_loss: 238.9915 - val_mae: 10.1885\n",
            "Epoch 197/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 258.1133 - mae: 10.3797 - val_loss: 240.7273 - val_mae: 10.2221\n",
            "Epoch 198/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 259.1609 - mae: 10.4383 - val_loss: 235.0779 - val_mae: 10.0732\n",
            "Epoch 199/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 258.3618 - mae: 10.3722 - val_loss: 241.2604 - val_mae: 10.2654\n",
            "Epoch 200/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 256.4439 - mae: 10.3725 - val_loss: 236.8527 - val_mae: 10.0894\n",
            "Epoch 201/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 257.3175 - mae: 10.3795 - val_loss: 236.6395 - val_mae: 10.0905\n",
            "Epoch 202/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 255.6208 - mae: 10.3160 - val_loss: 240.1962 - val_mae: 10.1967\n",
            "Epoch 203/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 256.1337 - mae: 10.3556 - val_loss: 240.4450 - val_mae: 10.1925\n",
            "Epoch 204/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 255.8391 - mae: 10.3792 - val_loss: 236.7192 - val_mae: 10.0734\n",
            "Epoch 205/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 256.0402 - mae: 10.3597 - val_loss: 238.7510 - val_mae: 10.3179\n",
            "Epoch 206/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 256.8283 - mae: 10.3781 - val_loss: 238.8774 - val_mae: 10.2025\n",
            "Epoch 207/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 256.0784 - mae: 10.3868 - val_loss: 236.5917 - val_mae: 10.1112\n",
            "Epoch 208/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 255.1968 - mae: 10.3794 - val_loss: 240.3661 - val_mae: 10.1544\n",
            "Epoch 209/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 256.4638 - mae: 10.3704 - val_loss: 240.5086 - val_mae: 10.2355\n",
            "Epoch 210/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 256.4041 - mae: 10.3440 - val_loss: 236.8245 - val_mae: 10.1356\n",
            "Epoch 211/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 257.1341 - mae: 10.3654 - val_loss: 241.6819 - val_mae: 10.3132\n",
            "Epoch 212/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 257.0157 - mae: 10.4318 - val_loss: 237.8386 - val_mae: 10.0976\n",
            "Epoch 213/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 254.9771 - mae: 10.3305 - val_loss: 238.2963 - val_mae: 10.2584\n",
            "Epoch 214/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 255.0863 - mae: 10.3523 - val_loss: 237.3319 - val_mae: 10.0831\n",
            "Epoch 215/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 254.3161 - mae: 10.3299 - val_loss: 240.2262 - val_mae: 10.2441\n",
            "Epoch 216/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 254.8703 - mae: 10.3263 - val_loss: 237.5403 - val_mae: 10.1399\n",
            "Epoch 217/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 254.9045 - mae: 10.3570 - val_loss: 236.0169 - val_mae: 10.0776\n",
            "Epoch 218/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 253.9183 - mae: 10.3164 - val_loss: 235.9669 - val_mae: 10.1217\n",
            "Epoch 219/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 254.9516 - mae: 10.3178 - val_loss: 238.7457 - val_mae: 10.2002\n",
            "Epoch 220/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 253.4535 - mae: 10.3115 - val_loss: 236.2348 - val_mae: 10.0921\n",
            "Epoch 221/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 254.1373 - mae: 10.3270 - val_loss: 233.7577 - val_mae: 10.0734\n",
            "Epoch 222/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 254.0530 - mae: 10.3405 - val_loss: 234.0459 - val_mae: 10.0910\n",
            "Epoch 223/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 253.6191 - mae: 10.2775 - val_loss: 239.5455 - val_mae: 10.2146\n",
            "Epoch 224/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 253.9448 - mae: 10.3556 - val_loss: 237.2147 - val_mae: 10.0983\n",
            "Epoch 225/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 253.2218 - mae: 10.2956 - val_loss: 236.8436 - val_mae: 10.1559\n",
            "Epoch 226/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 253.9704 - mae: 10.3088 - val_loss: 240.0363 - val_mae: 10.1772\n",
            "Epoch 227/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 253.6160 - mae: 10.3110 - val_loss: 233.9809 - val_mae: 10.1624\n",
            "Epoch 228/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 253.1407 - mae: 10.3013 - val_loss: 237.2830 - val_mae: 10.1503\n",
            "Epoch 229/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 252.0076 - mae: 10.3048 - val_loss: 233.5990 - val_mae: 10.0464\n",
            "Epoch 230/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 255.2143 - mae: 10.3950 - val_loss: 231.4868 - val_mae: 10.0537\n",
            "Epoch 231/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 254.1595 - mae: 10.3056 - val_loss: 240.6671 - val_mae: 10.2836\n",
            "Epoch 232/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 254.5073 - mae: 10.3686 - val_loss: 233.1220 - val_mae: 10.0254\n",
            "Epoch 233/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 252.7115 - mae: 10.3505 - val_loss: 235.1886 - val_mae: 10.0448\n",
            "Epoch 234/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 252.8244 - mae: 10.2823 - val_loss: 236.2174 - val_mae: 10.1306\n",
            "Epoch 235/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 252.2688 - mae: 10.2922 - val_loss: 235.7977 - val_mae: 10.1266\n",
            "Epoch 236/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 251.0389 - mae: 10.2693 - val_loss: 231.9402 - val_mae: 10.0511\n",
            "Epoch 237/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 254.1790 - mae: 10.3526 - val_loss: 231.4155 - val_mae: 10.0172\n",
            "Epoch 238/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 252.7102 - mae: 10.3100 - val_loss: 236.5063 - val_mae: 10.1274\n",
            "Epoch 239/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 251.3937 - mae: 10.2823 - val_loss: 233.0201 - val_mae: 10.0297\n",
            "Epoch 240/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 251.0703 - mae: 10.2688 - val_loss: 230.3707 - val_mae: 10.0341\n",
            "Epoch 241/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 252.1012 - mae: 10.3048 - val_loss: 230.9577 - val_mae: 9.9762\n",
            "Epoch 242/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 251.1611 - mae: 10.2713 - val_loss: 236.7106 - val_mae: 10.1357\n",
            "Epoch 243/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 251.3387 - mae: 10.2827 - val_loss: 235.5781 - val_mae: 10.0649\n",
            "Epoch 244/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 253.3379 - mae: 10.3277 - val_loss: 230.4355 - val_mae: 9.9926\n",
            "Epoch 245/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 251.0788 - mae: 10.2663 - val_loss: 235.7900 - val_mae: 10.1630\n",
            "Epoch 246/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 251.1820 - mae: 10.2922 - val_loss: 236.4865 - val_mae: 10.0899\n",
            "Epoch 247/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 250.5554 - mae: 10.2481 - val_loss: 234.9336 - val_mae: 10.2052\n",
            "Epoch 248/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 250.7186 - mae: 10.2772 - val_loss: 230.9172 - val_mae: 10.0307\n",
            "Epoch 249/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 250.5131 - mae: 10.2760 - val_loss: 233.0013 - val_mae: 10.0399\n",
            "Epoch 250/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 250.2108 - mae: 10.2489 - val_loss: 231.8102 - val_mae: 10.0545\n",
            "Epoch 251/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 250.2420 - mae: 10.2810 - val_loss: 230.2772 - val_mae: 9.9813\n",
            "Epoch 252/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 251.2085 - mae: 10.2885 - val_loss: 234.0234 - val_mae: 10.1067\n",
            "Epoch 253/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 250.3299 - mae: 10.2728 - val_loss: 229.9648 - val_mae: 10.0253\n",
            "Epoch 254/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 249.8960 - mae: 10.2603 - val_loss: 231.3717 - val_mae: 10.0017\n",
            "Epoch 255/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 249.5340 - mae: 10.2626 - val_loss: 231.4541 - val_mae: 10.0093\n",
            "Epoch 256/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 249.0434 - mae: 10.2563 - val_loss: 229.2893 - val_mae: 9.9710\n",
            "Epoch 257/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 249.8809 - mae: 10.2614 - val_loss: 229.8942 - val_mae: 10.0119\n",
            "Epoch 258/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 251.5430 - mae: 10.2869 - val_loss: 240.1013 - val_mae: 10.1685\n",
            "Epoch 259/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 249.3869 - mae: 10.2582 - val_loss: 231.3784 - val_mae: 10.0479\n",
            "Epoch 260/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 250.0798 - mae: 10.2562 - val_loss: 228.3754 - val_mae: 10.0025\n",
            "Epoch 261/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 250.2538 - mae: 10.3175 - val_loss: 230.2281 - val_mae: 9.9684\n",
            "Epoch 262/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 248.6649 - mae: 10.2637 - val_loss: 233.2641 - val_mae: 10.0364\n",
            "Epoch 263/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 249.2023 - mae: 10.2720 - val_loss: 229.2281 - val_mae: 9.9531\n",
            "Epoch 264/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 249.4400 - mae: 10.2498 - val_loss: 229.5206 - val_mae: 9.9816\n",
            "Epoch 265/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 249.2559 - mae: 10.2356 - val_loss: 236.0721 - val_mae: 10.0963\n",
            "Epoch 266/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 247.8352 - mae: 10.2336 - val_loss: 230.6124 - val_mae: 9.9777\n",
            "Epoch 267/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 248.1549 - mae: 10.2367 - val_loss: 227.8991 - val_mae: 10.0040\n",
            "Epoch 268/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 248.2744 - mae: 10.2423 - val_loss: 229.4810 - val_mae: 9.9284\n",
            "Epoch 269/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 247.3937 - mae: 10.2125 - val_loss: 235.1837 - val_mae: 10.0937\n",
            "Epoch 270/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 247.9313 - mae: 10.2221 - val_loss: 229.4941 - val_mae: 10.0207\n",
            "Epoch 271/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 248.5531 - mae: 10.2765 - val_loss: 227.6071 - val_mae: 9.9173\n",
            "Epoch 272/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 247.6814 - mae: 10.2366 - val_loss: 229.9204 - val_mae: 9.9593\n",
            "Epoch 273/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 248.7720 - mae: 10.2440 - val_loss: 238.2457 - val_mae: 10.1962\n",
            "Epoch 274/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 248.4148 - mae: 10.2197 - val_loss: 229.8615 - val_mae: 10.0076\n",
            "Epoch 275/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 248.2737 - mae: 10.2543 - val_loss: 226.7126 - val_mae: 9.9277\n",
            "Epoch 276/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 246.2638 - mae: 10.2123 - val_loss: 231.3693 - val_mae: 10.0226\n",
            "Epoch 277/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 246.9097 - mae: 10.1938 - val_loss: 231.5351 - val_mae: 10.0511\n",
            "Epoch 278/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 247.2748 - mae: 10.2499 - val_loss: 227.9348 - val_mae: 9.9597\n",
            "Epoch 279/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 247.2609 - mae: 10.2704 - val_loss: 228.7806 - val_mae: 9.9731\n",
            "Epoch 280/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 245.9442 - mae: 10.2096 - val_loss: 228.7965 - val_mae: 9.9526\n",
            "Epoch 281/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 246.3719 - mae: 10.1997 - val_loss: 228.0631 - val_mae: 10.0014\n",
            "Epoch 282/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 246.5976 - mae: 10.1996 - val_loss: 226.3304 - val_mae: 9.9249\n",
            "Epoch 283/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 246.2458 - mae: 10.2314 - val_loss: 228.4499 - val_mae: 9.9421\n",
            "Epoch 284/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 247.2854 - mae: 10.2031 - val_loss: 233.2774 - val_mae: 10.0694\n",
            "Epoch 285/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 245.3982 - mae: 10.1791 - val_loss: 226.1681 - val_mae: 10.0080\n",
            "Epoch 286/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 246.5490 - mae: 10.2465 - val_loss: 226.9952 - val_mae: 9.9447\n",
            "Epoch 287/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 245.4444 - mae: 10.2088 - val_loss: 226.3513 - val_mae: 9.9262\n",
            "Epoch 288/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 245.3643 - mae: 10.2059 - val_loss: 228.0559 - val_mae: 9.9138\n",
            "Epoch 289/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 245.6961 - mae: 10.1923 - val_loss: 230.5873 - val_mae: 10.0244\n",
            "Epoch 290/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 244.9913 - mae: 10.2119 - val_loss: 225.4203 - val_mae: 9.9611\n",
            "Epoch 291/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 244.9121 - mae: 10.1883 - val_loss: 226.1022 - val_mae: 9.8945\n",
            "Epoch 292/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 244.9973 - mae: 10.2091 - val_loss: 226.9518 - val_mae: 10.0084\n",
            "Epoch 293/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 245.3434 - mae: 10.2041 - val_loss: 230.9496 - val_mae: 10.0532\n",
            "Epoch 294/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 244.3734 - mae: 10.1557 - val_loss: 227.9951 - val_mae: 10.0711\n",
            "Epoch 295/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 245.5565 - mae: 10.2475 - val_loss: 225.3133 - val_mae: 9.9741\n",
            "Epoch 296/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 245.9198 - mae: 10.2177 - val_loss: 228.9180 - val_mae: 9.9538\n",
            "Epoch 297/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 250.3260 - mae: 10.3426 - val_loss: 223.3794 - val_mae: 9.8603\n",
            "Epoch 298/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 245.2072 - mae: 10.2320 - val_loss: 229.1455 - val_mae: 10.0297\n",
            "Epoch 299/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 244.1824 - mae: 10.1670 - val_loss: 225.0635 - val_mae: 9.9987\n",
            "Epoch 300/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 244.6352 - mae: 10.2388 - val_loss: 226.4080 - val_mae: 9.9222\n",
            "Epoch 301/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 243.8386 - mae: 10.1920 - val_loss: 224.8094 - val_mae: 9.8650\n",
            "Epoch 302/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 243.0675 - mae: 10.1367 - val_loss: 229.4075 - val_mae: 10.1947\n",
            "Epoch 303/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 243.2273 - mae: 10.1700 - val_loss: 225.7549 - val_mae: 9.8845\n",
            "Epoch 304/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 243.0392 - mae: 10.1921 - val_loss: 224.5544 - val_mae: 9.9154\n",
            "Epoch 305/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 243.2068 - mae: 10.1749 - val_loss: 225.5254 - val_mae: 9.9707\n",
            "Epoch 306/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 243.3262 - mae: 10.1676 - val_loss: 227.7253 - val_mae: 10.0199\n",
            "Epoch 307/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 242.0201 - mae: 10.1409 - val_loss: 223.3816 - val_mae: 9.9294\n",
            "Epoch 308/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 242.3790 - mae: 10.1886 - val_loss: 225.7385 - val_mae: 9.8990\n",
            "Epoch 309/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 243.2180 - mae: 10.1721 - val_loss: 227.7130 - val_mae: 9.9968\n",
            "Epoch 310/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 241.6717 - mae: 10.1322 - val_loss: 224.7650 - val_mae: 9.9328\n",
            "Epoch 311/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 242.2482 - mae: 10.1996 - val_loss: 222.9309 - val_mae: 9.9792\n",
            "Epoch 312/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 242.1091 - mae: 10.2259 - val_loss: 227.0034 - val_mae: 9.8731\n",
            "Epoch 313/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 242.8582 - mae: 10.2062 - val_loss: 225.8176 - val_mae: 10.0109\n",
            "Epoch 314/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 241.5090 - mae: 10.1430 - val_loss: 223.5737 - val_mae: 9.9249\n",
            "Epoch 315/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 242.0360 - mae: 10.1458 - val_loss: 226.4133 - val_mae: 10.0005\n",
            "Epoch 316/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 240.9293 - mae: 10.1394 - val_loss: 221.4808 - val_mae: 9.8268\n",
            "Epoch 317/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 243.3328 - mae: 10.1822 - val_loss: 226.7757 - val_mae: 9.9106\n",
            "Epoch 318/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 240.0936 - mae: 10.0855 - val_loss: 222.1554 - val_mae: 9.9929\n",
            "Epoch 319/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 240.9935 - mae: 10.1670 - val_loss: 222.8830 - val_mae: 9.9400\n",
            "Epoch 320/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 239.8712 - mae: 10.1146 - val_loss: 221.9510 - val_mae: 9.9144\n",
            "Epoch 321/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 240.5771 - mae: 10.1368 - val_loss: 223.1950 - val_mae: 9.8773\n",
            "Epoch 322/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 240.2318 - mae: 10.1344 - val_loss: 222.7283 - val_mae: 9.8484\n",
            "Epoch 323/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 239.7113 - mae: 10.1140 - val_loss: 220.2385 - val_mae: 9.8463\n",
            "Epoch 324/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 239.6719 - mae: 10.1273 - val_loss: 221.4227 - val_mae: 9.8696\n",
            "Epoch 325/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 239.1123 - mae: 10.1072 - val_loss: 220.2650 - val_mae: 9.8595\n",
            "Epoch 326/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 239.2240 - mae: 10.1148 - val_loss: 221.6678 - val_mae: 9.8629\n",
            "Epoch 327/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 238.6636 - mae: 10.0942 - val_loss: 227.1857 - val_mae: 9.9705\n",
            "Epoch 328/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 241.3136 - mae: 10.1728 - val_loss: 220.9886 - val_mae: 9.9482\n",
            "Epoch 329/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 238.8693 - mae: 10.1267 - val_loss: 224.9789 - val_mae: 10.0331\n",
            "Epoch 330/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 239.8275 - mae: 10.1471 - val_loss: 220.3832 - val_mae: 9.7939\n",
            "Epoch 331/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 238.8156 - mae: 10.1178 - val_loss: 221.7463 - val_mae: 9.8453\n",
            "Epoch 332/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 238.2601 - mae: 10.1001 - val_loss: 222.2675 - val_mae: 9.9482\n",
            "Epoch 333/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 238.0584 - mae: 10.0716 - val_loss: 221.1184 - val_mae: 9.9271\n",
            "Epoch 334/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 238.8296 - mae: 10.1975 - val_loss: 222.6022 - val_mae: 9.8104\n",
            "Epoch 335/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 237.6783 - mae: 10.1046 - val_loss: 220.0999 - val_mae: 9.8931\n",
            "Epoch 336/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 237.1041 - mae: 10.0754 - val_loss: 220.1484 - val_mae: 9.9008\n",
            "Epoch 337/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 237.4531 - mae: 10.1249 - val_loss: 218.9226 - val_mae: 9.7738\n",
            "Epoch 338/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 236.6544 - mae: 10.0826 - val_loss: 219.0253 - val_mae: 9.8303\n",
            "Epoch 339/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 236.2463 - mae: 10.0816 - val_loss: 217.9441 - val_mae: 9.7489\n",
            "Epoch 340/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 236.3414 - mae: 10.0761 - val_loss: 218.5002 - val_mae: 9.8874\n",
            "Epoch 341/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 235.7499 - mae: 10.0514 - val_loss: 223.3366 - val_mae: 10.0117\n",
            "Epoch 342/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 238.4943 - mae: 10.1745 - val_loss: 223.1809 - val_mae: 9.8181\n",
            "Epoch 343/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 236.1435 - mae: 10.0720 - val_loss: 222.5606 - val_mae: 9.9899\n",
            "Epoch 344/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 236.5514 - mae: 10.0803 - val_loss: 217.1265 - val_mae: 9.8484\n",
            "Epoch 345/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 239.2446 - mae: 10.1372 - val_loss: 223.5929 - val_mae: 9.8386\n",
            "Epoch 346/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 238.7225 - mae: 10.1576 - val_loss: 220.3976 - val_mae: 10.1665\n",
            "Epoch 347/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 238.2786 - mae: 10.1466 - val_loss: 222.0788 - val_mae: 9.8478\n",
            "Epoch 348/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 234.8900 - mae: 10.1109 - val_loss: 217.0277 - val_mae: 9.7638\n",
            "Epoch 349/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 234.3747 - mae: 10.0869 - val_loss: 218.4912 - val_mae: 9.8596\n",
            "Epoch 350/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 237.3111 - mae: 10.0691 - val_loss: 221.2820 - val_mae: 9.8632\n",
            "Epoch 351/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 234.8943 - mae: 10.0886 - val_loss: 215.4385 - val_mae: 9.7522\n",
            "Epoch 352/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 235.2181 - mae: 10.0701 - val_loss: 217.4913 - val_mae: 9.7968\n",
            "Epoch 353/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 233.3854 - mae: 10.0473 - val_loss: 216.0490 - val_mae: 9.8471\n",
            "Epoch 354/1650\n",
            "10/10 [==============================] - 0s 4ms/step - loss: 233.5086 - mae: 10.0867 - val_loss: 216.0665 - val_mae: 9.7279\n",
            "Epoch 355/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 235.6751 - mae: 10.0432 - val_loss: 221.2567 - val_mae: 9.9125\n",
            "Epoch 356/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 233.0007 - mae: 10.0603 - val_loss: 214.3318 - val_mae: 9.7169\n",
            "Epoch 357/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 233.1697 - mae: 10.0665 - val_loss: 216.5929 - val_mae: 9.8192\n",
            "Epoch 358/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 232.6221 - mae: 10.0327 - val_loss: 214.0269 - val_mae: 9.7693\n",
            "Epoch 359/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 231.9980 - mae: 10.0392 - val_loss: 216.3467 - val_mae: 9.8378\n",
            "Epoch 360/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 232.1856 - mae: 9.9850 - val_loss: 219.8531 - val_mae: 9.8002\n",
            "Epoch 361/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 233.2067 - mae: 10.0301 - val_loss: 213.3558 - val_mae: 9.8224\n",
            "Epoch 362/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 232.2360 - mae: 10.0509 - val_loss: 219.2762 - val_mae: 9.7941\n",
            "Epoch 363/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 231.1685 - mae: 9.9917 - val_loss: 213.4710 - val_mae: 9.7749\n",
            "Epoch 364/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 234.1020 - mae: 10.1372 - val_loss: 212.4764 - val_mae: 9.7498\n",
            "Epoch 365/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 230.2052 - mae: 9.9940 - val_loss: 220.6100 - val_mae: 9.8139\n",
            "Epoch 366/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 230.4594 - mae: 9.9418 - val_loss: 215.0247 - val_mae: 9.9193\n",
            "Epoch 367/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 229.8105 - mae: 10.0320 - val_loss: 212.1846 - val_mae: 9.7426\n",
            "Epoch 368/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 230.0360 - mae: 10.0515 - val_loss: 212.9062 - val_mae: 9.7789\n",
            "Epoch 369/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 230.2646 - mae: 10.0100 - val_loss: 215.7495 - val_mae: 9.7850\n",
            "Epoch 370/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 229.1315 - mae: 9.9554 - val_loss: 212.6936 - val_mae: 9.7489\n",
            "Epoch 371/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 229.9481 - mae: 10.0503 - val_loss: 210.6685 - val_mae: 9.7268\n",
            "Epoch 372/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 228.2868 - mae: 9.9836 - val_loss: 214.3807 - val_mae: 9.7142\n",
            "Epoch 373/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 228.2888 - mae: 9.9582 - val_loss: 212.6052 - val_mae: 9.7454\n",
            "Epoch 374/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 227.6179 - mae: 9.9745 - val_loss: 212.9196 - val_mae: 9.6914\n",
            "Epoch 375/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 228.9553 - mae: 9.9441 - val_loss: 215.3736 - val_mae: 9.7966\n",
            "Epoch 376/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 227.8634 - mae: 9.9424 - val_loss: 210.8804 - val_mae: 9.9264\n",
            "Epoch 377/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 228.7993 - mae: 10.1002 - val_loss: 212.1159 - val_mae: 9.6524\n",
            "Epoch 378/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 229.0729 - mae: 9.9844 - val_loss: 212.8651 - val_mae: 9.7716\n",
            "Epoch 379/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 226.0475 - mae: 9.9195 - val_loss: 209.1644 - val_mae: 9.7179\n",
            "Epoch 380/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 227.1445 - mae: 9.9870 - val_loss: 210.4545 - val_mae: 9.8444\n",
            "Epoch 381/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 225.2245 - mae: 9.9314 - val_loss: 214.1239 - val_mae: 9.7586\n",
            "Epoch 382/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 225.8138 - mae: 9.9383 - val_loss: 211.4044 - val_mae: 9.6898\n",
            "Epoch 383/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 224.9059 - mae: 9.9102 - val_loss: 208.8781 - val_mae: 9.7642\n",
            "Epoch 384/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 225.1594 - mae: 10.0172 - val_loss: 207.9306 - val_mae: 9.6752\n",
            "Epoch 385/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 226.9060 - mae: 9.9575 - val_loss: 210.4018 - val_mae: 9.6861\n",
            "Epoch 386/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 224.1917 - mae: 9.9381 - val_loss: 206.6371 - val_mae: 9.6610\n",
            "Epoch 387/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 224.0136 - mae: 9.9393 - val_loss: 209.1792 - val_mae: 9.7075\n",
            "Epoch 388/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 223.1959 - mae: 9.8806 - val_loss: 210.3343 - val_mae: 9.6931\n",
            "Epoch 389/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 222.7227 - mae: 9.8923 - val_loss: 205.7423 - val_mae: 9.6755\n",
            "Epoch 390/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 223.0152 - mae: 9.9372 - val_loss: 209.3334 - val_mae: 9.6653\n",
            "Epoch 391/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 223.3136 - mae: 9.9117 - val_loss: 206.6653 - val_mae: 9.6428\n",
            "Epoch 392/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 222.9576 - mae: 9.8673 - val_loss: 208.4323 - val_mae: 9.6827\n",
            "Epoch 393/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 222.4984 - mae: 9.8976 - val_loss: 208.7618 - val_mae: 9.6371\n",
            "Epoch 394/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 221.9240 - mae: 9.9617 - val_loss: 203.3130 - val_mae: 9.6637\n",
            "Epoch 395/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 222.3393 - mae: 9.9558 - val_loss: 208.1278 - val_mae: 9.6158\n",
            "Epoch 396/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 220.4954 - mae: 9.8772 - val_loss: 204.1584 - val_mae: 9.6822\n",
            "Epoch 397/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 220.9786 - mae: 9.9132 - val_loss: 203.4602 - val_mae: 9.7294\n",
            "Epoch 398/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 220.9294 - mae: 9.9128 - val_loss: 209.1234 - val_mae: 9.7001\n",
            "Epoch 399/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 220.1798 - mae: 9.8677 - val_loss: 204.2455 - val_mae: 9.5689\n",
            "Epoch 400/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 220.8854 - mae: 9.9566 - val_loss: 201.3495 - val_mae: 9.5736\n",
            "Epoch 401/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 219.9150 - mae: 9.8489 - val_loss: 205.3902 - val_mae: 9.5864\n",
            "Epoch 402/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 217.9073 - mae: 9.8353 - val_loss: 202.3450 - val_mae: 9.5068\n",
            "Epoch 403/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 219.6519 - mae: 9.9083 - val_loss: 206.0397 - val_mae: 10.0207\n",
            "Epoch 404/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 221.3523 - mae: 9.9267 - val_loss: 207.5307 - val_mae: 9.6014\n",
            "Epoch 405/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 216.7425 - mae: 9.8078 - val_loss: 200.9219 - val_mae: 9.5627\n",
            "Epoch 406/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 218.6091 - mae: 9.9208 - val_loss: 201.1940 - val_mae: 9.6499\n",
            "Epoch 407/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 217.5097 - mae: 9.7969 - val_loss: 205.1217 - val_mae: 9.5552\n",
            "Epoch 408/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 216.5476 - mae: 9.8795 - val_loss: 199.6848 - val_mae: 9.5926\n",
            "Epoch 409/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 214.8504 - mae: 9.7972 - val_loss: 203.5179 - val_mae: 9.7770\n",
            "Epoch 410/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 215.8536 - mae: 9.8454 - val_loss: 202.0479 - val_mae: 9.5776\n",
            "Epoch 411/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 215.1209 - mae: 9.7991 - val_loss: 201.6394 - val_mae: 9.5535\n",
            "Epoch 412/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 213.3136 - mae: 9.7623 - val_loss: 198.1158 - val_mae: 9.5364\n",
            "Epoch 413/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 214.2352 - mae: 9.8593 - val_loss: 198.0142 - val_mae: 9.4823\n",
            "Epoch 414/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 213.4768 - mae: 9.7818 - val_loss: 198.4192 - val_mae: 9.5352\n",
            "Epoch 415/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 212.7472 - mae: 9.7621 - val_loss: 197.6160 - val_mae: 9.6162\n",
            "Epoch 416/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 212.9423 - mae: 9.7799 - val_loss: 199.6361 - val_mae: 9.4605\n",
            "Epoch 417/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 212.1115 - mae: 9.7530 - val_loss: 196.6350 - val_mae: 9.5465\n",
            "Epoch 418/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 211.6636 - mae: 9.7724 - val_loss: 197.0046 - val_mae: 9.5193\n",
            "Epoch 419/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 211.7537 - mae: 9.7286 - val_loss: 195.8076 - val_mae: 9.4696\n",
            "Epoch 420/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 212.5294 - mae: 9.8693 - val_loss: 194.4364 - val_mae: 9.6878\n",
            "Epoch 421/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 211.9786 - mae: 9.7773 - val_loss: 201.5391 - val_mae: 9.5091\n",
            "Epoch 422/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 210.2629 - mae: 9.7421 - val_loss: 194.0286 - val_mae: 9.6691\n",
            "Epoch 423/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 208.9456 - mae: 9.7819 - val_loss: 195.9784 - val_mae: 9.4365\n",
            "Epoch 424/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 213.7276 - mae: 9.7398 - val_loss: 196.0843 - val_mae: 9.4636\n",
            "Epoch 425/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 210.9641 - mae: 9.9080 - val_loss: 191.2865 - val_mae: 9.4846\n",
            "Epoch 426/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 210.3727 - mae: 9.7578 - val_loss: 204.4701 - val_mae: 9.6406\n",
            "Epoch 427/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 209.4561 - mae: 9.7008 - val_loss: 193.2835 - val_mae: 9.7909\n",
            "Epoch 428/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 209.7197 - mae: 9.9304 - val_loss: 195.1013 - val_mae: 9.3625\n",
            "Epoch 429/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 213.8234 - mae: 9.7826 - val_loss: 195.0683 - val_mae: 9.4314\n",
            "Epoch 430/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 211.4632 - mae: 9.8404 - val_loss: 191.7413 - val_mae: 9.7488\n",
            "Epoch 431/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 209.1277 - mae: 9.7878 - val_loss: 194.4281 - val_mae: 9.4385\n",
            "Epoch 432/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 207.3564 - mae: 9.7792 - val_loss: 188.5600 - val_mae: 9.4180\n",
            "Epoch 433/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 204.6900 - mae: 9.7021 - val_loss: 192.3942 - val_mae: 9.4058\n",
            "Epoch 434/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 203.9412 - mae: 9.6303 - val_loss: 190.2750 - val_mae: 9.4224\n",
            "Epoch 435/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 204.1631 - mae: 9.7275 - val_loss: 188.4967 - val_mae: 9.5315\n",
            "Epoch 436/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 205.3507 - mae: 9.6473 - val_loss: 190.4618 - val_mae: 9.4346\n",
            "Epoch 437/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 201.8124 - mae: 9.7095 - val_loss: 188.8999 - val_mae: 9.3354\n",
            "Epoch 438/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 201.8526 - mae: 9.6144 - val_loss: 188.9459 - val_mae: 9.5404\n",
            "Epoch 439/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 200.6619 - mae: 9.6175 - val_loss: 187.3651 - val_mae: 9.4020\n",
            "Epoch 440/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 199.7800 - mae: 9.6199 - val_loss: 188.0367 - val_mae: 9.3358\n",
            "Epoch 441/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 199.9252 - mae: 9.5468 - val_loss: 187.9736 - val_mae: 9.5041\n",
            "Epoch 442/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 199.9137 - mae: 9.6677 - val_loss: 185.6616 - val_mae: 9.3028\n",
            "Epoch 443/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 199.7750 - mae: 9.5653 - val_loss: 187.4028 - val_mae: 9.4140\n",
            "Epoch 444/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 198.0571 - mae: 9.5971 - val_loss: 184.3093 - val_mae: 9.3741\n",
            "Epoch 445/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 196.9801 - mae: 9.6044 - val_loss: 185.3309 - val_mae: 9.4207\n",
            "Epoch 446/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 197.1510 - mae: 9.5390 - val_loss: 186.2810 - val_mae: 9.4194\n",
            "Epoch 447/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 196.5858 - mae: 9.5589 - val_loss: 183.2970 - val_mae: 9.2974\n",
            "Epoch 448/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 195.1886 - mae: 9.5617 - val_loss: 182.0844 - val_mae: 9.3432\n",
            "Epoch 449/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 194.9115 - mae: 9.5487 - val_loss: 185.3157 - val_mae: 9.2801\n",
            "Epoch 450/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 193.5001 - mae: 9.5214 - val_loss: 180.1390 - val_mae: 9.4150\n",
            "Epoch 451/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 195.5598 - mae: 9.5304 - val_loss: 184.0657 - val_mae: 9.2250\n",
            "Epoch 452/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 195.8584 - mae: 9.7137 - val_loss: 178.5477 - val_mae: 9.2962\n",
            "Epoch 453/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 192.6078 - mae: 9.4554 - val_loss: 186.6660 - val_mae: 9.3027\n",
            "Epoch 454/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 192.9542 - mae: 9.5375 - val_loss: 178.0872 - val_mae: 9.3221\n",
            "Epoch 455/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 191.4781 - mae: 9.5210 - val_loss: 180.6304 - val_mae: 9.4400\n",
            "Epoch 456/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 190.9267 - mae: 9.4985 - val_loss: 179.3221 - val_mae: 9.1635\n",
            "Epoch 457/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 191.0178 - mae: 9.6133 - val_loss: 183.5689 - val_mae: 9.4356\n",
            "Epoch 458/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 190.5239 - mae: 9.3881 - val_loss: 177.7204 - val_mae: 9.2696\n",
            "Epoch 459/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 189.0099 - mae: 9.5441 - val_loss: 177.9108 - val_mae: 9.2062\n",
            "Epoch 460/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 188.2278 - mae: 9.4475 - val_loss: 177.8281 - val_mae: 9.3694\n",
            "Epoch 461/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 188.9127 - mae: 9.4234 - val_loss: 175.3638 - val_mae: 9.2287\n",
            "Epoch 462/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 187.4953 - mae: 9.5114 - val_loss: 176.0862 - val_mae: 9.1595\n",
            "Epoch 463/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 186.8651 - mae: 9.3959 - val_loss: 179.5825 - val_mae: 9.4966\n",
            "Epoch 464/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 189.1475 - mae: 9.4906 - val_loss: 173.0711 - val_mae: 9.2951\n",
            "Epoch 465/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 186.7794 - mae: 9.4560 - val_loss: 175.5109 - val_mae: 9.1002\n",
            "Epoch 466/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 186.8174 - mae: 9.3331 - val_loss: 172.7610 - val_mae: 9.1404\n",
            "Epoch 467/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 191.1740 - mae: 9.7615 - val_loss: 178.2713 - val_mae: 9.6379\n",
            "Epoch 468/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 185.6535 - mae: 9.3068 - val_loss: 179.2515 - val_mae: 9.1240\n",
            "Epoch 469/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 184.8064 - mae: 9.4998 - val_loss: 168.8988 - val_mae: 9.2008\n",
            "Epoch 470/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 181.5523 - mae: 9.3564 - val_loss: 174.4503 - val_mae: 9.0833\n",
            "Epoch 471/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 182.1129 - mae: 9.3208 - val_loss: 169.3609 - val_mae: 9.3941\n",
            "Epoch 472/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 181.4217 - mae: 9.4481 - val_loss: 173.1930 - val_mae: 9.1308\n",
            "Epoch 473/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 180.5412 - mae: 9.3021 - val_loss: 168.5063 - val_mae: 9.0412\n",
            "Epoch 474/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 178.2955 - mae: 9.2643 - val_loss: 166.8268 - val_mae: 9.3417\n",
            "Epoch 475/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 180.9301 - mae: 9.4929 - val_loss: 168.9672 - val_mae: 9.1112\n",
            "Epoch 476/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 177.9782 - mae: 9.3814 - val_loss: 166.9983 - val_mae: 8.9502\n",
            "Epoch 477/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 178.0130 - mae: 9.3394 - val_loss: 166.3703 - val_mae: 9.1004\n",
            "Epoch 478/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 176.3619 - mae: 9.2374 - val_loss: 165.9294 - val_mae: 9.1374\n",
            "Epoch 479/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 180.2806 - mae: 9.3233 - val_loss: 164.7535 - val_mae: 8.9685\n",
            "Epoch 480/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 179.7258 - mae: 9.3607 - val_loss: 163.4814 - val_mae: 9.0596\n",
            "Epoch 481/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 173.3772 - mae: 9.2746 - val_loss: 166.1705 - val_mae: 9.0652\n",
            "Epoch 482/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 173.5618 - mae: 9.2080 - val_loss: 162.8600 - val_mae: 8.9749\n",
            "Epoch 483/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 174.4211 - mae: 9.2297 - val_loss: 161.2268 - val_mae: 9.0102\n",
            "Epoch 484/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 173.9689 - mae: 9.3115 - val_loss: 162.3155 - val_mae: 9.0190\n",
            "Epoch 485/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 170.9736 - mae: 9.1397 - val_loss: 159.7596 - val_mae: 9.0063\n",
            "Epoch 486/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 170.5499 - mae: 9.2759 - val_loss: 162.0698 - val_mae: 8.8845\n",
            "Epoch 487/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 169.1509 - mae: 9.0910 - val_loss: 158.1812 - val_mae: 9.0495\n",
            "Epoch 488/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 169.6348 - mae: 9.1779 - val_loss: 159.2929 - val_mae: 8.8947\n",
            "Epoch 489/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 167.9552 - mae: 9.1826 - val_loss: 158.7131 - val_mae: 8.9971\n",
            "Epoch 490/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 167.6651 - mae: 9.1186 - val_loss: 157.9849 - val_mae: 8.8318\n",
            "Epoch 491/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 166.0582 - mae: 9.1107 - val_loss: 159.0733 - val_mae: 8.9189\n",
            "Epoch 492/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 169.5883 - mae: 9.2061 - val_loss: 160.0232 - val_mae: 9.1694\n",
            "Epoch 493/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 166.2044 - mae: 9.1403 - val_loss: 156.0419 - val_mae: 8.9014\n",
            "Epoch 494/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 163.4441 - mae: 9.0466 - val_loss: 153.5320 - val_mae: 8.8688\n",
            "Epoch 495/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 166.9254 - mae: 9.2613 - val_loss: 162.8185 - val_mae: 9.1265\n",
            "Epoch 496/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 169.5299 - mae: 9.0771 - val_loss: 152.0093 - val_mae: 8.8601\n",
            "Epoch 497/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 167.3965 - mae: 9.3532 - val_loss: 156.8992 - val_mae: 8.7744\n",
            "Epoch 498/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 161.8016 - mae: 9.0303 - val_loss: 151.9474 - val_mae: 9.0172\n",
            "Epoch 499/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 160.4647 - mae: 9.1277 - val_loss: 153.2602 - val_mae: 8.7439\n",
            "Epoch 500/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 160.5955 - mae: 8.9749 - val_loss: 149.8860 - val_mae: 8.9081\n",
            "Epoch 501/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 160.0551 - mae: 9.0436 - val_loss: 152.3567 - val_mae: 8.7780\n",
            "Epoch 502/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 158.3143 - mae: 9.0144 - val_loss: 149.1624 - val_mae: 8.6873\n",
            "Epoch 503/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 157.5663 - mae: 9.0252 - val_loss: 151.5518 - val_mae: 8.8882\n",
            "Epoch 504/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 163.1566 - mae: 9.0091 - val_loss: 148.5267 - val_mae: 8.6922\n",
            "Epoch 505/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 161.8368 - mae: 9.2877 - val_loss: 150.5169 - val_mae: 8.7768\n",
            "Epoch 506/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 162.5969 - mae: 9.0215 - val_loss: 145.3247 - val_mae: 8.7798\n",
            "Epoch 507/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 159.0169 - mae: 9.1829 - val_loss: 154.6973 - val_mae: 8.8313\n",
            "Epoch 508/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 160.6540 - mae: 8.9503 - val_loss: 144.1872 - val_mae: 8.7583\n",
            "Epoch 509/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 156.1457 - mae: 9.1819 - val_loss: 147.3089 - val_mae: 8.6891\n",
            "Epoch 510/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 153.3021 - mae: 8.8551 - val_loss: 146.5144 - val_mae: 8.9099\n",
            "Epoch 511/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 152.6731 - mae: 8.9720 - val_loss: 144.6253 - val_mae: 8.5929\n",
            "Epoch 512/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 152.4325 - mae: 8.9239 - val_loss: 148.6527 - val_mae: 8.8839\n",
            "Epoch 513/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 160.2174 - mae: 8.9670 - val_loss: 142.3324 - val_mae: 8.5830\n",
            "Epoch 514/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 153.2577 - mae: 9.0406 - val_loss: 150.4342 - val_mae: 8.7564\n",
            "Epoch 515/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 152.9938 - mae: 8.8824 - val_loss: 144.5641 - val_mae: 8.7170\n",
            "Epoch 516/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 148.5134 - mae: 8.8057 - val_loss: 143.6419 - val_mae: 8.5770\n",
            "Epoch 517/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 147.7050 - mae: 8.7013 - val_loss: 141.8479 - val_mae: 8.9564\n",
            "Epoch 518/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 149.2886 - mae: 8.9987 - val_loss: 142.8005 - val_mae: 8.4854\n",
            "Epoch 519/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 147.6830 - mae: 8.7748 - val_loss: 138.8352 - val_mae: 8.6099\n",
            "Epoch 520/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 144.8459 - mae: 8.7472 - val_loss: 138.8148 - val_mae: 8.6123\n",
            "Epoch 521/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 144.4653 - mae: 8.8053 - val_loss: 138.8922 - val_mae: 8.4306\n",
            "Epoch 522/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 145.0696 - mae: 8.6372 - val_loss: 138.6936 - val_mae: 8.8526\n",
            "Epoch 523/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 144.3437 - mae: 8.8256 - val_loss: 141.2127 - val_mae: 8.6501\n",
            "Epoch 524/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 143.1721 - mae: 8.7197 - val_loss: 136.4628 - val_mae: 8.4647\n",
            "Epoch 525/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 143.0756 - mae: 8.7391 - val_loss: 135.6035 - val_mae: 8.5013\n",
            "Epoch 526/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 143.4795 - mae: 8.6335 - val_loss: 132.7023 - val_mae: 8.5079\n",
            "Epoch 527/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 142.8902 - mae: 8.8706 - val_loss: 136.6686 - val_mae: 8.5782\n",
            "Epoch 528/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 138.9433 - mae: 8.5905 - val_loss: 132.8256 - val_mae: 8.4261\n",
            "Epoch 529/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 138.9222 - mae: 8.7505 - val_loss: 133.9743 - val_mae: 8.3896\n",
            "Epoch 530/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 140.3277 - mae: 8.6879 - val_loss: 132.8174 - val_mae: 8.6788\n",
            "Epoch 531/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 138.3211 - mae: 8.6451 - val_loss: 129.3577 - val_mae: 8.4213\n",
            "Epoch 532/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 140.7947 - mae: 8.7781 - val_loss: 133.2699 - val_mae: 8.3779\n",
            "Epoch 533/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 133.9370 - mae: 8.4901 - val_loss: 128.6976 - val_mae: 8.6458\n",
            "Epoch 534/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 134.9744 - mae: 8.6917 - val_loss: 129.6040 - val_mae: 8.2925\n",
            "Epoch 535/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 133.1483 - mae: 8.4461 - val_loss: 133.2833 - val_mae: 8.6958\n",
            "Epoch 536/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 131.8335 - mae: 8.5611 - val_loss: 126.0494 - val_mae: 8.1859\n",
            "Epoch 537/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 134.0361 - mae: 8.5768 - val_loss: 126.3584 - val_mae: 8.3345\n",
            "Epoch 538/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 134.6037 - mae: 8.5642 - val_loss: 126.9229 - val_mae: 8.2951\n",
            "Epoch 539/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 129.6161 - mae: 8.5199 - val_loss: 121.9798 - val_mae: 8.3060\n",
            "Epoch 540/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 127.8580 - mae: 8.5548 - val_loss: 125.4586 - val_mae: 8.0924\n",
            "Epoch 541/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 126.4933 - mae: 8.4044 - val_loss: 119.1307 - val_mae: 8.2031\n",
            "Epoch 542/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 125.6202 - mae: 8.4260 - val_loss: 122.8694 - val_mae: 8.1856\n",
            "Epoch 543/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 126.1548 - mae: 8.3462 - val_loss: 118.1249 - val_mae: 8.1524\n",
            "Epoch 544/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 123.7562 - mae: 8.3760 - val_loss: 129.8073 - val_mae: 8.3125\n",
            "Epoch 545/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 125.0772 - mae: 8.3451 - val_loss: 115.2038 - val_mae: 8.2134\n",
            "Epoch 546/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 126.1001 - mae: 8.4579 - val_loss: 114.3262 - val_mae: 8.0811\n",
            "Epoch 547/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 122.5800 - mae: 8.3993 - val_loss: 115.4503 - val_mae: 8.0459\n",
            "Epoch 548/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 121.3708 - mae: 8.2454 - val_loss: 116.4260 - val_mae: 8.1022\n",
            "Epoch 549/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 117.3957 - mae: 8.2392 - val_loss: 112.2241 - val_mae: 8.1173\n",
            "Epoch 550/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 118.1462 - mae: 8.2125 - val_loss: 113.5319 - val_mae: 7.9907\n",
            "Epoch 551/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 131.7424 - mae: 8.7157 - val_loss: 127.5313 - val_mae: 8.0169\n",
            "Epoch 552/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 119.4428 - mae: 8.2017 - val_loss: 112.2584 - val_mae: 8.2607\n",
            "Epoch 553/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 117.7751 - mae: 8.2262 - val_loss: 108.7880 - val_mae: 7.7641\n",
            "Epoch 554/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 115.7459 - mae: 8.3453 - val_loss: 109.3059 - val_mae: 7.7540\n",
            "Epoch 555/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 114.5517 - mae: 8.0676 - val_loss: 112.4238 - val_mae: 8.4256\n",
            "Epoch 556/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 116.1229 - mae: 8.3068 - val_loss: 108.7173 - val_mae: 7.7225\n",
            "Epoch 557/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 114.0431 - mae: 8.1407 - val_loss: 104.6423 - val_mae: 8.0105\n",
            "Epoch 558/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 108.7254 - mae: 8.0549 - val_loss: 109.3323 - val_mae: 7.7131\n",
            "Epoch 559/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 109.0974 - mae: 7.9520 - val_loss: 103.8400 - val_mae: 7.8747\n",
            "Epoch 560/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 111.5787 - mae: 8.1085 - val_loss: 112.4073 - val_mae: 7.8135\n",
            "Epoch 561/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 105.8916 - mae: 7.8687 - val_loss: 101.9845 - val_mae: 7.7675\n",
            "Epoch 562/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 109.7799 - mae: 8.0458 - val_loss: 105.1000 - val_mae: 7.7596\n",
            "Epoch 563/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 107.5818 - mae: 8.0910 - val_loss: 103.1187 - val_mae: 7.6025\n",
            "Epoch 564/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 107.1243 - mae: 7.9014 - val_loss: 103.6688 - val_mae: 8.1201\n",
            "Epoch 565/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 108.0616 - mae: 8.1140 - val_loss: 109.4560 - val_mae: 7.6415\n",
            "Epoch 566/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 108.2143 - mae: 8.0207 - val_loss: 98.3921 - val_mae: 7.6218\n",
            "Epoch 567/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 101.6872 - mae: 7.8237 - val_loss: 97.2703 - val_mae: 7.7469\n",
            "Epoch 568/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 107.7835 - mae: 8.0719 - val_loss: 96.1671 - val_mae: 7.4977\n",
            "Epoch 569/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 106.3328 - mae: 8.0847 - val_loss: 100.0882 - val_mae: 7.5239\n",
            "Epoch 570/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 100.3648 - mae: 7.7972 - val_loss: 93.5075 - val_mae: 7.5418\n",
            "Epoch 571/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 98.4767 - mae: 7.7293 - val_loss: 96.1665 - val_mae: 7.5160\n",
            "Epoch 572/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 97.6982 - mae: 7.7941 - val_loss: 92.1318 - val_mae: 7.4910\n",
            "Epoch 573/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 98.3356 - mae: 7.7446 - val_loss: 93.3957 - val_mae: 7.4423\n",
            "Epoch 574/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 95.8384 - mae: 7.6564 - val_loss: 92.0847 - val_mae: 7.5103\n",
            "Epoch 575/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 94.9886 - mae: 7.6984 - val_loss: 90.3061 - val_mae: 7.3828\n",
            "Epoch 576/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 94.7483 - mae: 7.7411 - val_loss: 91.2013 - val_mae: 7.3455\n",
            "Epoch 577/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 95.8258 - mae: 7.6365 - val_loss: 88.7125 - val_mae: 7.4038\n",
            "Epoch 578/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 94.4893 - mae: 7.6567 - val_loss: 89.0587 - val_mae: 7.3881\n",
            "Epoch 579/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 93.1960 - mae: 7.6444 - val_loss: 102.2357 - val_mae: 7.6492\n",
            "Epoch 580/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 99.5733 - mae: 7.7662 - val_loss: 87.7340 - val_mae: 7.2471\n",
            "Epoch 581/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 94.3385 - mae: 7.5749 - val_loss: 87.8857 - val_mae: 7.5604\n",
            "Epoch 582/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 93.1108 - mae: 7.7346 - val_loss: 89.5908 - val_mae: 7.1590\n",
            "Epoch 583/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 91.3804 - mae: 7.5919 - val_loss: 87.6324 - val_mae: 7.5512\n",
            "Epoch 584/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 89.2446 - mae: 7.5298 - val_loss: 87.4389 - val_mae: 7.1137\n",
            "Epoch 585/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 90.5723 - mae: 7.5028 - val_loss: 84.0104 - val_mae: 7.3138\n",
            "Epoch 586/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 88.5170 - mae: 7.4855 - val_loss: 83.8906 - val_mae: 7.1190\n",
            "Epoch 587/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 88.8062 - mae: 7.5321 - val_loss: 82.5860 - val_mae: 7.1537\n",
            "Epoch 588/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 88.2310 - mae: 7.4610 - val_loss: 96.2288 - val_mae: 7.5260\n",
            "Epoch 589/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 92.4327 - mae: 7.6046 - val_loss: 81.9550 - val_mae: 7.2316\n",
            "Epoch 590/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 88.9287 - mae: 7.5214 - val_loss: 84.2718 - val_mae: 7.1475\n",
            "Epoch 591/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 87.7117 - mae: 7.5485 - val_loss: 89.6734 - val_mae: 7.1057\n",
            "Epoch 592/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 90.9979 - mae: 7.4792 - val_loss: 86.0886 - val_mae: 7.6297\n",
            "Epoch 593/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 90.7038 - mae: 7.5060 - val_loss: 84.7953 - val_mae: 7.0925\n",
            "Epoch 594/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 85.3705 - mae: 7.4315 - val_loss: 84.1483 - val_mae: 7.1014\n",
            "Epoch 595/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 84.3184 - mae: 7.2906 - val_loss: 78.6538 - val_mae: 7.0297\n",
            "Epoch 596/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 82.9409 - mae: 7.2820 - val_loss: 79.3881 - val_mae: 7.0596\n",
            "Epoch 597/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 83.7832 - mae: 7.3270 - val_loss: 88.0749 - val_mae: 7.3875\n",
            "Epoch 598/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 87.1394 - mae: 7.4506 - val_loss: 79.9785 - val_mae: 6.8883\n",
            "Epoch 599/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 81.6870 - mae: 7.2365 - val_loss: 77.6962 - val_mae: 7.1434\n",
            "Epoch 600/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 81.7487 - mae: 7.3503 - val_loss: 81.1313 - val_mae: 6.8814\n",
            "Epoch 601/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 85.9002 - mae: 7.3388 - val_loss: 82.7201 - val_mae: 7.2842\n",
            "Epoch 602/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 81.1628 - mae: 7.2313 - val_loss: 76.4515 - val_mae: 6.7979\n",
            "Epoch 603/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 79.6763 - mae: 7.1823 - val_loss: 74.8096 - val_mae: 6.8605\n",
            "Epoch 604/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 79.1880 - mae: 7.1249 - val_loss: 74.5759 - val_mae: 6.8885\n",
            "Epoch 605/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 80.2779 - mae: 7.2523 - val_loss: 74.8789 - val_mae: 6.7722\n",
            "Epoch 606/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 83.3463 - mae: 7.2432 - val_loss: 79.6648 - val_mae: 7.0938\n",
            "Epoch 607/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 82.3612 - mae: 7.3455 - val_loss: 86.9697 - val_mae: 7.0457\n",
            "Epoch 608/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 82.8587 - mae: 7.3094 - val_loss: 72.8754 - val_mae: 6.7296\n",
            "Epoch 609/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 78.9632 - mae: 7.0893 - val_loss: 78.8682 - val_mae: 7.0825\n",
            "Epoch 610/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 78.9058 - mae: 7.1484 - val_loss: 76.3995 - val_mae: 6.6935\n",
            "Epoch 611/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 82.2221 - mae: 7.2862 - val_loss: 74.1786 - val_mae: 6.8103\n",
            "Epoch 612/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 81.6790 - mae: 7.1695 - val_loss: 71.4410 - val_mae: 6.7604\n",
            "Epoch 613/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 79.8922 - mae: 7.1918 - val_loss: 71.1955 - val_mae: 6.7307\n",
            "Epoch 614/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 76.2514 - mae: 7.0642 - val_loss: 71.7544 - val_mae: 6.6554\n",
            "Epoch 615/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 77.3736 - mae: 7.1149 - val_loss: 70.3338 - val_mae: 6.5886\n",
            "Epoch 616/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 74.6567 - mae: 6.9410 - val_loss: 72.5140 - val_mae: 6.7854\n",
            "Epoch 617/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 74.5250 - mae: 6.9794 - val_loss: 69.3893 - val_mae: 6.5300\n",
            "Epoch 618/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 73.1929 - mae: 6.9128 - val_loss: 68.6625 - val_mae: 6.6221\n",
            "Epoch 619/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 72.4997 - mae: 6.8627 - val_loss: 68.9515 - val_mae: 6.5376\n",
            "Epoch 620/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 72.6232 - mae: 6.8701 - val_loss: 68.0075 - val_mae: 6.5520\n",
            "Epoch 621/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 72.7448 - mae: 6.8641 - val_loss: 67.5937 - val_mae: 6.5325\n",
            "Epoch 622/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 71.5973 - mae: 6.7876 - val_loss: 67.1391 - val_mae: 6.5568\n",
            "Epoch 623/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 71.5666 - mae: 6.8116 - val_loss: 66.4984 - val_mae: 6.4817\n",
            "Epoch 624/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 72.0159 - mae: 6.8209 - val_loss: 69.3258 - val_mae: 6.4692\n",
            "Epoch 625/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 71.1370 - mae: 6.7941 - val_loss: 67.0830 - val_mae: 6.5312\n",
            "Epoch 626/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 72.0303 - mae: 6.8541 - val_loss: 66.0344 - val_mae: 6.3319\n",
            "Epoch 627/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 71.8871 - mae: 6.8162 - val_loss: 65.8299 - val_mae: 6.3877\n",
            "Epoch 628/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 70.3038 - mae: 6.7314 - val_loss: 65.7621 - val_mae: 6.5036\n",
            "Epoch 629/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 70.5601 - mae: 6.7741 - val_loss: 64.6328 - val_mae: 6.3440\n",
            "Epoch 630/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 68.5709 - mae: 6.6192 - val_loss: 68.0612 - val_mae: 6.5444\n",
            "Epoch 631/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 70.5528 - mae: 6.7863 - val_loss: 70.3977 - val_mae: 6.4534\n",
            "Epoch 632/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 72.6828 - mae: 6.7647 - val_loss: 68.5913 - val_mae: 6.8626\n",
            "Epoch 633/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 69.5775 - mae: 6.7414 - val_loss: 66.3184 - val_mae: 6.2647\n",
            "Epoch 634/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 70.1641 - mae: 6.6287 - val_loss: 68.4712 - val_mae: 6.7355\n",
            "Epoch 635/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 70.8559 - mae: 6.7587 - val_loss: 64.1466 - val_mae: 6.1709\n",
            "Epoch 636/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 68.2075 - mae: 6.5915 - val_loss: 67.6692 - val_mae: 6.5538\n",
            "Epoch 637/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 69.1777 - mae: 6.6796 - val_loss: 63.1544 - val_mae: 6.2854\n",
            "Epoch 638/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 65.7954 - mae: 6.4733 - val_loss: 60.6709 - val_mae: 6.1919\n",
            "Epoch 639/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 65.6343 - mae: 6.4859 - val_loss: 60.3656 - val_mae: 6.1651\n",
            "Epoch 640/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 65.0152 - mae: 6.4522 - val_loss: 61.5356 - val_mae: 6.1980\n",
            "Epoch 641/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 66.4022 - mae: 6.5932 - val_loss: 69.1211 - val_mae: 6.3362\n",
            "Epoch 642/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 72.8578 - mae: 6.6644 - val_loss: 69.5674 - val_mae: 6.8610\n",
            "Epoch 643/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 68.2242 - mae: 6.6342 - val_loss: 60.8498 - val_mae: 6.0226\n",
            "Epoch 644/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 63.9056 - mae: 6.4097 - val_loss: 59.7845 - val_mae: 6.1836\n",
            "Epoch 645/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 64.9267 - mae: 6.4258 - val_loss: 58.5272 - val_mae: 6.1275\n",
            "Epoch 646/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 65.6843 - mae: 6.5353 - val_loss: 60.9793 - val_mae: 6.0531\n",
            "Epoch 647/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 63.4984 - mae: 6.3556 - val_loss: 63.1408 - val_mae: 6.3439\n",
            "Epoch 648/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 64.3570 - mae: 6.3892 - val_loss: 59.9058 - val_mae: 6.0262\n",
            "Epoch 649/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 65.2664 - mae: 6.4890 - val_loss: 56.5763 - val_mae: 5.9295\n",
            "Epoch 650/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 62.5498 - mae: 6.3117 - val_loss: 57.3662 - val_mae: 6.0837\n",
            "Epoch 651/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 61.9896 - mae: 6.2987 - val_loss: 57.1809 - val_mae: 5.8628\n",
            "Epoch 652/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 62.1638 - mae: 6.3391 - val_loss: 55.6789 - val_mae: 5.8439\n",
            "Epoch 653/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 60.0500 - mae: 6.1432 - val_loss: 55.6511 - val_mae: 5.9131\n",
            "Epoch 654/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 59.7188 - mae: 6.1438 - val_loss: 55.1254 - val_mae: 5.9250\n",
            "Epoch 655/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 59.5599 - mae: 6.1494 - val_loss: 55.0876 - val_mae: 5.9691\n",
            "Epoch 656/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 59.3682 - mae: 6.1186 - val_loss: 54.2943 - val_mae: 5.8618\n",
            "Epoch 657/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 59.2817 - mae: 6.1519 - val_loss: 54.2562 - val_mae: 5.7072\n",
            "Epoch 658/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 58.5733 - mae: 6.0767 - val_loss: 53.9228 - val_mae: 5.7590\n",
            "Epoch 659/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 57.7332 - mae: 6.0344 - val_loss: 53.1194 - val_mae: 5.7529\n",
            "Epoch 660/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 58.0048 - mae: 6.0717 - val_loss: 54.4820 - val_mae: 5.7932\n",
            "Epoch 661/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 57.7554 - mae: 6.0950 - val_loss: 53.4042 - val_mae: 5.7518\n",
            "Epoch 662/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 57.0560 - mae: 5.9430 - val_loss: 53.6428 - val_mae: 5.9199\n",
            "Epoch 663/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 57.4192 - mae: 6.0900 - val_loss: 52.7842 - val_mae: 5.6302\n",
            "Epoch 664/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 56.9381 - mae: 5.9738 - val_loss: 51.9198 - val_mae: 5.7306\n",
            "Epoch 665/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 56.7473 - mae: 6.0128 - val_loss: 52.0087 - val_mae: 5.5561\n",
            "Epoch 666/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 56.0804 - mae: 5.9404 - val_loss: 51.5729 - val_mae: 5.6302\n",
            "Epoch 667/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 58.0871 - mae: 5.9949 - val_loss: 53.9922 - val_mae: 6.0177\n",
            "Epoch 668/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 56.8100 - mae: 6.0123 - val_loss: 50.5677 - val_mae: 5.5126\n",
            "Epoch 669/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 55.8451 - mae: 5.9774 - val_loss: 50.1080 - val_mae: 5.4716\n",
            "Epoch 670/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 55.3596 - mae: 5.9285 - val_loss: 50.0108 - val_mae: 5.6503\n",
            "Epoch 671/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 54.8979 - mae: 5.8821 - val_loss: 49.2683 - val_mae: 5.5162\n",
            "Epoch 672/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 54.8661 - mae: 5.9047 - val_loss: 49.2072 - val_mae: 5.5195\n",
            "Epoch 673/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 54.4134 - mae: 5.8525 - val_loss: 49.0892 - val_mae: 5.5679\n",
            "Epoch 674/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 53.3004 - mae: 5.7739 - val_loss: 49.0080 - val_mae: 5.5838\n",
            "Epoch 675/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 52.9108 - mae: 5.7816 - val_loss: 48.2868 - val_mae: 5.4720\n",
            "Epoch 676/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 52.3258 - mae: 5.7530 - val_loss: 49.6239 - val_mae: 5.6511\n",
            "Epoch 677/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 53.7730 - mae: 5.8416 - val_loss: 49.6940 - val_mae: 5.3759\n",
            "Epoch 678/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 53.8249 - mae: 5.8599 - val_loss: 49.4178 - val_mae: 5.6525\n",
            "Epoch 679/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 53.7143 - mae: 5.7680 - val_loss: 47.7780 - val_mae: 5.5201\n",
            "Epoch 680/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 51.7564 - mae: 5.7159 - val_loss: 46.9143 - val_mae: 5.3970\n",
            "Epoch 681/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 51.1469 - mae: 5.6836 - val_loss: 48.1787 - val_mae: 5.4833\n",
            "Epoch 682/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 51.7715 - mae: 5.7133 - val_loss: 48.0696 - val_mae: 5.3688\n",
            "Epoch 683/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 50.5454 - mae: 5.5707 - val_loss: 45.5878 - val_mae: 5.3079\n",
            "Epoch 684/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 50.2324 - mae: 5.5840 - val_loss: 45.6795 - val_mae: 5.3011\n",
            "Epoch 685/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 49.8234 - mae: 5.6146 - val_loss: 45.3110 - val_mae: 5.2376\n",
            "Epoch 686/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 50.8102 - mae: 5.5793 - val_loss: 46.4692 - val_mae: 5.4744\n",
            "Epoch 687/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 50.4683 - mae: 5.5822 - val_loss: 45.5279 - val_mae: 5.4113\n",
            "Epoch 688/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 49.4353 - mae: 5.5895 - val_loss: 45.3966 - val_mae: 5.1300\n",
            "Epoch 689/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 48.6282 - mae: 5.4227 - val_loss: 46.0102 - val_mae: 5.4453\n",
            "Epoch 690/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 50.6484 - mae: 5.5967 - val_loss: 43.8521 - val_mae: 5.2320\n",
            "Epoch 691/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 48.5571 - mae: 5.5158 - val_loss: 43.7368 - val_mae: 5.1141\n",
            "Epoch 692/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 47.8845 - mae: 5.4476 - val_loss: 43.5562 - val_mae: 5.1618\n",
            "Epoch 693/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 47.7758 - mae: 5.4813 - val_loss: 44.8985 - val_mae: 5.3049\n",
            "Epoch 694/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 48.3308 - mae: 5.5539 - val_loss: 43.8015 - val_mae: 5.1207\n",
            "Epoch 695/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 47.6945 - mae: 5.3766 - val_loss: 43.6927 - val_mae: 5.2903\n",
            "Epoch 696/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 47.8372 - mae: 5.5107 - val_loss: 43.5690 - val_mae: 4.9805\n",
            "Epoch 697/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 46.6543 - mae: 5.3681 - val_loss: 43.4432 - val_mae: 5.3025\n",
            "Epoch 698/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 46.5783 - mae: 5.3783 - val_loss: 42.1902 - val_mae: 5.1535\n",
            "Epoch 699/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 46.6264 - mae: 5.4260 - val_loss: 42.7925 - val_mae: 5.2019\n",
            "Epoch 700/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 47.5071 - mae: 5.5060 - val_loss: 42.7610 - val_mae: 5.0859\n",
            "Epoch 701/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 47.5092 - mae: 5.4567 - val_loss: 42.0676 - val_mae: 4.8801\n",
            "Epoch 702/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 45.4601 - mae: 5.2485 - val_loss: 40.6016 - val_mae: 5.0422\n",
            "Epoch 703/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 44.7267 - mae: 5.2816 - val_loss: 41.9278 - val_mae: 4.8978\n",
            "Epoch 704/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 45.7461 - mae: 5.3208 - val_loss: 39.7870 - val_mae: 4.9369\n",
            "Epoch 705/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 44.4280 - mae: 5.2335 - val_loss: 39.7970 - val_mae: 4.9782\n",
            "Epoch 706/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 44.6252 - mae: 5.3029 - val_loss: 40.2482 - val_mae: 4.9378\n",
            "Epoch 707/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 43.9858 - mae: 5.2494 - val_loss: 39.6575 - val_mae: 4.7870\n",
            "Epoch 708/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 44.8736 - mae: 5.2155 - val_loss: 39.5671 - val_mae: 5.0126\n",
            "Epoch 709/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 43.1258 - mae: 5.1127 - val_loss: 38.6132 - val_mae: 4.8319\n",
            "Epoch 710/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 42.9350 - mae: 5.1370 - val_loss: 38.5743 - val_mae: 4.7502\n",
            "Epoch 711/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 42.5850 - mae: 5.0947 - val_loss: 38.6075 - val_mae: 4.9417\n",
            "Epoch 712/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 42.1717 - mae: 5.1296 - val_loss: 38.0032 - val_mae: 4.7267\n",
            "Epoch 713/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 42.7809 - mae: 5.0634 - val_loss: 38.4717 - val_mae: 4.9377\n",
            "Epoch 714/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 41.1166 - mae: 5.0072 - val_loss: 38.0678 - val_mae: 4.7471\n",
            "Epoch 715/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 42.1335 - mae: 5.0880 - val_loss: 37.6132 - val_mae: 4.6997\n",
            "Epoch 716/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 41.1259 - mae: 5.0026 - val_loss: 38.1579 - val_mae: 4.9370\n",
            "Epoch 717/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 41.0086 - mae: 5.0364 - val_loss: 38.1125 - val_mae: 4.6248\n",
            "Epoch 718/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 40.9161 - mae: 4.9490 - val_loss: 36.0865 - val_mae: 4.6923\n",
            "Epoch 719/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 40.4950 - mae: 5.0049 - val_loss: 36.8708 - val_mae: 4.6404\n",
            "Epoch 720/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 40.1318 - mae: 4.9974 - val_loss: 37.6490 - val_mae: 4.9614\n",
            "Epoch 721/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 40.8711 - mae: 5.0910 - val_loss: 36.1362 - val_mae: 4.7047\n",
            "Epoch 722/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 40.4934 - mae: 4.9874 - val_loss: 35.5210 - val_mae: 4.7007\n",
            "Epoch 723/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 39.3583 - mae: 4.9086 - val_loss: 35.5492 - val_mae: 4.7307\n",
            "Epoch 724/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 39.3540 - mae: 4.9454 - val_loss: 35.9286 - val_mae: 4.5797\n",
            "Epoch 725/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 38.9706 - mae: 4.9110 - val_loss: 34.5970 - val_mae: 4.6192\n",
            "Epoch 726/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 38.5913 - mae: 4.8423 - val_loss: 34.2904 - val_mae: 4.5839\n",
            "Epoch 727/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 38.8501 - mae: 4.8754 - val_loss: 36.0648 - val_mae: 4.4657\n",
            "Epoch 728/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 39.1204 - mae: 4.8581 - val_loss: 34.4479 - val_mae: 4.6554\n",
            "Epoch 729/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 37.8856 - mae: 4.7676 - val_loss: 33.7634 - val_mae: 4.5804\n",
            "Epoch 730/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 38.1670 - mae: 4.8138 - val_loss: 33.7537 - val_mae: 4.4515\n",
            "Epoch 731/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 37.5097 - mae: 4.7954 - val_loss: 33.6389 - val_mae: 4.4046\n",
            "Epoch 732/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 37.5575 - mae: 4.6935 - val_loss: 33.7590 - val_mae: 4.6120\n",
            "Epoch 733/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 36.9928 - mae: 4.7108 - val_loss: 32.5199 - val_mae: 4.4215\n",
            "Epoch 734/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 36.1189 - mae: 4.6826 - val_loss: 32.6641 - val_mae: 4.3667\n",
            "Epoch 735/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 36.9084 - mae: 4.6108 - val_loss: 34.9885 - val_mae: 4.7549\n",
            "Epoch 736/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 36.5408 - mae: 4.7119 - val_loss: 32.4871 - val_mae: 4.3499\n",
            "Epoch 737/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 35.4947 - mae: 4.6613 - val_loss: 31.6078 - val_mae: 4.3705\n",
            "Epoch 738/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 35.6455 - mae: 4.6115 - val_loss: 31.6906 - val_mae: 4.4395\n",
            "Epoch 739/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 35.2386 - mae: 4.6446 - val_loss: 31.7384 - val_mae: 4.2710\n",
            "Epoch 740/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 34.6916 - mae: 4.5743 - val_loss: 30.6337 - val_mae: 4.2945\n",
            "Epoch 741/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 34.1949 - mae: 4.5092 - val_loss: 30.6775 - val_mae: 4.3235\n",
            "Epoch 742/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 34.5230 - mae: 4.5688 - val_loss: 31.2450 - val_mae: 4.1676\n",
            "Epoch 743/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 34.4621 - mae: 4.4924 - val_loss: 29.8853 - val_mae: 4.2319\n",
            "Epoch 744/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 33.4340 - mae: 4.4626 - val_loss: 30.0515 - val_mae: 4.2851\n",
            "Epoch 745/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 32.8018 - mae: 4.4243 - val_loss: 29.7233 - val_mae: 4.1025\n",
            "Epoch 746/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 33.5514 - mae: 4.4253 - val_loss: 29.4814 - val_mae: 4.2003\n",
            "Epoch 747/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 32.3778 - mae: 4.3011 - val_loss: 28.7684 - val_mae: 4.1224\n",
            "Epoch 748/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 32.5546 - mae: 4.4068 - val_loss: 31.0927 - val_mae: 4.0731\n",
            "Epoch 749/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 34.5945 - mae: 4.3984 - val_loss: 28.2158 - val_mae: 4.0360\n",
            "Epoch 750/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 32.3754 - mae: 4.2751 - val_loss: 30.6504 - val_mae: 4.3716\n",
            "Epoch 751/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 32.2772 - mae: 4.3259 - val_loss: 29.2039 - val_mae: 3.9286\n",
            "Epoch 752/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 31.1532 - mae: 4.2341 - val_loss: 27.5406 - val_mae: 4.0296\n",
            "Epoch 753/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 30.2268 - mae: 4.1222 - val_loss: 27.3168 - val_mae: 3.8263\n",
            "Epoch 754/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 30.7667 - mae: 4.1583 - val_loss: 26.6333 - val_mae: 3.8768\n",
            "Epoch 755/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 29.7434 - mae: 4.0606 - val_loss: 26.2567 - val_mae: 3.8591\n",
            "Epoch 756/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 29.1072 - mae: 4.0148 - val_loss: 26.2435 - val_mae: 3.7479\n",
            "Epoch 757/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 29.2608 - mae: 4.0277 - val_loss: 25.4686 - val_mae: 3.7393\n",
            "Epoch 758/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 29.2103 - mae: 4.0032 - val_loss: 27.1966 - val_mae: 4.0070\n",
            "Epoch 759/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 29.6938 - mae: 4.0470 - val_loss: 26.6478 - val_mae: 3.6990\n",
            "Epoch 760/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 29.4755 - mae: 4.0125 - val_loss: 26.1984 - val_mae: 3.6620\n",
            "Epoch 761/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 30.6831 - mae: 4.0958 - val_loss: 24.5852 - val_mae: 3.6987\n",
            "Epoch 762/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 29.4373 - mae: 3.9687 - val_loss: 25.1548 - val_mae: 3.7765\n",
            "Epoch 763/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.3848 - mae: 3.8331 - val_loss: 24.3860 - val_mae: 3.6865\n",
            "Epoch 764/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 27.6060 - mae: 3.8673 - val_loss: 23.9984 - val_mae: 3.5305\n",
            "Epoch 765/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 26.2387 - mae: 3.7538 - val_loss: 23.6569 - val_mae: 3.5246\n",
            "Epoch 766/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 26.1259 - mae: 3.7905 - val_loss: 23.4195 - val_mae: 3.6413\n",
            "Epoch 767/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 26.4520 - mae: 3.8336 - val_loss: 22.7933 - val_mae: 3.4701\n",
            "Epoch 768/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 25.6935 - mae: 3.7463 - val_loss: 22.4415 - val_mae: 3.4265\n",
            "Epoch 769/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 24.7429 - mae: 3.6451 - val_loss: 24.2028 - val_mae: 3.7159\n",
            "Epoch 770/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 26.3002 - mae: 3.7235 - val_loss: 21.8926 - val_mae: 3.3633\n",
            "Epoch 771/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 24.4949 - mae: 3.6248 - val_loss: 21.8358 - val_mae: 3.4070\n",
            "Epoch 772/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 24.0865 - mae: 3.5593 - val_loss: 21.4160 - val_mae: 3.3599\n",
            "Epoch 773/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 24.1061 - mae: 3.5928 - val_loss: 22.6949 - val_mae: 3.3713\n",
            "Epoch 774/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 24.1880 - mae: 3.5728 - val_loss: 20.8917 - val_mae: 3.2878\n",
            "Epoch 775/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 23.0611 - mae: 3.4828 - val_loss: 20.6348 - val_mae: 3.2524\n",
            "Epoch 776/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 22.8166 - mae: 3.4508 - val_loss: 20.2751 - val_mae: 3.2402\n",
            "Epoch 777/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 22.4216 - mae: 3.4088 - val_loss: 20.1696 - val_mae: 3.2404\n",
            "Epoch 778/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 22.7966 - mae: 3.4813 - val_loss: 22.3520 - val_mae: 3.3413\n",
            "Epoch 779/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 23.4886 - mae: 3.5340 - val_loss: 20.0250 - val_mae: 3.2519\n",
            "Epoch 780/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 22.3098 - mae: 3.3878 - val_loss: 20.1088 - val_mae: 3.2310\n",
            "Epoch 781/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 21.1397 - mae: 3.2993 - val_loss: 19.6501 - val_mae: 3.1034\n",
            "Epoch 782/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 21.0810 - mae: 3.2755 - val_loss: 19.4652 - val_mae: 3.2251\n",
            "Epoch 783/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 21.4899 - mae: 3.3281 - val_loss: 18.5038 - val_mae: 3.0352\n",
            "Epoch 784/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 20.5194 - mae: 3.2349 - val_loss: 19.2099 - val_mae: 3.0329\n",
            "Epoch 785/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 21.9538 - mae: 3.3514 - val_loss: 22.5749 - val_mae: 3.5138\n",
            "Epoch 786/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 21.1748 - mae: 3.3285 - val_loss: 19.3522 - val_mae: 3.1441\n",
            "Epoch 787/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 20.0818 - mae: 3.1965 - val_loss: 17.6305 - val_mae: 2.9541\n",
            "Epoch 788/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 19.5661 - mae: 3.1311 - val_loss: 18.2340 - val_mae: 3.0656\n",
            "Epoch 789/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 20.2641 - mae: 3.2204 - val_loss: 16.9681 - val_mae: 2.9078\n",
            "Epoch 790/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 18.6860 - mae: 3.0700 - val_loss: 16.9072 - val_mae: 2.8671\n",
            "Epoch 791/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 18.5808 - mae: 3.0616 - val_loss: 16.4026 - val_mae: 2.8537\n",
            "Epoch 792/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 18.1103 - mae: 3.0193 - val_loss: 16.1392 - val_mae: 2.8049\n",
            "Epoch 793/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 17.7877 - mae: 2.9809 - val_loss: 15.9596 - val_mae: 2.7998\n",
            "Epoch 794/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 17.7061 - mae: 2.9948 - val_loss: 16.2552 - val_mae: 2.8909\n",
            "Epoch 795/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 17.5400 - mae: 2.9591 - val_loss: 15.4207 - val_mae: 2.7636\n",
            "Epoch 796/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 17.1661 - mae: 2.9157 - val_loss: 15.7318 - val_mae: 2.7339\n",
            "Epoch 797/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 17.0562 - mae: 2.9139 - val_loss: 15.6588 - val_mae: 2.7989\n",
            "Epoch 798/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 16.6319 - mae: 2.8752 - val_loss: 14.7441 - val_mae: 2.6933\n",
            "Epoch 799/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 16.8307 - mae: 2.8641 - val_loss: 14.6578 - val_mae: 2.6683\n",
            "Epoch 800/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 15.9310 - mae: 2.8307 - val_loss: 14.1635 - val_mae: 2.6300\n",
            "Epoch 801/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 15.8607 - mae: 2.7990 - val_loss: 14.3729 - val_mae: 2.6083\n",
            "Epoch 802/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 15.6534 - mae: 2.7901 - val_loss: 13.8171 - val_mae: 2.5850\n",
            "Epoch 803/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 15.3009 - mae: 2.7537 - val_loss: 14.6882 - val_mae: 2.7661\n",
            "Epoch 804/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 15.1971 - mae: 2.8141 - val_loss: 13.5770 - val_mae: 2.6105\n",
            "Epoch 805/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 14.8222 - mae: 2.7421 - val_loss: 13.5858 - val_mae: 2.5351\n",
            "Epoch 806/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 14.8996 - mae: 2.7143 - val_loss: 13.1247 - val_mae: 2.5159\n",
            "Epoch 807/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 14.2108 - mae: 2.6489 - val_loss: 12.7386 - val_mae: 2.4901\n",
            "Epoch 808/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 13.9180 - mae: 2.6180 - val_loss: 12.7154 - val_mae: 2.5055\n",
            "Epoch 809/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 14.8099 - mae: 2.6889 - val_loss: 12.1984 - val_mae: 2.4314\n",
            "Epoch 810/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 15.1386 - mae: 2.6808 - val_loss: 13.4005 - val_mae: 2.5208\n",
            "Epoch 811/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 14.0567 - mae: 2.6253 - val_loss: 14.0733 - val_mae: 2.6427\n",
            "Epoch 812/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 16.1733 - mae: 2.8174 - val_loss: 11.8438 - val_mae: 2.3782\n",
            "Epoch 813/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 13.8864 - mae: 2.6104 - val_loss: 11.3661 - val_mae: 2.3422\n",
            "Epoch 814/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.6511 - mae: 2.4897 - val_loss: 11.2577 - val_mae: 2.3663\n",
            "Epoch 815/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.3796 - mae: 2.4804 - val_loss: 10.9254 - val_mae: 2.3068\n",
            "Epoch 816/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.4713 - mae: 2.4354 - val_loss: 12.9293 - val_mae: 2.6223\n",
            "Epoch 817/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 13.6990 - mae: 2.5749 - val_loss: 10.7888 - val_mae: 2.3010\n",
            "Epoch 818/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 12.7567 - mae: 2.5144 - val_loss: 12.0528 - val_mae: 2.3549\n",
            "Epoch 819/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 11.6885 - mae: 2.4334 - val_loss: 10.4025 - val_mae: 2.2824\n",
            "Epoch 820/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 12.4034 - mae: 2.4562 - val_loss: 12.7163 - val_mae: 2.5914\n",
            "Epoch 821/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 12.2969 - mae: 2.4437 - val_loss: 10.0790 - val_mae: 2.2430\n",
            "Epoch 822/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.8651 - mae: 2.2812 - val_loss: 9.5633 - val_mae: 2.1439\n",
            "Epoch 823/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 10.5485 - mae: 2.2566 - val_loss: 10.4534 - val_mae: 2.1763\n",
            "Epoch 824/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.6639 - mae: 2.2624 - val_loss: 9.2321 - val_mae: 2.1085\n",
            "Epoch 825/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 10.2526 - mae: 2.2217 - val_loss: 9.0857 - val_mae: 2.0678\n",
            "Epoch 826/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 10.2409 - mae: 2.2398 - val_loss: 8.9418 - val_mae: 2.1158\n",
            "Epoch 827/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.9314 - mae: 2.2301 - val_loss: 8.6392 - val_mae: 2.0238\n",
            "Epoch 828/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.6133 - mae: 2.1644 - val_loss: 8.8379 - val_mae: 2.0534\n",
            "Epoch 829/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.6919 - mae: 2.1457 - val_loss: 8.5144 - val_mae: 1.9974\n",
            "Epoch 830/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 9.5698 - mae: 2.1406 - val_loss: 8.1585 - val_mae: 1.9747\n",
            "Epoch 831/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.4558 - mae: 2.1161 - val_loss: 10.5834 - val_mae: 2.3319\n",
            "Epoch 832/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.5129 - mae: 2.1745 - val_loss: 7.8368 - val_mae: 1.9552\n",
            "Epoch 833/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.9357 - mae: 2.0635 - val_loss: 7.7137 - val_mae: 1.9053\n",
            "Epoch 834/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 8.5535 - mae: 2.0371 - val_loss: 7.7574 - val_mae: 1.9417\n",
            "Epoch 835/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.6639 - mae: 2.0398 - val_loss: 7.8211 - val_mae: 1.9686\n",
            "Epoch 836/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 9.1077 - mae: 2.0320 - val_loss: 8.8184 - val_mae: 2.0519\n",
            "Epoch 837/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 8.8710 - mae: 2.0780 - val_loss: 9.0403 - val_mae: 2.1469\n",
            "Epoch 838/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 8.5403 - mae: 2.0848 - val_loss: 7.8599 - val_mae: 1.9108\n",
            "Epoch 839/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.9557 - mae: 1.9712 - val_loss: 7.2130 - val_mae: 1.7971\n",
            "Epoch 840/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.7203 - mae: 1.9051 - val_loss: 6.6483 - val_mae: 1.7394\n",
            "Epoch 841/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 7.1887 - mae: 1.8435 - val_loss: 6.5685 - val_mae: 1.7520\n",
            "Epoch 842/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 7.0174 - mae: 1.8058 - val_loss: 6.6031 - val_mae: 1.8661\n",
            "Epoch 843/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 7.0742 - mae: 1.8892 - val_loss: 6.2854 - val_mae: 1.7824\n",
            "Epoch 844/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.9097 - mae: 1.8511 - val_loss: 6.4060 - val_mae: 1.7933\n",
            "Epoch 845/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.8062 - mae: 1.8722 - val_loss: 6.2633 - val_mae: 1.7948\n",
            "Epoch 846/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.6057 - mae: 1.8189 - val_loss: 6.1127 - val_mae: 1.8045\n",
            "Epoch 847/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 6.4770 - mae: 1.7714 - val_loss: 5.6835 - val_mae: 1.6685\n",
            "Epoch 848/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.1884 - mae: 1.7156 - val_loss: 5.5609 - val_mae: 1.6189\n",
            "Epoch 849/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0500 - mae: 1.6560 - val_loss: 5.7345 - val_mae: 1.6366\n",
            "Epoch 850/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 6.7056 - mae: 1.7906 - val_loss: 5.2318 - val_mae: 1.5581\n",
            "Epoch 851/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 6.1677 - mae: 1.7260 - val_loss: 6.0950 - val_mae: 1.6559\n",
            "Epoch 852/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 6.0026 - mae: 1.6767 - val_loss: 5.2708 - val_mae: 1.5142\n",
            "Epoch 853/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.9104 - mae: 1.6302 - val_loss: 4.9690 - val_mae: 1.5363\n",
            "Epoch 854/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 5.7040 - mae: 1.6281 - val_loss: 4.9315 - val_mae: 1.5044\n",
            "Epoch 855/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 5.4469 - mae: 1.5958 - val_loss: 5.5680 - val_mae: 1.6641\n",
            "Epoch 856/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.2703 - mae: 1.5830 - val_loss: 4.6436 - val_mae: 1.4268\n",
            "Epoch 857/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 5.1424 - mae: 1.5464 - val_loss: 5.0694 - val_mae: 1.5240\n",
            "Epoch 858/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 5.0208 - mae: 1.5159 - val_loss: 4.2847 - val_mae: 1.3697\n",
            "Epoch 859/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.9589 - mae: 1.5112 - val_loss: 4.3819 - val_mae: 1.4454\n",
            "Epoch 860/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.6619 - mae: 1.4560 - val_loss: 4.1979 - val_mae: 1.3944\n",
            "Epoch 861/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.7055 - mae: 1.5079 - val_loss: 4.1429 - val_mae: 1.4423\n",
            "Epoch 862/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.5258 - mae: 1.4748 - val_loss: 3.9298 - val_mae: 1.3195\n",
            "Epoch 863/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.5447 - mae: 1.4677 - val_loss: 4.6155 - val_mae: 1.4219\n",
            "Epoch 864/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 4.4515 - mae: 1.4266 - val_loss: 4.2305 - val_mae: 1.3654\n",
            "Epoch 865/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.5396 - mae: 1.4742 - val_loss: 3.5637 - val_mae: 1.2407\n",
            "Epoch 866/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 4.0692 - mae: 1.3501 - val_loss: 3.5367 - val_mae: 1.2224\n",
            "Epoch 867/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.8216 - mae: 1.2807 - val_loss: 3.3918 - val_mae: 1.2130\n",
            "Epoch 868/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.9977 - mae: 1.3388 - val_loss: 3.2877 - val_mae: 1.2106\n",
            "Epoch 869/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.7318 - mae: 1.3040 - val_loss: 3.2877 - val_mae: 1.1788\n",
            "Epoch 870/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.5925 - mae: 1.2627 - val_loss: 3.1202 - val_mae: 1.1500\n",
            "Epoch 871/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.3958 - mae: 1.2154 - val_loss: 3.0378 - val_mae: 1.1364\n",
            "Epoch 872/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.3305 - mae: 1.2022 - val_loss: 2.9976 - val_mae: 1.1515\n",
            "Epoch 873/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3692 - mae: 1.2679 - val_loss: 2.9935 - val_mae: 1.1625\n",
            "Epoch 874/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.2201 - mae: 1.2172 - val_loss: 2.9827 - val_mae: 1.1817\n",
            "Epoch 875/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.4121 - mae: 1.2821 - val_loss: 2.8186 - val_mae: 1.1422\n",
            "Epoch 876/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.0699 - mae: 1.1609 - val_loss: 2.7435 - val_mae: 1.1153\n",
            "Epoch 877/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.3259 - mae: 1.2193 - val_loss: 2.6363 - val_mae: 1.0936\n",
            "Epoch 878/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 3.0422 - mae: 1.1587 - val_loss: 2.5937 - val_mae: 1.0278\n",
            "Epoch 879/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.0838 - mae: 1.1538 - val_loss: 2.8799 - val_mae: 1.1254\n",
            "Epoch 880/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.5625 - mae: 1.3024 - val_loss: 2.5433 - val_mae: 1.0146\n",
            "Epoch 881/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 3.1052 - mae: 1.2000 - val_loss: 2.3285 - val_mae: 1.0265\n",
            "Epoch 882/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 3.1079 - mae: 1.2577 - val_loss: 2.4865 - val_mae: 1.1271\n",
            "Epoch 883/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5403 - mae: 1.0665 - val_loss: 2.2706 - val_mae: 1.0348\n",
            "Epoch 884/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.4320 - mae: 1.0469 - val_loss: 2.1627 - val_mae: 0.9830\n",
            "Epoch 885/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.3137 - mae: 1.0014 - val_loss: 2.0576 - val_mae: 0.9507\n",
            "Epoch 886/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 2.3788 - mae: 1.0149 - val_loss: 2.0015 - val_mae: 0.9176\n",
            "Epoch 887/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.3343 - mae: 1.0207 - val_loss: 2.0407 - val_mae: 0.9617\n",
            "Epoch 888/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 2.2541 - mae: 0.9765 - val_loss: 2.0161 - val_mae: 0.9197\n",
            "Epoch 889/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.6133 - mae: 1.1225 - val_loss: 1.8552 - val_mae: 0.8760\n",
            "Epoch 890/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.1385 - mae: 0.9746 - val_loss: 2.0027 - val_mae: 1.0090\n",
            "Epoch 891/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.1955 - mae: 0.9826 - val_loss: 2.0847 - val_mae: 0.9587\n",
            "Epoch 892/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 2.2871 - mae: 1.0771 - val_loss: 1.8717 - val_mae: 0.8660\n",
            "Epoch 893/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 2.1540 - mae: 0.9926 - val_loss: 1.6931 - val_mae: 0.8199\n",
            "Epoch 894/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.2337 - mae: 1.0387 - val_loss: 1.7010 - val_mae: 0.9235\n",
            "Epoch 895/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.9402 - mae: 0.9332 - val_loss: 1.5754 - val_mae: 0.8083\n",
            "Epoch 896/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8890 - mae: 0.9385 - val_loss: 1.6759 - val_mae: 0.8396\n",
            "Epoch 897/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7540 - mae: 0.9131 - val_loss: 1.7370 - val_mae: 0.9801\n",
            "Epoch 898/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.6992 - mae: 0.9058 - val_loss: 1.4404 - val_mae: 0.7664\n",
            "Epoch 899/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.6967 - mae: 0.8692 - val_loss: 1.7363 - val_mae: 0.9779\n",
            "Epoch 900/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6916 - mae: 0.8854 - val_loss: 1.6392 - val_mae: 0.9262\n",
            "Epoch 901/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6200 - mae: 0.8448 - val_loss: 1.6048 - val_mae: 0.9277\n",
            "Epoch 902/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.7254 - mae: 0.8849 - val_loss: 1.8423 - val_mae: 1.0138\n",
            "Epoch 903/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8103 - mae: 0.9312 - val_loss: 1.2750 - val_mae: 0.7089\n",
            "Epoch 904/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.3996 - mae: 0.7980 - val_loss: 1.2546 - val_mae: 0.7963\n",
            "Epoch 905/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3450 - mae: 0.7671 - val_loss: 1.3447 - val_mae: 0.7226\n",
            "Epoch 906/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.4574 - mae: 0.8113 - val_loss: 1.1204 - val_mae: 0.6775\n",
            "Epoch 907/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3099 - mae: 0.7544 - val_loss: 1.1226 - val_mae: 0.6366\n",
            "Epoch 908/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2692 - mae: 0.7325 - val_loss: 1.1743 - val_mae: 0.6868\n",
            "Epoch 909/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 1.2010 - mae: 0.7510 - val_loss: 1.0269 - val_mae: 0.6676\n",
            "Epoch 910/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1936 - mae: 0.7146 - val_loss: 1.0150 - val_mae: 0.6510\n",
            "Epoch 911/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1751 - mae: 0.6877 - val_loss: 1.0614 - val_mae: 0.7523\n",
            "Epoch 912/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.1103 - mae: 0.7255 - val_loss: 0.9556 - val_mae: 0.5895\n",
            "Epoch 913/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1352 - mae: 0.7433 - val_loss: 1.0312 - val_mae: 0.6945\n",
            "Epoch 914/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.1127 - mae: 0.7263 - val_loss: 0.9875 - val_mae: 0.7168\n",
            "Epoch 915/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.0815 - mae: 0.7180 - val_loss: 1.0781 - val_mae: 0.7573\n",
            "Epoch 916/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.0475 - mae: 0.6906 - val_loss: 0.8859 - val_mae: 0.6841\n",
            "Epoch 917/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9789 - mae: 0.6872 - val_loss: 0.8390 - val_mae: 0.6277\n",
            "Epoch 918/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9515 - mae: 0.6575 - val_loss: 0.8223 - val_mae: 0.6368\n",
            "Epoch 919/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.9472 - mae: 0.6672 - val_loss: 0.8547 - val_mae: 0.6723\n",
            "Epoch 920/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.9662 - mae: 0.6991 - val_loss: 0.7427 - val_mae: 0.5650\n",
            "Epoch 921/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8723 - mae: 0.6202 - val_loss: 0.7494 - val_mae: 0.5725\n",
            "Epoch 922/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8878 - mae: 0.6709 - val_loss: 0.8169 - val_mae: 0.6089\n",
            "Epoch 923/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.0427 - mae: 0.7444 - val_loss: 0.7644 - val_mae: 0.5350\n",
            "Epoch 924/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8485 - mae: 0.6477 - val_loss: 0.7782 - val_mae: 0.6056\n",
            "Epoch 925/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8615 - mae: 0.6797 - val_loss: 0.9184 - val_mae: 0.6980\n",
            "Epoch 926/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8589 - mae: 0.6469 - val_loss: 0.7191 - val_mae: 0.6186\n",
            "Epoch 927/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7980 - mae: 0.6676 - val_loss: 0.6566 - val_mae: 0.5433\n",
            "Epoch 928/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7902 - mae: 0.6157 - val_loss: 0.6432 - val_mae: 0.5102\n",
            "Epoch 929/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.7488 - mae: 0.6526 - val_loss: 0.5753 - val_mae: 0.4999\n",
            "Epoch 930/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7554 - mae: 0.6125 - val_loss: 0.6894 - val_mae: 0.5606\n",
            "Epoch 931/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7292 - mae: 0.6050 - val_loss: 0.6082 - val_mae: 0.5500\n",
            "Epoch 932/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6699 - mae: 0.5553 - val_loss: 0.5593 - val_mae: 0.5252\n",
            "Epoch 933/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6472 - mae: 0.5767 - val_loss: 0.5139 - val_mae: 0.4771\n",
            "Epoch 934/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6342 - mae: 0.5468 - val_loss: 0.5590 - val_mae: 0.5058\n",
            "Epoch 935/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6025 - mae: 0.5322 - val_loss: 0.5165 - val_mae: 0.4777\n",
            "Epoch 936/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6149 - mae: 0.5486 - val_loss: 0.5455 - val_mae: 0.5775\n",
            "Epoch 937/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6318 - mae: 0.5671 - val_loss: 0.6882 - val_mae: 0.6267\n",
            "Epoch 938/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.6058 - mae: 0.5561 - val_loss: 0.5267 - val_mae: 0.5571\n",
            "Epoch 939/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5731 - mae: 0.5363 - val_loss: 0.4933 - val_mae: 0.5007\n",
            "Epoch 940/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5594 - mae: 0.5324 - val_loss: 0.4323 - val_mae: 0.4492\n",
            "Epoch 941/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5237 - mae: 0.5212 - val_loss: 0.4505 - val_mae: 0.4777\n",
            "Epoch 942/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5545 - mae: 0.5637 - val_loss: 0.4774 - val_mae: 0.4865\n",
            "Epoch 943/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5195 - mae: 0.5216 - val_loss: 0.4432 - val_mae: 0.4551\n",
            "Epoch 944/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5768 - mae: 0.5239 - val_loss: 0.4961 - val_mae: 0.5526\n",
            "Epoch 945/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5206 - mae: 0.5320 - val_loss: 0.5292 - val_mae: 0.5805\n",
            "Epoch 946/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5151 - mae: 0.5363 - val_loss: 0.4944 - val_mae: 0.5625\n",
            "Epoch 947/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4710 - mae: 0.4862 - val_loss: 0.3878 - val_mae: 0.4428\n",
            "Epoch 948/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4365 - mae: 0.4564 - val_loss: 0.3780 - val_mae: 0.4181\n",
            "Epoch 949/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4705 - mae: 0.4863 - val_loss: 0.4467 - val_mae: 0.4767\n",
            "Epoch 950/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4557 - mae: 0.5050 - val_loss: 0.4186 - val_mae: 0.4734\n",
            "Epoch 951/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5020 - mae: 0.5387 - val_loss: 0.3532 - val_mae: 0.4220\n",
            "Epoch 952/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4064 - mae: 0.4702 - val_loss: 0.3123 - val_mae: 0.4001\n",
            "Epoch 953/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4282 - mae: 0.4722 - val_loss: 0.5040 - val_mae: 0.4936\n",
            "Epoch 954/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4959 - mae: 0.5202 - val_loss: 0.3885 - val_mae: 0.4594\n",
            "Epoch 955/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4249 - mae: 0.4831 - val_loss: 0.3121 - val_mae: 0.3919\n",
            "Epoch 956/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4007 - mae: 0.4426 - val_loss: 0.3264 - val_mae: 0.4257\n",
            "Epoch 957/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.3609 - mae: 0.4227 - val_loss: 0.2771 - val_mae: 0.3703\n",
            "Epoch 958/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3531 - mae: 0.4227 - val_loss: 0.2897 - val_mae: 0.3900\n",
            "Epoch 959/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3637 - mae: 0.4225 - val_loss: 0.2812 - val_mae: 0.3916\n",
            "Epoch 960/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3476 - mae: 0.4220 - val_loss: 0.2608 - val_mae: 0.3662\n",
            "Epoch 961/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3566 - mae: 0.4353 - val_loss: 0.2729 - val_mae: 0.3836\n",
            "Epoch 962/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3522 - mae: 0.4223 - val_loss: 0.2732 - val_mae: 0.3874\n",
            "Epoch 963/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3357 - mae: 0.4183 - val_loss: 0.2856 - val_mae: 0.4003\n",
            "Epoch 964/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3396 - mae: 0.4244 - val_loss: 0.2812 - val_mae: 0.3885\n",
            "Epoch 965/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3588 - mae: 0.4515 - val_loss: 0.2485 - val_mae: 0.3562\n",
            "Epoch 966/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3387 - mae: 0.4200 - val_loss: 0.2869 - val_mae: 0.3932\n",
            "Epoch 967/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3203 - mae: 0.4039 - val_loss: 0.2867 - val_mae: 0.4065\n",
            "Epoch 968/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3256 - mae: 0.4336 - val_loss: 0.3896 - val_mae: 0.5135\n",
            "Epoch 969/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.3801 - mae: 0.4769 - val_loss: 0.3365 - val_mae: 0.4654\n",
            "Epoch 970/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3606 - mae: 0.4739 - val_loss: 0.2609 - val_mae: 0.3978\n",
            "Epoch 971/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4555 - mae: 0.5158 - val_loss: 0.3403 - val_mae: 0.4476\n",
            "Epoch 972/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4144 - mae: 0.4872 - val_loss: 0.2241 - val_mae: 0.3544\n",
            "Epoch 973/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3007 - mae: 0.4071 - val_loss: 0.2408 - val_mae: 0.3671\n",
            "Epoch 974/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3161 - mae: 0.4152 - val_loss: 0.2617 - val_mae: 0.3973\n",
            "Epoch 975/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3161 - mae: 0.4310 - val_loss: 0.3315 - val_mae: 0.4435\n",
            "Epoch 976/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3471 - mae: 0.4511 - val_loss: 0.3839 - val_mae: 0.5030\n",
            "Epoch 977/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3164 - mae: 0.4286 - val_loss: 0.2239 - val_mae: 0.3698\n",
            "Epoch 978/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2885 - mae: 0.4017 - val_loss: 0.2234 - val_mae: 0.3632\n",
            "Epoch 979/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2798 - mae: 0.3864 - val_loss: 0.1882 - val_mae: 0.3213\n",
            "Epoch 980/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2609 - mae: 0.3704 - val_loss: 0.1973 - val_mae: 0.3383\n",
            "Epoch 981/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2632 - mae: 0.3716 - val_loss: 0.2478 - val_mae: 0.3913\n",
            "Epoch 982/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2922 - mae: 0.4102 - val_loss: 0.2401 - val_mae: 0.3852\n",
            "Epoch 983/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2953 - mae: 0.4101 - val_loss: 0.2618 - val_mae: 0.4075\n",
            "Epoch 984/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2831 - mae: 0.3986 - val_loss: 0.1894 - val_mae: 0.3289\n",
            "Epoch 985/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2741 - mae: 0.3913 - val_loss: 0.2384 - val_mae: 0.3824\n",
            "Epoch 986/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2536 - mae: 0.3614 - val_loss: 0.1787 - val_mae: 0.3138\n",
            "Epoch 987/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2531 - mae: 0.3546 - val_loss: 0.2086 - val_mae: 0.3580\n",
            "Epoch 988/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2452 - mae: 0.3531 - val_loss: 0.1689 - val_mae: 0.3058\n",
            "Epoch 989/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2507 - mae: 0.3568 - val_loss: 0.1972 - val_mae: 0.3365\n",
            "Epoch 990/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2666 - mae: 0.3769 - val_loss: 0.1916 - val_mae: 0.3421\n",
            "Epoch 991/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2822 - mae: 0.3999 - val_loss: 0.2208 - val_mae: 0.3675\n",
            "Epoch 992/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2719 - mae: 0.3913 - val_loss: 0.1957 - val_mae: 0.3363\n",
            "Epoch 993/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2491 - mae: 0.3748 - val_loss: 0.2106 - val_mae: 0.3651\n",
            "Epoch 994/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2829 - mae: 0.4019 - val_loss: 0.2188 - val_mae: 0.3732\n",
            "Epoch 995/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3598 - mae: 0.4529 - val_loss: 0.3257 - val_mae: 0.4333\n",
            "Epoch 996/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3102 - mae: 0.4224 - val_loss: 0.1581 - val_mae: 0.3051\n",
            "Epoch 997/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2696 - mae: 0.3826 - val_loss: 0.1643 - val_mae: 0.3054\n",
            "Epoch 998/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2325 - mae: 0.3504 - val_loss: 0.1473 - val_mae: 0.2867\n",
            "Epoch 999/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2197 - mae: 0.3232 - val_loss: 0.1875 - val_mae: 0.3287\n",
            "Epoch 1000/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2459 - mae: 0.3709 - val_loss: 0.1784 - val_mae: 0.3259\n",
            "Epoch 1001/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2481 - mae: 0.3719 - val_loss: 0.1932 - val_mae: 0.3410\n",
            "Epoch 1002/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2502 - mae: 0.3755 - val_loss: 0.1559 - val_mae: 0.2968\n",
            "Epoch 1003/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2245 - mae: 0.3414 - val_loss: 0.1811 - val_mae: 0.3385\n",
            "Epoch 1004/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2318 - mae: 0.3562 - val_loss: 0.1678 - val_mae: 0.3244\n",
            "Epoch 1005/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2622 - mae: 0.3851 - val_loss: 0.1420 - val_mae: 0.2835\n",
            "Epoch 1006/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2599 - mae: 0.3775 - val_loss: 0.2197 - val_mae: 0.3733\n",
            "Epoch 1007/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2538 - mae: 0.3891 - val_loss: 0.1536 - val_mae: 0.3076\n",
            "Epoch 1008/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2212 - mae: 0.3400 - val_loss: 0.1559 - val_mae: 0.3051\n",
            "Epoch 1009/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2181 - mae: 0.3333 - val_loss: 0.1768 - val_mae: 0.3266\n",
            "Epoch 1010/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2207 - mae: 0.3412 - val_loss: 0.1642 - val_mae: 0.3116\n",
            "Epoch 1011/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2109 - mae: 0.3294 - val_loss: 0.1494 - val_mae: 0.3005\n",
            "Epoch 1012/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2122 - mae: 0.3302 - val_loss: 0.2004 - val_mae: 0.3584\n",
            "Epoch 1013/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2389 - mae: 0.3699 - val_loss: 0.1703 - val_mae: 0.3395\n",
            "Epoch 1014/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2776 - mae: 0.4116 - val_loss: 0.1460 - val_mae: 0.3008\n",
            "Epoch 1015/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3324 - mae: 0.4209 - val_loss: 0.3933 - val_mae: 0.4835\n",
            "Epoch 1016/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6148 - mae: 0.5967 - val_loss: 0.3588 - val_mae: 0.4316\n",
            "Epoch 1017/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5231 - mae: 0.5285 - val_loss: 0.6989 - val_mae: 0.5760\n",
            "Epoch 1018/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.5044 - mae: 0.5136 - val_loss: 0.1850 - val_mae: 0.3336\n",
            "Epoch 1019/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2909 - mae: 0.4119 - val_loss: 0.3084 - val_mae: 0.4339\n",
            "Epoch 1020/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3448 - mae: 0.4322 - val_loss: 0.2855 - val_mae: 0.4021\n",
            "Epoch 1021/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3139 - mae: 0.4130 - val_loss: 0.3723 - val_mae: 0.4416\n",
            "Epoch 1022/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.4495 - mae: 0.5006 - val_loss: 0.2397 - val_mae: 0.3784\n",
            "Epoch 1023/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3283 - mae: 0.4316 - val_loss: 0.1741 - val_mae: 0.3384\n",
            "Epoch 1024/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2357 - mae: 0.3645 - val_loss: 0.1377 - val_mae: 0.2855\n",
            "Epoch 1025/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2057 - mae: 0.3266 - val_loss: 0.1287 - val_mae: 0.2747\n",
            "Epoch 1026/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2315 - mae: 0.3503 - val_loss: 0.1271 - val_mae: 0.2789\n",
            "Epoch 1027/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2062 - mae: 0.3323 - val_loss: 0.1522 - val_mae: 0.2949\n",
            "Epoch 1028/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2497 - mae: 0.3779 - val_loss: 0.1689 - val_mae: 0.3220\n",
            "Epoch 1029/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2766 - mae: 0.3885 - val_loss: 0.2898 - val_mae: 0.4285\n",
            "Epoch 1030/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3129 - mae: 0.4233 - val_loss: 0.1316 - val_mae: 0.2617\n",
            "Epoch 1031/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2189 - mae: 0.3402 - val_loss: 0.1359 - val_mae: 0.2991\n",
            "Epoch 1032/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2015 - mae: 0.3206 - val_loss: 0.1481 - val_mae: 0.3015\n",
            "Epoch 1033/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1951 - mae: 0.3151 - val_loss: 0.1400 - val_mae: 0.2949\n",
            "Epoch 1034/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2263 - mae: 0.3510 - val_loss: 0.1454 - val_mae: 0.2892\n",
            "Epoch 1035/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1989 - mae: 0.3228 - val_loss: 0.1265 - val_mae: 0.2886\n",
            "Epoch 1036/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2079 - mae: 0.3315 - val_loss: 0.1458 - val_mae: 0.2945\n",
            "Epoch 1037/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1979 - mae: 0.3156 - val_loss: 0.1122 - val_mae: 0.2467\n",
            "Epoch 1038/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1978 - mae: 0.3176 - val_loss: 0.1358 - val_mae: 0.2847\n",
            "Epoch 1039/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2094 - mae: 0.3411 - val_loss: 0.1928 - val_mae: 0.3754\n",
            "Epoch 1040/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2047 - mae: 0.3295 - val_loss: 0.1577 - val_mae: 0.3329\n",
            "Epoch 1041/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2139 - mae: 0.3454 - val_loss: 0.1285 - val_mae: 0.2675\n",
            "Epoch 1042/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1886 - mae: 0.3061 - val_loss: 0.1079 - val_mae: 0.2384\n",
            "Epoch 1043/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1889 - mae: 0.2984 - val_loss: 0.1087 - val_mae: 0.2386\n",
            "Epoch 1044/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1849 - mae: 0.2959 - val_loss: 0.1072 - val_mae: 0.2469\n",
            "Epoch 1045/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1899 - mae: 0.3080 - val_loss: 0.1228 - val_mae: 0.2557\n",
            "Epoch 1046/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1861 - mae: 0.2962 - val_loss: 0.1266 - val_mae: 0.2706\n",
            "Epoch 1047/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1826 - mae: 0.2978 - val_loss: 0.1084 - val_mae: 0.2475\n",
            "Epoch 1048/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1871 - mae: 0.2944 - val_loss: 0.1598 - val_mae: 0.3298\n",
            "Epoch 1049/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2225 - mae: 0.3557 - val_loss: 0.1203 - val_mae: 0.2807\n",
            "Epoch 1050/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2000 - mae: 0.3287 - val_loss: 0.1057 - val_mae: 0.2321\n",
            "Epoch 1051/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1862 - mae: 0.3075 - val_loss: 0.1594 - val_mae: 0.3202\n",
            "Epoch 1052/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2119 - mae: 0.3504 - val_loss: 0.1370 - val_mae: 0.3137\n",
            "Epoch 1053/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2034 - mae: 0.3426 - val_loss: 0.1455 - val_mae: 0.3041\n",
            "Epoch 1054/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1908 - mae: 0.3135 - val_loss: 0.1142 - val_mae: 0.2631\n",
            "Epoch 1055/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2257 - mae: 0.3528 - val_loss: 0.1594 - val_mae: 0.3221\n",
            "Epoch 1056/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2865 - mae: 0.4157 - val_loss: 0.2510 - val_mae: 0.4125\n",
            "Epoch 1057/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2341 - mae: 0.3659 - val_loss: 0.1466 - val_mae: 0.3172\n",
            "Epoch 1058/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1912 - mae: 0.3270 - val_loss: 0.1181 - val_mae: 0.2685\n",
            "Epoch 1059/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1789 - mae: 0.2945 - val_loss: 0.1145 - val_mae: 0.2735\n",
            "Epoch 1060/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1889 - mae: 0.3129 - val_loss: 0.1265 - val_mae: 0.2702\n",
            "Epoch 1061/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1850 - mae: 0.3062 - val_loss: 0.1015 - val_mae: 0.2288\n",
            "Epoch 1062/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1954 - mae: 0.3338 - val_loss: 0.1206 - val_mae: 0.2737\n",
            "Epoch 1063/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1839 - mae: 0.3087 - val_loss: 0.1206 - val_mae: 0.2640\n",
            "Epoch 1064/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1959 - mae: 0.3270 - val_loss: 0.1039 - val_mae: 0.2287\n",
            "Epoch 1065/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1816 - mae: 0.2872 - val_loss: 0.1268 - val_mae: 0.2567\n",
            "Epoch 1066/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1899 - mae: 0.3169 - val_loss: 0.1088 - val_mae: 0.2573\n",
            "Epoch 1067/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2006 - mae: 0.3291 - val_loss: 0.1481 - val_mae: 0.3176\n",
            "Epoch 1068/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2102 - mae: 0.3439 - val_loss: 0.1298 - val_mae: 0.2967\n",
            "Epoch 1069/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1943 - mae: 0.3274 - val_loss: 0.1142 - val_mae: 0.2608\n",
            "Epoch 1070/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1845 - mae: 0.3077 - val_loss: 0.1234 - val_mae: 0.2940\n",
            "Epoch 1071/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1899 - mae: 0.3185 - val_loss: 0.1341 - val_mae: 0.2938\n",
            "Epoch 1072/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1865 - mae: 0.3066 - val_loss: 0.1094 - val_mae: 0.2533\n",
            "Epoch 1073/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1809 - mae: 0.2951 - val_loss: 0.0938 - val_mae: 0.2105\n",
            "Epoch 1074/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1715 - mae: 0.2834 - val_loss: 0.1093 - val_mae: 0.2567\n",
            "Epoch 1075/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1679 - mae: 0.2750 - val_loss: 0.1058 - val_mae: 0.2232\n",
            "Epoch 1076/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1679 - mae: 0.2738 - val_loss: 0.1042 - val_mae: 0.2439\n",
            "Epoch 1077/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1754 - mae: 0.2884 - val_loss: 0.1791 - val_mae: 0.3458\n",
            "Epoch 1078/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1857 - mae: 0.3086 - val_loss: 0.1096 - val_mae: 0.2612\n",
            "Epoch 1079/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1702 - mae: 0.2824 - val_loss: 0.1096 - val_mae: 0.2548\n",
            "Epoch 1080/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1687 - mae: 0.2812 - val_loss: 0.1052 - val_mae: 0.2624\n",
            "Epoch 1081/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1682 - mae: 0.2856 - val_loss: 0.0983 - val_mae: 0.2367\n",
            "Epoch 1082/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1709 - mae: 0.2864 - val_loss: 0.1195 - val_mae: 0.2917\n",
            "Epoch 1083/1650\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1820 - mae: 0.3087 - val_loss: 0.0964 - val_mae: 0.2307\n",
            "Epoch 1084/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1643 - mae: 0.2666 - val_loss: 0.0970 - val_mae: 0.2113\n",
            "Epoch 1085/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1612 - mae: 0.2537 - val_loss: 0.1045 - val_mae: 0.2311\n",
            "Epoch 1086/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1662 - mae: 0.2726 - val_loss: 0.1160 - val_mae: 0.2709\n",
            "Epoch 1087/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1858 - mae: 0.3170 - val_loss: 0.1118 - val_mae: 0.2635\n",
            "Epoch 1088/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1762 - mae: 0.2968 - val_loss: 0.1184 - val_mae: 0.2814\n",
            "Epoch 1089/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1739 - mae: 0.2886 - val_loss: 0.1379 - val_mae: 0.3052\n",
            "Epoch 1090/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1912 - mae: 0.3133 - val_loss: 0.0941 - val_mae: 0.2207\n",
            "Epoch 1091/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1708 - mae: 0.2889 - val_loss: 0.0966 - val_mae: 0.2322\n",
            "Epoch 1092/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1724 - mae: 0.2847 - val_loss: 0.1210 - val_mae: 0.2759\n",
            "Epoch 1093/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1829 - mae: 0.3194 - val_loss: 0.1221 - val_mae: 0.2809\n",
            "Epoch 1094/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1874 - mae: 0.3212 - val_loss: 0.1462 - val_mae: 0.3082\n",
            "Epoch 1095/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1775 - mae: 0.3048 - val_loss: 0.0946 - val_mae: 0.2289\n",
            "Epoch 1096/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1939 - mae: 0.3179 - val_loss: 0.1203 - val_mae: 0.2818\n",
            "Epoch 1097/1650\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1913 - mae: 0.3168 - val_loss: 0.1832 - val_mae: 0.3379\n",
            "Epoch 1098/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1939 - mae: 0.3198 - val_loss: 0.1146 - val_mae: 0.2692\n",
            "Epoch 1099/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1754 - mae: 0.2944 - val_loss: 0.1189 - val_mae: 0.2668\n",
            "Epoch 1100/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1819 - mae: 0.3136 - val_loss: 0.1377 - val_mae: 0.3071\n",
            "Epoch 1101/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1739 - mae: 0.3056 - val_loss: 0.1200 - val_mae: 0.2929\n",
            "Epoch 1102/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1708 - mae: 0.2826 - val_loss: 0.0985 - val_mae: 0.2127\n",
            "Epoch 1103/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1624 - mae: 0.2663 - val_loss: 0.0895 - val_mae: 0.2162\n",
            "Epoch 1104/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1612 - mae: 0.2623 - val_loss: 0.0883 - val_mae: 0.2002\n",
            "Epoch 1105/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1817 - mae: 0.3087 - val_loss: 0.0964 - val_mae: 0.2371\n",
            "Epoch 1106/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2371 - mae: 0.3882 - val_loss: 0.2370 - val_mae: 0.3959\n",
            "Epoch 1107/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2490 - mae: 0.3788 - val_loss: 0.3284 - val_mae: 0.4756\n",
            "Epoch 1108/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3454 - mae: 0.4738 - val_loss: 0.1748 - val_mae: 0.3442\n",
            "Epoch 1109/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2151 - mae: 0.3571 - val_loss: 0.1771 - val_mae: 0.3455\n",
            "Epoch 1110/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1841 - mae: 0.3100 - val_loss: 0.1022 - val_mae: 0.2577\n",
            "Epoch 1111/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1751 - mae: 0.2957 - val_loss: 0.1228 - val_mae: 0.2887\n",
            "Epoch 1112/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1895 - mae: 0.3198 - val_loss: 0.1071 - val_mae: 0.2378\n",
            "Epoch 1113/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2046 - mae: 0.3365 - val_loss: 0.1840 - val_mae: 0.3483\n",
            "Epoch 1114/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2047 - mae: 0.3430 - val_loss: 0.1310 - val_mae: 0.2867\n",
            "Epoch 1115/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2261 - mae: 0.3606 - val_loss: 0.1417 - val_mae: 0.3008\n",
            "Epoch 1116/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1809 - mae: 0.2948 - val_loss: 0.1176 - val_mae: 0.2784\n",
            "Epoch 1117/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1744 - mae: 0.2824 - val_loss: 0.0934 - val_mae: 0.2287\n",
            "Epoch 1118/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1697 - mae: 0.2825 - val_loss: 0.1306 - val_mae: 0.2999\n",
            "Epoch 1119/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1646 - mae: 0.2772 - val_loss: 0.1064 - val_mae: 0.2688\n",
            "Epoch 1120/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1695 - mae: 0.2929 - val_loss: 0.1217 - val_mae: 0.2652\n",
            "Epoch 1121/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1706 - mae: 0.2962 - val_loss: 0.0978 - val_mae: 0.2355\n",
            "Epoch 1122/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1580 - mae: 0.2619 - val_loss: 0.0961 - val_mae: 0.2434\n",
            "Epoch 1123/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1673 - mae: 0.2863 - val_loss: 0.1417 - val_mae: 0.3114\n",
            "Epoch 1124/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1940 - mae: 0.3229 - val_loss: 0.1297 - val_mae: 0.2786\n",
            "Epoch 1125/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3056 - mae: 0.4030 - val_loss: 0.1066 - val_mae: 0.2621\n",
            "Epoch 1126/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2406 - mae: 0.3668 - val_loss: 0.0984 - val_mae: 0.2324\n",
            "Epoch 1127/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1864 - mae: 0.3214 - val_loss: 0.1767 - val_mae: 0.3245\n",
            "Epoch 1128/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2208 - mae: 0.3533 - val_loss: 0.0908 - val_mae: 0.2168\n",
            "Epoch 1129/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1778 - mae: 0.2955 - val_loss: 0.0880 - val_mae: 0.1989\n",
            "Epoch 1130/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1635 - mae: 0.2586 - val_loss: 0.0937 - val_mae: 0.2142\n",
            "Epoch 1131/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1594 - mae: 0.2698 - val_loss: 0.1457 - val_mae: 0.3041\n",
            "Epoch 1132/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1760 - mae: 0.2934 - val_loss: 0.0910 - val_mae: 0.2123\n",
            "Epoch 1133/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1528 - mae: 0.2477 - val_loss: 0.0835 - val_mae: 0.1911\n",
            "Epoch 1134/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1586 - mae: 0.2584 - val_loss: 0.0909 - val_mae: 0.2041\n",
            "Epoch 1135/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1579 - mae: 0.2610 - val_loss: 0.1021 - val_mae: 0.2437\n",
            "Epoch 1136/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1949 - mae: 0.3083 - val_loss: 0.1669 - val_mae: 0.3448\n",
            "Epoch 1137/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1982 - mae: 0.3286 - val_loss: 0.1077 - val_mae: 0.2481\n",
            "Epoch 1138/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1658 - mae: 0.2754 - val_loss: 0.1053 - val_mae: 0.2532\n",
            "Epoch 1139/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1883 - mae: 0.3180 - val_loss: 0.0956 - val_mae: 0.2459\n",
            "Epoch 1140/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1837 - mae: 0.3061 - val_loss: 0.0974 - val_mae: 0.2381\n",
            "Epoch 1141/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2247 - mae: 0.3483 - val_loss: 0.3510 - val_mae: 0.4427\n",
            "Epoch 1142/1650\n",
            "10/10 [==============================] - 0s 5ms/step - loss: 0.2931 - mae: 0.4240 - val_loss: 0.1665 - val_mae: 0.3504\n",
            "Epoch 1143/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3895 - mae: 0.4527 - val_loss: 0.1958 - val_mae: 0.3445\n",
            "Epoch 1144/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2196 - mae: 0.3481 - val_loss: 0.1199 - val_mae: 0.2707\n",
            "Epoch 1145/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1929 - mae: 0.3126 - val_loss: 0.1023 - val_mae: 0.2547\n",
            "Epoch 1146/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1830 - mae: 0.3044 - val_loss: 0.1238 - val_mae: 0.2629\n",
            "Epoch 1147/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1807 - mae: 0.3043 - val_loss: 0.0981 - val_mae: 0.2275\n",
            "Epoch 1148/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1745 - mae: 0.2905 - val_loss: 0.2151 - val_mae: 0.3985\n",
            "Epoch 1149/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1984 - mae: 0.3230 - val_loss: 0.1879 - val_mae: 0.3419\n",
            "Epoch 1150/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2073 - mae: 0.3331 - val_loss: 0.1247 - val_mae: 0.2720\n",
            "Epoch 1151/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1718 - mae: 0.2919 - val_loss: 0.1093 - val_mae: 0.2442\n",
            "Epoch 1152/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2110 - mae: 0.3563 - val_loss: 0.1833 - val_mae: 0.3677\n",
            "Epoch 1153/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2183 - mae: 0.3536 - val_loss: 0.1296 - val_mae: 0.3055\n",
            "Epoch 1154/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1836 - mae: 0.3112 - val_loss: 0.0886 - val_mae: 0.2098\n",
            "Epoch 1155/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1762 - mae: 0.2864 - val_loss: 0.2031 - val_mae: 0.3769\n",
            "Epoch 1156/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2390 - mae: 0.3826 - val_loss: 0.1400 - val_mae: 0.3144\n",
            "Epoch 1157/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2103 - mae: 0.3565 - val_loss: 0.1396 - val_mae: 0.3111\n",
            "Epoch 1158/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1790 - mae: 0.3046 - val_loss: 0.0960 - val_mae: 0.2323\n",
            "Epoch 1159/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1625 - mae: 0.2765 - val_loss: 0.1341 - val_mae: 0.2932\n",
            "Epoch 1160/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1678 - mae: 0.2814 - val_loss: 0.1290 - val_mae: 0.2861\n",
            "Epoch 1161/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1899 - mae: 0.3111 - val_loss: 0.1008 - val_mae: 0.2490\n",
            "Epoch 1162/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1742 - mae: 0.2975 - val_loss: 0.2466 - val_mae: 0.3889\n",
            "Epoch 1163/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2382 - mae: 0.3605 - val_loss: 0.1337 - val_mae: 0.2968\n",
            "Epoch 1164/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1747 - mae: 0.2905 - val_loss: 0.1966 - val_mae: 0.3714\n",
            "Epoch 1165/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2188 - mae: 0.3675 - val_loss: 0.1362 - val_mae: 0.3059\n",
            "Epoch 1166/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2602 - mae: 0.3935 - val_loss: 0.4036 - val_mae: 0.4405\n",
            "Epoch 1167/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3027 - mae: 0.4016 - val_loss: 0.1695 - val_mae: 0.3396\n",
            "Epoch 1168/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3264 - mae: 0.4132 - val_loss: 0.7359 - val_mae: 0.5271\n",
            "Epoch 1169/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.8805 - mae: 0.8958 - val_loss: 0.4672 - val_mae: 0.5392\n",
            "Epoch 1170/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8980 - mae: 0.6388 - val_loss: 0.7574 - val_mae: 0.5830\n",
            "Epoch 1171/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5856 - mae: 0.5511 - val_loss: 0.2112 - val_mae: 0.3986\n",
            "Epoch 1172/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2370 - mae: 0.3634 - val_loss: 0.1339 - val_mae: 0.2997\n",
            "Epoch 1173/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2963 - mae: 0.4164 - val_loss: 0.4516 - val_mae: 0.5310\n",
            "Epoch 1174/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.4065 - mae: 0.5087 - val_loss: 0.3836 - val_mae: 0.4390\n",
            "Epoch 1175/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3717 - mae: 0.4756 - val_loss: 0.0871 - val_mae: 0.2092\n",
            "Epoch 1176/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1884 - mae: 0.3055 - val_loss: 0.1290 - val_mae: 0.2755\n",
            "Epoch 1177/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1851 - mae: 0.3085 - val_loss: 0.1485 - val_mae: 0.3102\n",
            "Epoch 1178/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2303 - mae: 0.3666 - val_loss: 0.1443 - val_mae: 0.2853\n",
            "Epoch 1179/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2019 - mae: 0.3210 - val_loss: 0.1459 - val_mae: 0.2680\n",
            "Epoch 1180/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1966 - mae: 0.3212 - val_loss: 0.3830 - val_mae: 0.5628\n",
            "Epoch 1181/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3221 - mae: 0.4823 - val_loss: 0.1696 - val_mae: 0.3262\n",
            "Epoch 1182/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2658 - mae: 0.4231 - val_loss: 0.2531 - val_mae: 0.4113\n",
            "Epoch 1183/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2337 - mae: 0.3667 - val_loss: 0.0996 - val_mae: 0.2306\n",
            "Epoch 1184/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1945 - mae: 0.3184 - val_loss: 0.0924 - val_mae: 0.2352\n",
            "Epoch 1185/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1792 - mae: 0.2985 - val_loss: 0.1176 - val_mae: 0.2717\n",
            "Epoch 1186/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1723 - mae: 0.2905 - val_loss: 0.1540 - val_mae: 0.3215\n",
            "Epoch 1187/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1817 - mae: 0.3143 - val_loss: 0.2704 - val_mae: 0.3805\n",
            "Epoch 1188/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2547 - mae: 0.3829 - val_loss: 0.2708 - val_mae: 0.3880\n",
            "Epoch 1189/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2670 - mae: 0.4019 - val_loss: 0.2348 - val_mae: 0.4006\n",
            "Epoch 1190/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2784 - mae: 0.4113 - val_loss: 0.1948 - val_mae: 0.3989\n",
            "Epoch 1191/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1981 - mae: 0.3272 - val_loss: 0.0928 - val_mae: 0.2033\n",
            "Epoch 1192/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1591 - mae: 0.2675 - val_loss: 0.1453 - val_mae: 0.3089\n",
            "Epoch 1193/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1656 - mae: 0.2882 - val_loss: 0.1121 - val_mae: 0.2749\n",
            "Epoch 1194/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1772 - mae: 0.2943 - val_loss: 0.1043 - val_mae: 0.2654\n",
            "Epoch 1195/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1585 - mae: 0.2708 - val_loss: 0.0995 - val_mae: 0.2451\n",
            "Epoch 1196/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1694 - mae: 0.2806 - val_loss: 0.0853 - val_mae: 0.1900\n",
            "Epoch 1197/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1703 - mae: 0.2737 - val_loss: 0.0967 - val_mae: 0.2201\n",
            "Epoch 1198/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1852 - mae: 0.2988 - val_loss: 0.0932 - val_mae: 0.2243\n",
            "Epoch 1199/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1832 - mae: 0.2968 - val_loss: 0.1068 - val_mae: 0.2178\n",
            "Epoch 1200/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1702 - mae: 0.2724 - val_loss: 0.1072 - val_mae: 0.2646\n",
            "Epoch 1201/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1579 - mae: 0.2567 - val_loss: 0.0922 - val_mae: 0.2299\n",
            "Epoch 1202/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1573 - mae: 0.2617 - val_loss: 0.0969 - val_mae: 0.2325\n",
            "Epoch 1203/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1661 - mae: 0.2701 - val_loss: 0.1258 - val_mae: 0.2706\n",
            "Epoch 1204/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2001 - mae: 0.3187 - val_loss: 0.0952 - val_mae: 0.2492\n",
            "Epoch 1205/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2032 - mae: 0.3311 - val_loss: 0.1548 - val_mae: 0.3165\n",
            "Epoch 1206/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1749 - mae: 0.3028 - val_loss: 0.2060 - val_mae: 0.3643\n",
            "Epoch 1207/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2323 - mae: 0.3677 - val_loss: 0.1459 - val_mae: 0.3141\n",
            "Epoch 1208/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1946 - mae: 0.3293 - val_loss: 0.1584 - val_mae: 0.2983\n",
            "Epoch 1209/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3280 - mae: 0.3950 - val_loss: 0.4774 - val_mae: 0.4508\n",
            "Epoch 1210/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5913 - mae: 0.5387 - val_loss: 1.8113 - val_mae: 0.7890\n",
            "Epoch 1211/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 4.0849 - mae: 1.3159 - val_loss: 2.2475 - val_mae: 1.2006\n",
            "Epoch 1212/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 1.9922 - mae: 1.0456 - val_loss: 1.9448 - val_mae: 1.2007\n",
            "Epoch 1213/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.8585 - mae: 0.7466 - val_loss: 1.1532 - val_mae: 0.9104\n",
            "Epoch 1214/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5789 - mae: 0.6154 - val_loss: 0.1682 - val_mae: 0.3189\n",
            "Epoch 1215/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2439 - mae: 0.3823 - val_loss: 0.2745 - val_mae: 0.4611\n",
            "Epoch 1216/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2200 - mae: 0.3513 - val_loss: 0.0972 - val_mae: 0.2025\n",
            "Epoch 1217/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1838 - mae: 0.3114 - val_loss: 0.1487 - val_mae: 0.3343\n",
            "Epoch 1218/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1824 - mae: 0.3110 - val_loss: 0.0828 - val_mae: 0.1917\n",
            "Epoch 1219/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1731 - mae: 0.2867 - val_loss: 0.1376 - val_mae: 0.2976\n",
            "Epoch 1220/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1685 - mae: 0.2706 - val_loss: 0.1031 - val_mae: 0.2378\n",
            "Epoch 1221/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1545 - mae: 0.2640 - val_loss: 0.0785 - val_mae: 0.1802\n",
            "Epoch 1222/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1557 - mae: 0.2538 - val_loss: 0.0804 - val_mae: 0.1931\n",
            "Epoch 1223/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1575 - mae: 0.2622 - val_loss: 0.0876 - val_mae: 0.2168\n",
            "Epoch 1224/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1690 - mae: 0.2795 - val_loss: 0.1018 - val_mae: 0.2105\n",
            "Epoch 1225/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1518 - mae: 0.2501 - val_loss: 0.0830 - val_mae: 0.1969\n",
            "Epoch 1226/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1550 - mae: 0.2445 - val_loss: 0.0889 - val_mae: 0.2289\n",
            "Epoch 1227/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1520 - mae: 0.2543 - val_loss: 0.0795 - val_mae: 0.1790\n",
            "Epoch 1228/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1567 - mae: 0.2417 - val_loss: 0.1061 - val_mae: 0.2230\n",
            "Epoch 1229/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1636 - mae: 0.2707 - val_loss: 0.1078 - val_mae: 0.2458\n",
            "Epoch 1230/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1514 - mae: 0.2478 - val_loss: 0.0955 - val_mae: 0.2250\n",
            "Epoch 1231/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1682 - mae: 0.2732 - val_loss: 0.1088 - val_mae: 0.2448\n",
            "Epoch 1232/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1737 - mae: 0.2842 - val_loss: 0.0993 - val_mae: 0.2141\n",
            "Epoch 1233/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1500 - mae: 0.2401 - val_loss: 0.1082 - val_mae: 0.2365\n",
            "Epoch 1234/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1586 - mae: 0.2548 - val_loss: 0.1360 - val_mae: 0.2900\n",
            "Epoch 1235/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1586 - mae: 0.2621 - val_loss: 0.1193 - val_mae: 0.2442\n",
            "Epoch 1236/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1520 - mae: 0.2447 - val_loss: 0.0884 - val_mae: 0.2205\n",
            "Epoch 1237/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1531 - mae: 0.2462 - val_loss: 0.1061 - val_mae: 0.2094\n",
            "Epoch 1238/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1729 - mae: 0.2677 - val_loss: 0.1518 - val_mae: 0.3130\n",
            "Epoch 1239/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1683 - mae: 0.2762 - val_loss: 0.0894 - val_mae: 0.2170\n",
            "Epoch 1240/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1505 - mae: 0.2391 - val_loss: 0.0873 - val_mae: 0.1941\n",
            "Epoch 1241/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1658 - mae: 0.2712 - val_loss: 0.1227 - val_mae: 0.2935\n",
            "Epoch 1242/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1714 - mae: 0.2972 - val_loss: 0.0999 - val_mae: 0.2308\n",
            "Epoch 1243/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1546 - mae: 0.2519 - val_loss: 0.0863 - val_mae: 0.2172\n",
            "Epoch 1244/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1596 - mae: 0.2628 - val_loss: 0.0874 - val_mae: 0.2218\n",
            "Epoch 1245/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1616 - mae: 0.2648 - val_loss: 0.1007 - val_mae: 0.2361\n",
            "Epoch 1246/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1589 - mae: 0.2664 - val_loss: 0.0901 - val_mae: 0.2252\n",
            "Epoch 1247/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1689 - mae: 0.2811 - val_loss: 0.1395 - val_mae: 0.3240\n",
            "Epoch 1248/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1768 - mae: 0.2975 - val_loss: 0.0815 - val_mae: 0.1997\n",
            "Epoch 1249/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1700 - mae: 0.2752 - val_loss: 0.1333 - val_mae: 0.2965\n",
            "Epoch 1250/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1680 - mae: 0.2839 - val_loss: 0.1071 - val_mae: 0.2648\n",
            "Epoch 1251/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1650 - mae: 0.2777 - val_loss: 0.1030 - val_mae: 0.2510\n",
            "Epoch 1252/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1812 - mae: 0.2999 - val_loss: 0.2527 - val_mae: 0.4437\n",
            "Epoch 1253/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2187 - mae: 0.3665 - val_loss: 0.1715 - val_mae: 0.3287\n",
            "Epoch 1254/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2023 - mae: 0.3324 - val_loss: 0.1350 - val_mae: 0.2872\n",
            "Epoch 1255/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1823 - mae: 0.3087 - val_loss: 0.1239 - val_mae: 0.2832\n",
            "Epoch 1256/1650\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1735 - mae: 0.2850 - val_loss: 0.1066 - val_mae: 0.2365\n",
            "Epoch 1257/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1656 - mae: 0.2798 - val_loss: 0.1075 - val_mae: 0.2492\n",
            "Epoch 1258/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1553 - mae: 0.2549 - val_loss: 0.1232 - val_mae: 0.2730\n",
            "Epoch 1259/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1586 - mae: 0.2536 - val_loss: 0.0872 - val_mae: 0.2143\n",
            "Epoch 1260/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1465 - mae: 0.2332 - val_loss: 0.0799 - val_mae: 0.1958\n",
            "Epoch 1261/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1486 - mae: 0.2379 - val_loss: 0.0806 - val_mae: 0.1765\n",
            "Epoch 1262/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1513 - mae: 0.2402 - val_loss: 0.0884 - val_mae: 0.2203\n",
            "Epoch 1263/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1605 - mae: 0.2666 - val_loss: 0.1068 - val_mae: 0.2208\n",
            "Epoch 1264/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1549 - mae: 0.2474 - val_loss: 0.1076 - val_mae: 0.2621\n",
            "Epoch 1265/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1998 - mae: 0.3148 - val_loss: 0.2301 - val_mae: 0.4075\n",
            "Epoch 1266/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2398 - mae: 0.3736 - val_loss: 0.1738 - val_mae: 0.3298\n",
            "Epoch 1267/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1950 - mae: 0.3094 - val_loss: 0.0994 - val_mae: 0.2443\n",
            "Epoch 1268/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1664 - mae: 0.2814 - val_loss: 0.0819 - val_mae: 0.1941\n",
            "Epoch 1269/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1671 - mae: 0.2689 - val_loss: 0.1364 - val_mae: 0.3161\n",
            "Epoch 1270/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2074 - mae: 0.3357 - val_loss: 0.1431 - val_mae: 0.3009\n",
            "Epoch 1271/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1965 - mae: 0.3277 - val_loss: 0.0931 - val_mae: 0.2379\n",
            "Epoch 1272/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2035 - mae: 0.3421 - val_loss: 0.0841 - val_mae: 0.1993\n",
            "Epoch 1273/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1836 - mae: 0.3036 - val_loss: 0.0857 - val_mae: 0.2044\n",
            "Epoch 1274/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1714 - mae: 0.2799 - val_loss: 0.0816 - val_mae: 0.1857\n",
            "Epoch 1275/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1592 - mae: 0.2525 - val_loss: 0.0805 - val_mae: 0.1791\n",
            "Epoch 1276/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1454 - mae: 0.2338 - val_loss: 0.1493 - val_mae: 0.3093\n",
            "Epoch 1277/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1734 - mae: 0.2914 - val_loss: 0.1049 - val_mae: 0.2378\n",
            "Epoch 1278/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.2054 - mae: 0.3264 - val_loss: 0.2598 - val_mae: 0.3981\n",
            "Epoch 1279/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2778 - mae: 0.4048 - val_loss: 0.1096 - val_mae: 0.2403\n",
            "Epoch 1280/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2887 - mae: 0.4188 - val_loss: 0.1047 - val_mae: 0.2285\n",
            "Epoch 1281/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2197 - mae: 0.3514 - val_loss: 0.0889 - val_mae: 0.1975\n",
            "Epoch 1282/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1758 - mae: 0.2997 - val_loss: 0.0789 - val_mae: 0.1830\n",
            "Epoch 1283/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1659 - mae: 0.2669 - val_loss: 0.1131 - val_mae: 0.2343\n",
            "Epoch 1284/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1666 - mae: 0.2888 - val_loss: 0.1203 - val_mae: 0.2833\n",
            "Epoch 1285/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1980 - mae: 0.3267 - val_loss: 0.2565 - val_mae: 0.4305\n",
            "Epoch 1286/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3283 - mae: 0.4437 - val_loss: 0.3341 - val_mae: 0.5049\n",
            "Epoch 1287/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2760 - mae: 0.4188 - val_loss: 0.1307 - val_mae: 0.2771\n",
            "Epoch 1288/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1721 - mae: 0.2884 - val_loss: 0.0836 - val_mae: 0.1999\n",
            "Epoch 1289/1650\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1671 - mae: 0.2744 - val_loss: 0.1115 - val_mae: 0.2569\n",
            "Epoch 1290/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1627 - mae: 0.2752 - val_loss: 0.0823 - val_mae: 0.1952\n",
            "Epoch 1291/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1455 - mae: 0.2301 - val_loss: 0.0829 - val_mae: 0.1946\n",
            "Epoch 1292/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1516 - mae: 0.2427 - val_loss: 0.0918 - val_mae: 0.2298\n",
            "Epoch 1293/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1580 - mae: 0.2551 - val_loss: 0.0954 - val_mae: 0.2211\n",
            "Epoch 1294/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1496 - mae: 0.2458 - val_loss: 0.0833 - val_mae: 0.1943\n",
            "Epoch 1295/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1617 - mae: 0.2622 - val_loss: 0.0843 - val_mae: 0.2059\n",
            "Epoch 1296/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1460 - mae: 0.2305 - val_loss: 0.0905 - val_mae: 0.2046\n",
            "Epoch 1297/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1460 - mae: 0.2288 - val_loss: 0.0788 - val_mae: 0.1822\n",
            "Epoch 1298/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1437 - mae: 0.2158 - val_loss: 0.0813 - val_mae: 0.1949\n",
            "Epoch 1299/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1646 - mae: 0.2733 - val_loss: 0.0883 - val_mae: 0.2056\n",
            "Epoch 1300/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1708 - mae: 0.2932 - val_loss: 0.1452 - val_mae: 0.3128\n",
            "Epoch 1301/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1830 - mae: 0.3164 - val_loss: 0.1911 - val_mae: 0.3161\n",
            "Epoch 1302/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1888 - mae: 0.3145 - val_loss: 0.1689 - val_mae: 0.3314\n",
            "Epoch 1303/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2459 - mae: 0.3939 - val_loss: 0.4119 - val_mae: 0.4379\n",
            "Epoch 1304/1650\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.3193 - mae: 0.4083 - val_loss: 0.2361 - val_mae: 0.3990\n",
            "Epoch 1305/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2255 - mae: 0.3403 - val_loss: 0.1412 - val_mae: 0.2750\n",
            "Epoch 1306/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2048 - mae: 0.3092 - val_loss: 0.1916 - val_mae: 0.3561\n",
            "Epoch 1307/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1918 - mae: 0.3153 - val_loss: 0.1368 - val_mae: 0.3033\n",
            "Epoch 1308/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1852 - mae: 0.3031 - val_loss: 0.1004 - val_mae: 0.2228\n",
            "Epoch 1309/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1721 - mae: 0.2902 - val_loss: 0.1003 - val_mae: 0.2466\n",
            "Epoch 1310/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1709 - mae: 0.2911 - val_loss: 0.1034 - val_mae: 0.2557\n",
            "Epoch 1311/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1810 - mae: 0.3082 - val_loss: 0.0997 - val_mae: 0.2521\n",
            "Epoch 1312/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1907 - mae: 0.3231 - val_loss: 0.1038 - val_mae: 0.2609\n",
            "Epoch 1313/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1652 - mae: 0.2667 - val_loss: 0.1157 - val_mae: 0.2695\n",
            "Epoch 1314/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1718 - mae: 0.2656 - val_loss: 0.0762 - val_mae: 0.1768\n",
            "Epoch 1315/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1470 - mae: 0.2249 - val_loss: 0.1050 - val_mae: 0.2300\n",
            "Epoch 1316/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1698 - mae: 0.2806 - val_loss: 0.0841 - val_mae: 0.1996\n",
            "Epoch 1317/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1706 - mae: 0.2760 - val_loss: 0.1440 - val_mae: 0.2763\n",
            "Epoch 1318/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2101 - mae: 0.3422 - val_loss: 0.1086 - val_mae: 0.2549\n",
            "Epoch 1319/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1775 - mae: 0.3052 - val_loss: 0.1318 - val_mae: 0.2853\n",
            "Epoch 1320/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1704 - mae: 0.2845 - val_loss: 0.1446 - val_mae: 0.3025\n",
            "Epoch 1321/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2255 - mae: 0.3534 - val_loss: 0.3921 - val_mae: 0.5016\n",
            "Epoch 1322/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2996 - mae: 0.3949 - val_loss: 0.0926 - val_mae: 0.2203\n",
            "Epoch 1323/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1862 - mae: 0.3058 - val_loss: 0.0905 - val_mae: 0.2283\n",
            "Epoch 1324/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1738 - mae: 0.2991 - val_loss: 0.1265 - val_mae: 0.3041\n",
            "Epoch 1325/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1772 - mae: 0.2919 - val_loss: 0.1081 - val_mae: 0.2470\n",
            "Epoch 1326/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1738 - mae: 0.2892 - val_loss: 0.1695 - val_mae: 0.3208\n",
            "Epoch 1327/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1992 - mae: 0.3220 - val_loss: 0.1012 - val_mae: 0.2057\n",
            "Epoch 1328/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1833 - mae: 0.2930 - val_loss: 0.2430 - val_mae: 0.3903\n",
            "Epoch 1329/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1745 - mae: 0.2992 - val_loss: 0.1152 - val_mae: 0.2627\n",
            "Epoch 1330/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1727 - mae: 0.2910 - val_loss: 0.1469 - val_mae: 0.2780\n",
            "Epoch 1331/1650\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1649 - mae: 0.2863 - val_loss: 0.0897 - val_mae: 0.2145\n",
            "Epoch 1332/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1704 - mae: 0.2750 - val_loss: 0.1235 - val_mae: 0.2512\n",
            "Epoch 1333/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2024 - mae: 0.3156 - val_loss: 0.1955 - val_mae: 0.3739\n",
            "Epoch 1334/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1989 - mae: 0.3242 - val_loss: 0.0877 - val_mae: 0.2039\n",
            "Epoch 1335/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1819 - mae: 0.2832 - val_loss: 0.0930 - val_mae: 0.2349\n",
            "Epoch 1336/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1649 - mae: 0.2675 - val_loss: 0.1044 - val_mae: 0.2466\n",
            "Epoch 1337/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1690 - mae: 0.2895 - val_loss: 0.1059 - val_mae: 0.2312\n",
            "Epoch 1338/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1886 - mae: 0.3090 - val_loss: 0.0985 - val_mae: 0.2364\n",
            "Epoch 1339/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1933 - mae: 0.2975 - val_loss: 0.2064 - val_mae: 0.3902\n",
            "Epoch 1340/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2062 - mae: 0.3509 - val_loss: 0.2088 - val_mae: 0.3841\n",
            "Epoch 1341/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1802 - mae: 0.2939 - val_loss: 0.1133 - val_mae: 0.2545\n",
            "Epoch 1342/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1660 - mae: 0.2679 - val_loss: 0.0921 - val_mae: 0.2153\n",
            "Epoch 1343/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1828 - mae: 0.3142 - val_loss: 0.0926 - val_mae: 0.2391\n",
            "Epoch 1344/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1773 - mae: 0.2893 - val_loss: 0.0946 - val_mae: 0.2354\n",
            "Epoch 1345/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1883 - mae: 0.3110 - val_loss: 0.1087 - val_mae: 0.2599\n",
            "Epoch 1346/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1720 - mae: 0.2947 - val_loss: 0.1518 - val_mae: 0.3153\n",
            "Epoch 1347/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2214 - mae: 0.3571 - val_loss: 0.1616 - val_mae: 0.3271\n",
            "Epoch 1348/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2097 - mae: 0.3441 - val_loss: 0.2026 - val_mae: 0.3289\n",
            "Epoch 1349/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2273 - mae: 0.3466 - val_loss: 0.1120 - val_mae: 0.2751\n",
            "Epoch 1350/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1701 - mae: 0.2763 - val_loss: 0.1981 - val_mae: 0.3779\n",
            "Epoch 1351/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2399 - mae: 0.3885 - val_loss: 0.1943 - val_mae: 0.3736\n",
            "Epoch 1352/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2164 - mae: 0.3507 - val_loss: 0.0930 - val_mae: 0.2123\n",
            "Epoch 1353/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2381 - mae: 0.3609 - val_loss: 0.1755 - val_mae: 0.3429\n",
            "Epoch 1354/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1946 - mae: 0.3201 - val_loss: 0.1763 - val_mae: 0.3164\n",
            "Epoch 1355/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2076 - mae: 0.3311 - val_loss: 0.1844 - val_mae: 0.3581\n",
            "Epoch 1356/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1669 - mae: 0.2640 - val_loss: 0.0912 - val_mae: 0.2266\n",
            "Epoch 1357/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1559 - mae: 0.2519 - val_loss: 0.0786 - val_mae: 0.1877\n",
            "Epoch 1358/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1970 - mae: 0.3044 - val_loss: 0.0863 - val_mae: 0.2005\n",
            "Epoch 1359/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1766 - mae: 0.2938 - val_loss: 0.2046 - val_mae: 0.3516\n",
            "Epoch 1360/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1951 - mae: 0.3240 - val_loss: 0.1610 - val_mae: 0.3207\n",
            "Epoch 1361/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1649 - mae: 0.2705 - val_loss: 0.0926 - val_mae: 0.2323\n",
            "Epoch 1362/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1454 - mae: 0.2240 - val_loss: 0.0811 - val_mae: 0.1911\n",
            "Epoch 1363/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1464 - mae: 0.2366 - val_loss: 0.0907 - val_mae: 0.2276\n",
            "Epoch 1364/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1523 - mae: 0.2535 - val_loss: 0.1097 - val_mae: 0.2472\n",
            "Epoch 1365/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1582 - mae: 0.2630 - val_loss: 0.0987 - val_mae: 0.2380\n",
            "Epoch 1366/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1473 - mae: 0.2320 - val_loss: 0.1070 - val_mae: 0.2524\n",
            "Epoch 1367/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1634 - mae: 0.2763 - val_loss: 0.0916 - val_mae: 0.2253\n",
            "Epoch 1368/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1852 - mae: 0.3023 - val_loss: 0.1817 - val_mae: 0.3443\n",
            "Epoch 1369/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1849 - mae: 0.3128 - val_loss: 0.1106 - val_mae: 0.2632\n",
            "Epoch 1370/1650\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.2094 - mae: 0.3283 - val_loss: 0.1337 - val_mae: 0.3164\n",
            "Epoch 1371/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1817 - mae: 0.3090 - val_loss: 0.1451 - val_mae: 0.3142\n",
            "Epoch 1372/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1758 - mae: 0.2870 - val_loss: 0.0918 - val_mae: 0.2294\n",
            "Epoch 1373/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1647 - mae: 0.2832 - val_loss: 0.0779 - val_mae: 0.1762\n",
            "Epoch 1374/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1469 - mae: 0.2281 - val_loss: 0.1194 - val_mae: 0.2824\n",
            "Epoch 1375/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3234 - mae: 0.4138 - val_loss: 0.6601 - val_mae: 0.6517\n",
            "Epoch 1376/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.4853 - mae: 0.4968 - val_loss: 1.5114 - val_mae: 0.7865\n",
            "Epoch 1377/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.8088 - mae: 0.6073 - val_loss: 0.3575 - val_mae: 0.5081\n",
            "Epoch 1378/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6880 - mae: 0.5490 - val_loss: 0.4777 - val_mae: 0.5619\n",
            "Epoch 1379/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6289 - mae: 0.5752 - val_loss: 0.2371 - val_mae: 0.3702\n",
            "Epoch 1380/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3634 - mae: 0.4519 - val_loss: 1.1557 - val_mae: 0.6894\n",
            "Epoch 1381/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8331 - mae: 0.6336 - val_loss: 0.6555 - val_mae: 0.5343\n",
            "Epoch 1382/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7019 - mae: 0.5724 - val_loss: 1.3669 - val_mae: 0.9614\n",
            "Epoch 1383/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.1177 - mae: 0.7723 - val_loss: 0.6136 - val_mae: 0.5290\n",
            "Epoch 1384/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.5056 - mae: 0.4860 - val_loss: 0.1013 - val_mae: 0.2301\n",
            "Epoch 1385/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3526 - mae: 0.3980 - val_loss: 0.1285 - val_mae: 0.2840\n",
            "Epoch 1386/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1961 - mae: 0.3257 - val_loss: 0.0925 - val_mae: 0.2182\n",
            "Epoch 1387/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1581 - mae: 0.2578 - val_loss: 0.1498 - val_mae: 0.2778\n",
            "Epoch 1388/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2084 - mae: 0.3192 - val_loss: 0.0962 - val_mae: 0.2299\n",
            "Epoch 1389/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.2595 - mae: 0.3751 - val_loss: 0.2079 - val_mae: 0.3898\n",
            "Epoch 1390/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1900 - mae: 0.3143 - val_loss: 0.1469 - val_mae: 0.3100\n",
            "Epoch 1391/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1799 - mae: 0.2937 - val_loss: 0.0887 - val_mae: 0.1910\n",
            "Epoch 1392/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1511 - mae: 0.2599 - val_loss: 0.0713 - val_mae: 0.1856\n",
            "Epoch 1393/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1845 - mae: 0.3022 - val_loss: 0.1270 - val_mae: 0.2876\n",
            "Epoch 1394/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1957 - mae: 0.3320 - val_loss: 0.1560 - val_mae: 0.3356\n",
            "Epoch 1395/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1773 - mae: 0.2958 - val_loss: 0.1964 - val_mae: 0.3627\n",
            "Epoch 1396/1650\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1809 - mae: 0.3109 - val_loss: 0.0955 - val_mae: 0.2230\n",
            "Epoch 1397/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1310 - mae: 0.2283 - val_loss: 0.0643 - val_mae: 0.1754\n",
            "Epoch 1398/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1265 - mae: 0.2228 - val_loss: 0.0684 - val_mae: 0.1963\n",
            "Epoch 1399/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1225 - mae: 0.2211 - val_loss: 0.0847 - val_mae: 0.2223\n",
            "Epoch 1400/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1236 - mae: 0.2231 - val_loss: 0.0820 - val_mae: 0.1882\n",
            "Epoch 1401/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1265 - mae: 0.2286 - val_loss: 0.0816 - val_mae: 0.2101\n",
            "Epoch 1402/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1234 - mae: 0.2251 - val_loss: 0.0648 - val_mae: 0.1644\n",
            "Epoch 1403/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1213 - mae: 0.2259 - val_loss: 0.1020 - val_mae: 0.2261\n",
            "Epoch 1404/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1271 - mae: 0.2395 - val_loss: 0.0585 - val_mae: 0.1578\n",
            "Epoch 1405/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1164 - mae: 0.2216 - val_loss: 0.0849 - val_mae: 0.2324\n",
            "Epoch 1406/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1197 - mae: 0.2280 - val_loss: 0.1069 - val_mae: 0.2794\n",
            "Epoch 1407/1650\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.1537 - mae: 0.2819 - val_loss: 0.1007 - val_mae: 0.2556\n",
            "Epoch 1408/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1418 - mae: 0.2725 - val_loss: 0.0918 - val_mae: 0.2222\n",
            "Epoch 1409/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1625 - mae: 0.2885 - val_loss: 0.0989 - val_mae: 0.2465\n",
            "Epoch 1410/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1661 - mae: 0.2901 - val_loss: 0.1045 - val_mae: 0.2543\n",
            "Epoch 1411/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1578 - mae: 0.2926 - val_loss: 0.0829 - val_mae: 0.2325\n",
            "Epoch 1412/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1216 - mae: 0.2364 - val_loss: 0.0732 - val_mae: 0.1976\n",
            "Epoch 1413/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1068 - mae: 0.1884 - val_loss: 0.0750 - val_mae: 0.2168\n",
            "Epoch 1414/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1144 - mae: 0.2182 - val_loss: 0.0713 - val_mae: 0.1854\n",
            "Epoch 1415/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1081 - mae: 0.1971 - val_loss: 0.0571 - val_mae: 0.1555\n",
            "Epoch 1416/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1065 - mae: 0.1979 - val_loss: 0.0553 - val_mae: 0.1532\n",
            "Epoch 1417/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1037 - mae: 0.1864 - val_loss: 0.0587 - val_mae: 0.1605\n",
            "Epoch 1418/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1074 - mae: 0.2018 - val_loss: 0.0558 - val_mae: 0.1603\n",
            "Epoch 1419/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1181 - mae: 0.2260 - val_loss: 0.0686 - val_mae: 0.2083\n",
            "Epoch 1420/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1142 - mae: 0.2247 - val_loss: 0.0584 - val_mae: 0.1729\n",
            "Epoch 1421/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1063 - mae: 0.1983 - val_loss: 0.0546 - val_mae: 0.1594\n",
            "Epoch 1422/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1041 - mae: 0.1982 - val_loss: 0.0640 - val_mae: 0.1956\n",
            "Epoch 1423/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1123 - mae: 0.2242 - val_loss: 0.0643 - val_mae: 0.1918\n",
            "Epoch 1424/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1110 - mae: 0.2186 - val_loss: 0.0577 - val_mae: 0.1764\n",
            "Epoch 1425/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0997 - mae: 0.1862 - val_loss: 0.0541 - val_mae: 0.1546\n",
            "Epoch 1426/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1026 - mae: 0.1960 - val_loss: 0.0916 - val_mae: 0.2474\n",
            "Epoch 1427/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1251 - mae: 0.2368 - val_loss: 0.0790 - val_mae: 0.2148\n",
            "Epoch 1428/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1482 - mae: 0.2853 - val_loss: 0.1942 - val_mae: 0.3780\n",
            "Epoch 1429/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1402 - mae: 0.2795 - val_loss: 0.0721 - val_mae: 0.2067\n",
            "Epoch 1430/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1058 - mae: 0.2076 - val_loss: 0.0589 - val_mae: 0.1815\n",
            "Epoch 1431/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1131 - mae: 0.2314 - val_loss: 0.0874 - val_mae: 0.2018\n",
            "Epoch 1432/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1362 - mae: 0.2673 - val_loss: 0.0958 - val_mae: 0.2514\n",
            "Epoch 1433/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1320 - mae: 0.2571 - val_loss: 0.0840 - val_mae: 0.2101\n",
            "Epoch 1434/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1341 - mae: 0.2641 - val_loss: 0.1195 - val_mae: 0.2990\n",
            "Epoch 1435/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1347 - mae: 0.2671 - val_loss: 0.0582 - val_mae: 0.1420\n",
            "Epoch 1436/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1272 - mae: 0.2570 - val_loss: 0.0859 - val_mae: 0.2451\n",
            "Epoch 1437/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1267 - mae: 0.2530 - val_loss: 0.0764 - val_mae: 0.2035\n",
            "Epoch 1438/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1096 - mae: 0.2297 - val_loss: 0.0652 - val_mae: 0.1776\n",
            "Epoch 1439/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0945 - mae: 0.1863 - val_loss: 0.0681 - val_mae: 0.1855\n",
            "Epoch 1440/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0916 - mae: 0.1805 - val_loss: 0.0538 - val_mae: 0.1550\n",
            "Epoch 1441/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1069 - mae: 0.2123 - val_loss: 0.0667 - val_mae: 0.1991\n",
            "Epoch 1442/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1231 - mae: 0.2474 - val_loss: 0.2172 - val_mae: 0.3538\n",
            "Epoch 1443/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2196 - mae: 0.3402 - val_loss: 0.0851 - val_mae: 0.2436\n",
            "Epoch 1444/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1095 - mae: 0.2194 - val_loss: 0.0941 - val_mae: 0.2247\n",
            "Epoch 1445/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1504 - mae: 0.2815 - val_loss: 0.1575 - val_mae: 0.3019\n",
            "Epoch 1446/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1851 - mae: 0.3311 - val_loss: 0.2143 - val_mae: 0.3848\n",
            "Epoch 1447/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3618 - mae: 0.4745 - val_loss: 0.1794 - val_mae: 0.3555\n",
            "Epoch 1448/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2144 - mae: 0.3297 - val_loss: 1.2789 - val_mae: 0.6092\n",
            "Epoch 1449/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.8187 - mae: 0.5438 - val_loss: 0.6418 - val_mae: 0.5700\n",
            "Epoch 1450/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.5170 - mae: 0.5852 - val_loss: 0.1992 - val_mae: 0.3880\n",
            "Epoch 1451/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2641 - mae: 0.4095 - val_loss: 0.3420 - val_mae: 0.5281\n",
            "Epoch 1452/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2424 - mae: 0.3854 - val_loss: 0.0571 - val_mae: 0.1592\n",
            "Epoch 1453/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1339 - mae: 0.2647 - val_loss: 0.0984 - val_mae: 0.2264\n",
            "Epoch 1454/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1295 - mae: 0.2682 - val_loss: 0.0852 - val_mae: 0.2207\n",
            "Epoch 1455/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1847 - mae: 0.3012 - val_loss: 0.1878 - val_mae: 0.3789\n",
            "Epoch 1456/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1629 - mae: 0.3065 - val_loss: 0.2171 - val_mae: 0.4065\n",
            "Epoch 1457/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1627 - mae: 0.2959 - val_loss: 0.0861 - val_mae: 0.1988\n",
            "Epoch 1458/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1127 - mae: 0.2228 - val_loss: 0.0598 - val_mae: 0.1749\n",
            "Epoch 1459/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0846 - mae: 0.1778 - val_loss: 0.0501 - val_mae: 0.1378\n",
            "Epoch 1460/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0894 - mae: 0.1881 - val_loss: 0.0996 - val_mae: 0.2729\n",
            "Epoch 1461/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1106 - mae: 0.2381 - val_loss: 0.0565 - val_mae: 0.1524\n",
            "Epoch 1462/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0878 - mae: 0.1903 - val_loss: 0.0755 - val_mae: 0.2346\n",
            "Epoch 1463/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1045 - mae: 0.2207 - val_loss: 0.0620 - val_mae: 0.1826\n",
            "Epoch 1464/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0866 - mae: 0.1772 - val_loss: 0.0394 - val_mae: 0.1229\n",
            "Epoch 1465/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0823 - mae: 0.1729 - val_loss: 0.0561 - val_mae: 0.1715\n",
            "Epoch 1466/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1069 - mae: 0.2282 - val_loss: 0.1047 - val_mae: 0.2836\n",
            "Epoch 1467/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2436 - mae: 0.3308 - val_loss: 0.3166 - val_mae: 0.3656\n",
            "Epoch 1468/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3084 - mae: 0.4057 - val_loss: 0.4913 - val_mae: 0.5750\n",
            "Epoch 1469/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2984 - mae: 0.4156 - val_loss: 0.1719 - val_mae: 0.3113\n",
            "Epoch 1470/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2086 - mae: 0.3352 - val_loss: 0.1786 - val_mae: 0.3221\n",
            "Epoch 1471/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1394 - mae: 0.2813 - val_loss: 0.0584 - val_mae: 0.1658\n",
            "Epoch 1472/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1074 - mae: 0.2310 - val_loss: 0.0439 - val_mae: 0.1358\n",
            "Epoch 1473/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1072 - mae: 0.2291 - val_loss: 0.1038 - val_mae: 0.2678\n",
            "Epoch 1474/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1172 - mae: 0.2521 - val_loss: 0.0749 - val_mae: 0.1887\n",
            "Epoch 1475/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1067 - mae: 0.2261 - val_loss: 0.1169 - val_mae: 0.2659\n",
            "Epoch 1476/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1295 - mae: 0.2689 - val_loss: 0.2090 - val_mae: 0.3276\n",
            "Epoch 1477/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.2503 - mae: 0.3863 - val_loss: 0.0411 - val_mae: 0.1347\n",
            "Epoch 1478/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1309 - mae: 0.2810 - val_loss: 0.0716 - val_mae: 0.2218\n",
            "Epoch 1479/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0815 - mae: 0.1891 - val_loss: 0.0417 - val_mae: 0.1482\n",
            "Epoch 1480/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0940 - mae: 0.2039 - val_loss: 0.0382 - val_mae: 0.1361\n",
            "Epoch 1481/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0852 - mae: 0.1966 - val_loss: 0.0478 - val_mae: 0.1627\n",
            "Epoch 1482/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0757 - mae: 0.1742 - val_loss: 0.0384 - val_mae: 0.1379\n",
            "Epoch 1483/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0690 - mae: 0.1445 - val_loss: 0.0477 - val_mae: 0.1444\n",
            "Epoch 1484/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0806 - mae: 0.1907 - val_loss: 0.1106 - val_mae: 0.2881\n",
            "Epoch 1485/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1064 - mae: 0.2335 - val_loss: 0.0444 - val_mae: 0.1355\n",
            "Epoch 1486/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1433 - mae: 0.2839 - val_loss: 0.1127 - val_mae: 0.2936\n",
            "Epoch 1487/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0999 - mae: 0.2282 - val_loss: 0.0578 - val_mae: 0.1916\n",
            "Epoch 1488/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0762 - mae: 0.1709 - val_loss: 0.0535 - val_mae: 0.1652\n",
            "Epoch 1489/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0817 - mae: 0.1895 - val_loss: 0.0928 - val_mae: 0.2618\n",
            "Epoch 1490/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1026 - mae: 0.2309 - val_loss: 0.1151 - val_mae: 0.2647\n",
            "Epoch 1491/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.3119 - mae: 0.3876 - val_loss: 0.1681 - val_mae: 0.3873\n",
            "Epoch 1492/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1496 - mae: 0.3026 - val_loss: 0.0327 - val_mae: 0.1063\n",
            "Epoch 1493/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0942 - mae: 0.2164 - val_loss: 0.0755 - val_mae: 0.2318\n",
            "Epoch 1494/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0801 - mae: 0.1904 - val_loss: 0.0513 - val_mae: 0.1874\n",
            "Epoch 1495/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0782 - mae: 0.1943 - val_loss: 0.0390 - val_mae: 0.1364\n",
            "Epoch 1496/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0659 - mae: 0.1583 - val_loss: 0.0432 - val_mae: 0.1453\n",
            "Epoch 1497/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0694 - mae: 0.1734 - val_loss: 0.0525 - val_mae: 0.1720\n",
            "Epoch 1498/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0899 - mae: 0.2144 - val_loss: 0.0600 - val_mae: 0.1839\n",
            "Epoch 1499/1650\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0670 - mae: 0.1648 - val_loss: 0.0326 - val_mae: 0.1134\n",
            "Epoch 1500/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0560 - mae: 0.1249 - val_loss: 0.0393 - val_mae: 0.1325\n",
            "Epoch 1501/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0568 - mae: 0.1347 - val_loss: 0.0304 - val_mae: 0.1058\n",
            "Epoch 1502/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0584 - mae: 0.1459 - val_loss: 0.0372 - val_mae: 0.1466\n",
            "Epoch 1503/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0622 - mae: 0.1586 - val_loss: 0.0397 - val_mae: 0.1374\n",
            "Epoch 1504/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0610 - mae: 0.1466 - val_loss: 0.1052 - val_mae: 0.2232\n",
            "Epoch 1505/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1119 - mae: 0.2127 - val_loss: 0.0760 - val_mae: 0.1934\n",
            "Epoch 1506/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1135 - mae: 0.2406 - val_loss: 0.2308 - val_mae: 0.3147\n",
            "Epoch 1507/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1155 - mae: 0.2113 - val_loss: 0.0462 - val_mae: 0.1518\n",
            "Epoch 1508/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0716 - mae: 0.1784 - val_loss: 0.0877 - val_mae: 0.2078\n",
            "Epoch 1509/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1756 - mae: 0.2745 - val_loss: 0.2695 - val_mae: 0.3159\n",
            "Epoch 1510/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1718 - mae: 0.3072 - val_loss: 0.0691 - val_mae: 0.1894\n",
            "Epoch 1511/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.1292 - mae: 0.2732 - val_loss: 0.0292 - val_mae: 0.1033\n",
            "Epoch 1512/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0669 - mae: 0.1745 - val_loss: 0.0349 - val_mae: 0.1249\n",
            "Epoch 1513/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0629 - mae: 0.1679 - val_loss: 0.0447 - val_mae: 0.1558\n",
            "Epoch 1514/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0645 - mae: 0.1642 - val_loss: 0.0295 - val_mae: 0.1235\n",
            "Epoch 1515/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0676 - mae: 0.1820 - val_loss: 0.0485 - val_mae: 0.1518\n",
            "Epoch 1516/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0593 - mae: 0.1581 - val_loss: 0.0438 - val_mae: 0.1649\n",
            "Epoch 1517/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0589 - mae: 0.1628 - val_loss: 0.0287 - val_mae: 0.1058\n",
            "Epoch 1518/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0510 - mae: 0.1319 - val_loss: 0.0294 - val_mae: 0.1012\n",
            "Epoch 1519/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0497 - mae: 0.1270 - val_loss: 0.0402 - val_mae: 0.1581\n",
            "Epoch 1520/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0619 - mae: 0.1718 - val_loss: 0.0517 - val_mae: 0.1786\n",
            "Epoch 1521/1650\n",
            "10/10 [==============================] - 0s 10ms/step - loss: 0.0573 - mae: 0.1569 - val_loss: 0.0425 - val_mae: 0.1470\n",
            "Epoch 1522/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0591 - mae: 0.1644 - val_loss: 0.0942 - val_mae: 0.2363\n",
            "Epoch 1523/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0816 - mae: 0.2121 - val_loss: 0.0372 - val_mae: 0.1453\n",
            "Epoch 1524/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0670 - mae: 0.1799 - val_loss: 0.0312 - val_mae: 0.1075\n",
            "Epoch 1525/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0793 - mae: 0.2047 - val_loss: 0.1310 - val_mae: 0.3352\n",
            "Epoch 1526/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0777 - mae: 0.2083 - val_loss: 0.0479 - val_mae: 0.1627\n",
            "Epoch 1527/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0563 - mae: 0.1632 - val_loss: 0.0432 - val_mae: 0.1555\n",
            "Epoch 1528/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0472 - mae: 0.1323 - val_loss: 0.0287 - val_mae: 0.1291\n",
            "Epoch 1529/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0682 - mae: 0.1805 - val_loss: 0.0298 - val_mae: 0.1219\n",
            "Epoch 1530/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0937 - mae: 0.1960 - val_loss: 0.0910 - val_mae: 0.2036\n",
            "Epoch 1531/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1188 - mae: 0.2442 - val_loss: 0.0467 - val_mae: 0.1443\n",
            "Epoch 1532/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.1236 - mae: 0.2842 - val_loss: 0.3081 - val_mae: 0.4101\n",
            "Epoch 1533/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.3421 - mae: 0.4007 - val_loss: 0.2238 - val_mae: 0.2926\n",
            "Epoch 1534/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 1.6580 - mae: 0.7412 - val_loss: 2.4742 - val_mae: 1.0225\n",
            "Epoch 1535/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 1.3218 - mae: 0.8192 - val_loss: 0.9769 - val_mae: 0.7884\n",
            "Epoch 1536/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.6995 - mae: 0.6849 - val_loss: 1.0733 - val_mae: 0.9244\n",
            "Epoch 1537/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.7131 - mae: 0.6889 - val_loss: 0.6649 - val_mae: 0.7764\n",
            "Epoch 1538/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.3756 - mae: 0.5069 - val_loss: 0.1592 - val_mae: 0.3212\n",
            "Epoch 1539/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1830 - mae: 0.3471 - val_loss: 0.1041 - val_mae: 0.2051\n",
            "Epoch 1540/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.4822 - mae: 0.4791 - val_loss: 0.5556 - val_mae: 0.4732\n",
            "Epoch 1541/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.7167 - mae: 0.6303 - val_loss: 1.0572 - val_mae: 0.6802\n",
            "Epoch 1542/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 3.2470 - mae: 1.1326 - val_loss: 3.5537 - val_mae: 1.3168\n",
            "Epoch 1543/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.8388 - mae: 0.8956 - val_loss: 2.2282 - val_mae: 1.0592\n",
            "Epoch 1544/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 1.7996 - mae: 0.9873 - val_loss: 0.9153 - val_mae: 0.8457\n",
            "Epoch 1545/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 2.5553 - mae: 1.1246 - val_loss: 1.4550 - val_mae: 0.9590\n",
            "Epoch 1546/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.8811 - mae: 0.7303 - val_loss: 0.7101 - val_mae: 0.5451\n",
            "Epoch 1547/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.6070 - mae: 0.6178 - val_loss: 0.3859 - val_mae: 0.5394\n",
            "Epoch 1548/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.2429 - mae: 0.4016 - val_loss: 0.1985 - val_mae: 0.3303\n",
            "Epoch 1549/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.1670 - mae: 0.3203 - val_loss: 0.0774 - val_mae: 0.2261\n",
            "Epoch 1550/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0969 - mae: 0.2411 - val_loss: 0.0350 - val_mae: 0.1583\n",
            "Epoch 1551/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0698 - mae: 0.2002 - val_loss: 0.0242 - val_mae: 0.1078\n",
            "Epoch 1552/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0461 - mae: 0.1476 - val_loss: 0.0289 - val_mae: 0.1182\n",
            "Epoch 1553/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0355 - mae: 0.1117 - val_loss: 0.0309 - val_mae: 0.1170\n",
            "Epoch 1554/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0347 - mae: 0.1120 - val_loss: 0.0237 - val_mae: 0.1014\n",
            "Epoch 1555/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0340 - mae: 0.1063 - val_loss: 0.0196 - val_mae: 0.0836\n",
            "Epoch 1556/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0309 - mae: 0.0905 - val_loss: 0.0180 - val_mae: 0.0738\n",
            "Epoch 1557/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0304 - mae: 0.0872 - val_loss: 0.0222 - val_mae: 0.0944\n",
            "Epoch 1558/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0315 - mae: 0.1040 - val_loss: 0.0177 - val_mae: 0.0662\n",
            "Epoch 1559/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0320 - mae: 0.1078 - val_loss: 0.0286 - val_mae: 0.1405\n",
            "Epoch 1560/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0321 - mae: 0.1037 - val_loss: 0.0148 - val_mae: 0.0624\n",
            "Epoch 1561/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0278 - mae: 0.0840 - val_loss: 0.0158 - val_mae: 0.0656\n",
            "Epoch 1562/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0269 - mae: 0.0818 - val_loss: 0.0186 - val_mae: 0.0806\n",
            "Epoch 1563/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0283 - mae: 0.0928 - val_loss: 0.0189 - val_mae: 0.0817\n",
            "Epoch 1564/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0287 - mae: 0.0937 - val_loss: 0.0270 - val_mae: 0.1216\n",
            "Epoch 1565/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0306 - mae: 0.1068 - val_loss: 0.0214 - val_mae: 0.0947\n",
            "Epoch 1566/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0281 - mae: 0.0936 - val_loss: 0.0162 - val_mae: 0.0730\n",
            "Epoch 1567/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0263 - mae: 0.0863 - val_loss: 0.0138 - val_mae: 0.0609\n",
            "Epoch 1568/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0279 - mae: 0.0903 - val_loss: 0.0140 - val_mae: 0.0638\n",
            "Epoch 1569/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0273 - mae: 0.0949 - val_loss: 0.0215 - val_mae: 0.1129\n",
            "Epoch 1570/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0312 - mae: 0.1133 - val_loss: 0.0194 - val_mae: 0.1044\n",
            "Epoch 1571/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0277 - mae: 0.0986 - val_loss: 0.0160 - val_mae: 0.0834\n",
            "Epoch 1572/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0269 - mae: 0.0973 - val_loss: 0.0152 - val_mae: 0.0699\n",
            "Epoch 1573/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0237 - mae: 0.0817 - val_loss: 0.0145 - val_mae: 0.0674\n",
            "Epoch 1574/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0230 - mae: 0.0764 - val_loss: 0.0196 - val_mae: 0.0919\n",
            "Epoch 1575/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0293 - mae: 0.1118 - val_loss: 0.0361 - val_mae: 0.1575\n",
            "Epoch 1576/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0296 - mae: 0.1167 - val_loss: 0.0201 - val_mae: 0.0925\n",
            "Epoch 1577/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0249 - mae: 0.0933 - val_loss: 0.0206 - val_mae: 0.1043\n",
            "Epoch 1578/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0262 - mae: 0.1030 - val_loss: 0.0180 - val_mae: 0.0887\n",
            "Epoch 1579/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0226 - mae: 0.0850 - val_loss: 0.0195 - val_mae: 0.0918\n",
            "Epoch 1580/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0251 - mae: 0.0980 - val_loss: 0.0143 - val_mae: 0.0697\n",
            "Epoch 1581/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0214 - mae: 0.0781 - val_loss: 0.0116 - val_mae: 0.0536\n",
            "Epoch 1582/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0201 - mae: 0.0698 - val_loss: 0.0117 - val_mae: 0.0572\n",
            "Epoch 1583/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0196 - mae: 0.0680 - val_loss: 0.0102 - val_mae: 0.0510\n",
            "Epoch 1584/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0209 - mae: 0.0782 - val_loss: 0.0164 - val_mae: 0.0881\n",
            "Epoch 1585/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0232 - mae: 0.0961 - val_loss: 0.0133 - val_mae: 0.0680\n",
            "Epoch 1586/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0194 - mae: 0.0739 - val_loss: 0.0116 - val_mae: 0.0562\n",
            "Epoch 1587/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0185 - mae: 0.0646 - val_loss: 0.0145 - val_mae: 0.0759\n",
            "Epoch 1588/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0211 - mae: 0.0853 - val_loss: 0.0114 - val_mae: 0.0610\n",
            "Epoch 1589/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0194 - mae: 0.0727 - val_loss: 0.0101 - val_mae: 0.0593\n",
            "Epoch 1590/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0194 - mae: 0.0720 - val_loss: 0.0112 - val_mae: 0.0625\n",
            "Epoch 1591/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0200 - mae: 0.0824 - val_loss: 0.0313 - val_mae: 0.1414\n",
            "Epoch 1592/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0375 - mae: 0.1427 - val_loss: 0.0312 - val_mae: 0.1399\n",
            "Epoch 1593/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0256 - mae: 0.1131 - val_loss: 0.0354 - val_mae: 0.1602\n",
            "Epoch 1594/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0282 - mae: 0.1204 - val_loss: 0.0150 - val_mae: 0.0765\n",
            "Epoch 1595/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0346 - mae: 0.1147 - val_loss: 0.0400 - val_mae: 0.1197\n",
            "Epoch 1596/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0287 - mae: 0.1097 - val_loss: 0.0265 - val_mae: 0.0995\n",
            "Epoch 1597/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0278 - mae: 0.1181 - val_loss: 0.0151 - val_mae: 0.0739\n",
            "Epoch 1598/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0252 - mae: 0.1110 - val_loss: 0.0179 - val_mae: 0.0912\n",
            "Epoch 1599/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0220 - mae: 0.1007 - val_loss: 0.0191 - val_mae: 0.1101\n",
            "Epoch 1600/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0199 - mae: 0.0930 - val_loss: 0.0091 - val_mae: 0.0501\n",
            "Epoch 1601/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0193 - mae: 0.0859 - val_loss: 0.0211 - val_mae: 0.1260\n",
            "Epoch 1602/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0219 - mae: 0.1039 - val_loss: 0.0154 - val_mae: 0.0959\n",
            "Epoch 1603/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0167 - mae: 0.0794 - val_loss: 0.0110 - val_mae: 0.0649\n",
            "Epoch 1604/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0169 - mae: 0.0782 - val_loss: 0.0151 - val_mae: 0.0804\n",
            "Epoch 1605/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0176 - mae: 0.0832 - val_loss: 0.0079 - val_mae: 0.0392\n",
            "Epoch 1606/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.0652 - val_loss: 0.0084 - val_mae: 0.0455\n",
            "Epoch 1607/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0140 - mae: 0.0603 - val_loss: 0.0159 - val_mae: 0.0973\n",
            "Epoch 1608/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0159 - mae: 0.0750 - val_loss: 0.0106 - val_mae: 0.0601\n",
            "Epoch 1609/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0156 - mae: 0.0735 - val_loss: 0.0095 - val_mae: 0.0604\n",
            "Epoch 1610/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0143 - mae: 0.0672 - val_loss: 0.0088 - val_mae: 0.0499\n",
            "Epoch 1611/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0127 - mae: 0.0554 - val_loss: 0.0077 - val_mae: 0.0384\n",
            "Epoch 1612/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0125 - mae: 0.0554 - val_loss: 0.0074 - val_mae: 0.0378\n",
            "Epoch 1613/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0129 - mae: 0.0599 - val_loss: 0.0117 - val_mae: 0.0790\n",
            "Epoch 1614/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0155 - mae: 0.0813 - val_loss: 0.0089 - val_mae: 0.0658\n",
            "Epoch 1615/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0145 - mae: 0.0741 - val_loss: 0.0113 - val_mae: 0.0776\n",
            "Epoch 1616/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0153 - mae: 0.0805 - val_loss: 0.0140 - val_mae: 0.0821\n",
            "Epoch 1617/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0151 - mae: 0.0784 - val_loss: 0.0110 - val_mae: 0.0633\n",
            "Epoch 1618/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0148 - mae: 0.0752 - val_loss: 0.0114 - val_mae: 0.0702\n",
            "Epoch 1619/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0133 - mae: 0.0729 - val_loss: 0.0190 - val_mae: 0.1074\n",
            "Epoch 1620/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0179 - mae: 0.0976 - val_loss: 0.0198 - val_mae: 0.1160\n",
            "Epoch 1621/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0220 - mae: 0.1072 - val_loss: 0.0123 - val_mae: 0.0749\n",
            "Epoch 1622/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0176 - mae: 0.0928 - val_loss: 0.0109 - val_mae: 0.0677\n",
            "Epoch 1623/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0129 - mae: 0.0708 - val_loss: 0.0092 - val_mae: 0.0648\n",
            "Epoch 1624/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0131 - mae: 0.0710 - val_loss: 0.0113 - val_mae: 0.0657\n",
            "Epoch 1625/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0137 - mae: 0.0746 - val_loss: 0.0195 - val_mae: 0.1142\n",
            "Epoch 1626/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0142 - mae: 0.0780 - val_loss: 0.0102 - val_mae: 0.0583\n",
            "Epoch 1627/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0114 - mae: 0.0605 - val_loss: 0.0056 - val_mae: 0.0310\n",
            "Epoch 1628/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0107 - mae: 0.0596 - val_loss: 0.0165 - val_mae: 0.1000\n",
            "Epoch 1629/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0166 - mae: 0.0941 - val_loss: 0.0224 - val_mae: 0.1239\n",
            "Epoch 1630/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0176 - mae: 0.0978 - val_loss: 0.0213 - val_mae: 0.1230\n",
            "Epoch 1631/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0190 - mae: 0.1002 - val_loss: 0.0124 - val_mae: 0.0887\n",
            "Epoch 1632/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0156 - mae: 0.0912 - val_loss: 0.0065 - val_mae: 0.0489\n",
            "Epoch 1633/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0143 - mae: 0.0841 - val_loss: 0.0123 - val_mae: 0.0764\n",
            "Epoch 1634/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0126 - mae: 0.0741 - val_loss: 0.0100 - val_mae: 0.0701\n",
            "Epoch 1635/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0115 - mae: 0.0659 - val_loss: 0.0061 - val_mae: 0.0496\n",
            "Epoch 1636/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.0559 - val_loss: 0.0052 - val_mae: 0.0338\n",
            "Epoch 1637/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0470 - val_loss: 0.0053 - val_mae: 0.0370\n",
            "Epoch 1638/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0482 - val_loss: 0.0048 - val_mae: 0.0285\n",
            "Epoch 1639/1650\n",
            "10/10 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0468 - val_loss: 0.0058 - val_mae: 0.0394\n",
            "Epoch 1640/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0469 - val_loss: 0.0056 - val_mae: 0.0366\n",
            "Epoch 1641/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0460 - val_loss: 0.0050 - val_mae: 0.0329\n",
            "Epoch 1642/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0075 - mae: 0.0430 - val_loss: 0.0045 - val_mae: 0.0290\n",
            "Epoch 1643/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0082 - mae: 0.0493 - val_loss: 0.0045 - val_mae: 0.0307\n",
            "Epoch 1644/1650\n",
            "10/10 [==============================] - 0s 8ms/step - loss: 0.0070 - mae: 0.0392 - val_loss: 0.0043 - val_mae: 0.0337\n",
            "Epoch 1645/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0083 - mae: 0.0552 - val_loss: 0.0126 - val_mae: 0.0948\n",
            "Epoch 1646/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0127 - mae: 0.0825 - val_loss: 0.0043 - val_mae: 0.0257\n",
            "Epoch 1647/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.0644 - val_loss: 0.0108 - val_mae: 0.0744\n",
            "Epoch 1648/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0094 - mae: 0.0670 - val_loss: 0.0065 - val_mae: 0.0547\n",
            "Epoch 1649/1650\n",
            "10/10 [==============================] - 0s 9ms/step - loss: 0.0088 - mae: 0.0608 - val_loss: 0.0081 - val_mae: 0.0716\n",
            "Epoch 1650/1650\n",
            "10/10 [==============================] - 0s 7ms/step - loss: 0.0121 - mae: 0.0797 - val_loss: 0.0161 - val_mae: 0.1048\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mc_CQu2_IvOP"
      },
      "source": [
        "### 3. Plot Metrics\n",
        "Each training epoch, the model prints out its loss and mean absolute error for training and validation. You can read this in the output above (note that your exact numbers may differ): \n",
        "\n",
        "```\n",
        "Epoch 500/500\n",
        "600/600 [==============================] - 0s 51us/sample - loss: 0.0118 - mae: 0.0873 - val_loss: 0.0105 - val_mae: 0.0832\n",
        "```\n",
        "\n",
        "You can see that we've already got a huge improvement - validation loss has dropped from 0.15 to 0.01, and validation MAE has dropped from 0.33 to 0.08.\n",
        "\n",
        "The following cell will print the same graphs we used to evaluate our original model, but showing our new training history:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYHGswAJJgrC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "outputId": "72e04a43-2d5b-4ab5-d38f-877b09dfcd1b"
      },
      "source": [
        "# Draw a graph of the loss, which is the distance between\n",
        "# the predicted and actual values during training and validation.\n",
        "loss = history_2.history['loss']\n",
        "val_loss = history_2.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "plt.plot(epochs, loss, 'g.', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Exclude the first few epochs so the graph is easier to read\n",
        "SKIP = 100\n",
        "\n",
        "plt.clf()\n",
        "\n",
        "plt.plot(epochs[SKIP:], loss[SKIP:], 'g.', label='Training loss')\n",
        "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.clf()\n",
        "\n",
        "# Draw a graph of mean absolute error, which is another way of\n",
        "# measuring the amount of error in the prediction.\n",
        "mae = history_2.history['mae']\n",
        "val_mae = history_2.history['val_mae']\n",
        "\n",
        "plt.plot(epochs[SKIP:], mae[SKIP:], 'g.', label='Training MAE')\n",
        "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
        "plt.title('Training and validation mean absolute error')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('MAE')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU5fn//9eVhLAF2UUlYEDBFQkQwIhLFHetC67UCmjrVlur1opdLHxsbW1r+/PDr2qLO0qlfmprsWJFkIhLVBaRTSyIoYCIGASCLFm4vn+ckzAzmaxkMgm+n4/HPGbmnjNnrjmEvHPf55z7mLsjIiJSk5RkFyAiIs2fwkJERGqlsBARkVopLEREpFYKCxERqZXCQkREaqWwkCZnZi+b2djGXjaZzKzQzE5PwHrdzA4PH//JzO6uy7IN+JyrzGxmQ+usYb15ZrausdcrTS8t2QVIy2Bm2yOetgN2A+Xh8xvcfWpd1+Xu5yRi2f2du9/YGOsxsyzgE6CVu5eF654K1PnfUL5+FBZSJ+6eUfHYzAqB77j7rNjlzCyt4heQiOw/NAwl+6RimMHMxpvZZ8ATZtbZzP5lZpvM7MvwcWbEe/LN7Dvh43Fm9qaZ3R8u+4mZndPAZfuY2VwzKzazWWb2oJk9U03ddanxF2b2Vri+mWbWLeL1q81sjZkVmdlPa9g+w83sMzNLjWi72MwWh4+HmVmBmW0xsw1m9kczS69mXU+a2S8jnv8ofM+nZnZtzLLnmdn7ZrbNzNaa2cSIl+eG91vMbLuZ5VZs24j3n2Bm88xsa3h/Ql23TU3M7Kjw/VvMbJmZXRDx2rlmtjxc53ozuyNs7xb++2wxs81m9oaZ6XdXE9MGl8ZwENAFOBS4nuDn6onweW9gJ/DHGt4/HPgI6Ab8FnjMzKwBy/4FeA/oCkwErq7hM+tS4zeBa4ADgXSg4pfX0cDD4foPCT8vkzjc/V3gK+C0mPX+JXxcDtwWfp9cYCTw3RrqJqzh7LCeM4B+QOz+kq+AMUAn4DzgJjO7KHzt5PC+k7tnuHtBzLq7AC8Bk8Lv9gfgJTPrGvMdqmybWmpuBbwIzAzf931gqpkdES7yGMGQZgfgWOC1sP2HwDqgO9AD+AmgeYqamMJCGsMeYIK773b3ne5e5O7Pu/sOdy8G7gVOqeH9a9z9EXcvB54CDib4pVDnZc2sNzAU+Lm7l7j7m8D06j6wjjU+4e7/cfedwHNAdth+KfAvd5/r7ruBu8NtUJ1ngdEAZtYBODdsw90XuPs77l7m7oXAn+PUEc/lYX1L3f0rgnCM/H757r7E3fe4++Lw8+qyXgjCZaW7Px3W9SywAvhGxDLVbZuaHA9kAPeF/0avAf8i3DZAKXC0mR3g7l+6+8KI9oOBQ9291N3fcE1q1+QUFtIYNrn7roonZtbOzP4cDtNsIxj26BQ5FBPjs4oH7r4jfJhRz2UPATZHtAGsra7gOtb4WcTjHRE1HRK57vCXdVF1n0XQixhlZq2BUcBCd18T1tE/HGL5LKzjVwS9jNpE1QCsifl+w81sTjjMthW4sY7rrVj3mpi2NUDPiOfVbZtaa3b3yGCNXO8lBEG6xsxeN7PcsP13wCpgppmtNrO76vY1pDEpLKQxxP6V90PgCGC4ux/A3mGP6oaWGsMGoIuZtYto61XD8vtS44bIdYef2bW6hd19OcEvxXOIHoKCYDhrBdAvrOMnDamBYCgt0l8Iela93L0j8KeI9db2V/mnBMNzkXoD6+tQV23r7RWzv6Fyve4+z90vJBiieoGgx4K7F7v7D929L3ABcLuZjdzHWqSeFBaSCB0I9gFsCce/JyT6A8O/1OcDE80sPfyr9Bs1vGVfavwbcL6ZnRjujL6H2v8v/QX4AUEo/V9MHduA7WZ2JHBTHWt4DhhnZkeHYRVbfweCntYuMxtGEFIVNhEMm/WtZt0zgP5m9k0zSzOzK4CjCYaM9sW7BL2QO82slZnlEfwbTQv/za4ys47uXkqwTfYAmNn5ZnZ4uG9qK8F+npqG/SQBFBaSCA8AbYEvgHeAfzfR515FsJO4CPgl8FeC80HiaXCN7r4MuJkgADYAXxLsgK1JxT6D19z9i4j2Owh+kRcDj4Q116WGl8Pv8BrBEM1rMYt8F7jHzIqBnxP+lR6+dwfBPpq3wiOMjo9ZdxFwPkHvqwi4Ezg/pu56c/cSgnA4h2C7PwSMcfcV4SJXA4XhcNyNBP+eEOzAnwVsBwqAh9x9zr7UIvVn2k8k+ysz+yuwwt0T3rMR2d+pZyH7DTMbamaHmVlKeGjphQRj3yKyj3QGt+xPDgL+TrCzeR1wk7u/n9ySRPYPGoYSEZFaaRhKRERqtV8OQ3Xr1s2zsrKSXYaISIuyYMGCL9y9e7zX9suwyMrKYv78+ckuQ0SkRTGz2DP3K2kYSkREaqWwEBGRWiksRESkVvvlPgsRaXqlpaWsW7eOXbt21b6wJFWbNm3IzMykVatWdX6PwkJEGsW6devo0KEDWVlZVH/tKkk2d6eoqIh169bRp0+fOr9Pw1Ai0ih27dpF165dFRTNnJnRtWvXevcAFRYi0mgUFC1DQ/6dFBYRtm+Ha29dx3f//BQFawtqf4OIyNeEwiLCGx/P44n/zeRP0xcwcspIBYZIC1JUVER2djbZ2dkcdNBB9OzZs/J5SUlJje+dP38+t9xyS62fccIJJzRKrfn5+Zx//vmNsq6moh3cEQrWvwEMxctTKSkvIb8wn9xeubW+T0SSr2vXrixatAiAiRMnkpGRwR133FH5ellZGWlp8X/l5eTkkJOTU+tnvP32241TbAuknkWEvMNGAGB70klPTScvKy+5BYns5wrWFvDrN36dsF78uHHjuPHGGxk+fDh33nkn7733Hrm5uQwaNIgTTjiBjz76CIj+S3/ixIlce+215OXl0bdvXyZNmlS5voyMjMrl8/LyuPTSSznyyCO56qqrqJjBe8aMGRx55JEMGTKEW265pdYexObNm7nooos47rjjOP7441m8eDEAr7/+emXPaNCgQRQXF7NhwwZOPvlksrOzOfbYY3njjTcafZtVRz2LCCOyhgNwRtY5TBxzkXoVIglUsLaAkVNGUlJeQnpqOrPHzE7I/7l169bx9ttvk5qayrZt23jjjTdIS0tj1qxZ/OQnP+H555+v8p4VK1YwZ84ciouLOeKII7jpppuqnJPw/vvvs2zZMg455BBGjBjBW2+9RU5ODjfccANz586lT58+jB49utb6JkyYwKBBg3jhhRd47bXXGDNmDIsWLeL+++/nwQcfZMSIEWzfvp02bdowefJkzjrrLH76059SXl7Ojh07Gm071UZhEaHiZ2FEZh65vZJbi8j+Lr8wn5LyEsq9PKHDvpdddhmpqakAbN26lbFjx7Jy5UrMjNLS0rjvOe+882jdujWtW7fmwAMPZOPGjWRmZkYtM2zYsMq27OxsCgsLycjIoG/fvpXnL4wePZrJkyfXWN+bb75ZGVinnXYaRUVFbNu2jREjRnD77bdz1VVXMWrUKDIzMxk6dCjXXnstpaWlXHTRRWRnZ+/TtqkPDUNFSEkBM6jm50dEGlFeVh7pqemkWmpCh33bt29f+fjuu+/m1FNPZenSpbz44ovVnmvQunXrysepqamUlZU1aJl9cdddd/Hoo4+yc+dORowYwYoVKzj55JOZO3cuPXv2ZNy4cUyZMqVRP7Mm6lnEaNUKGvnfXETiyO2Vy+wxs8kvzCcvK69Jhn23bt1Kz549AXjyyScbff1HHHEEq1evprCwkKysLP7617/W+p6TTjqJqVOncvfdd5Ofn0+3bt044IAD+PjjjxkwYAADBgxg3rx5rFixgrZt25KZmcl1113H7t27WbhwIWPGjGn07xGPwiJGWpp6FiJNJbdXbpPuG7zzzjsZO3Ysv/zlLznvvPMaff1t27bloYce4uyzz6Z9+/YMHTq01vdU7FA/7rjjaNeuHU899RQADzzwAHPmzCElJYVjjjmGc845h2nTpvG73/2OVq1akZGR0aQ9i/3yGtw5OTne0IsfdeoE48bBAw80bk0i+7sPP/yQo446KtllJN327dvJyMjA3bn55pvp168ft912W7LLqiLev5eZLXD3uMcQa59FrJRS3lmzQCfkiUiDPPLII2RnZ3PMMcewdetWbrjhhmSX1CgUFhEK1hawtbSI99bqDG4RaZjbbruNRYsWsXz5cqZOnUq7du2SXVKjUFhEyC/Mh5RSvDyt8lA+ERHRDu4oeVl5WGoZeCudwS0iEkFhESG3Vy6ZnXbSudsQ/pSgs0lFRFoihUWMDm3b0r/z0TqDW0QkgvZZxNB5FiIt06mnnsorr7wS1fbAAw9w0003VfuevLw8Kg6zP/fcc9myZUuVZSZOnMj9999f42e/8MILLF++vPL5z3/+c2bNmlWf8uNqTlOZKyxi6AxukZZp9OjRTJs2Lapt2rRpdZrMD4LZYjt16tSgz44Ni3vuuYfTTz+9QetqrhQWMdSzEGmZLr30Ul566aXKCx0VFhby6aefctJJJ3HTTTeRk5PDMcccw4QJE+K+Pysriy+++AKAe++9l/79+3PiiSdWTmMOwTkUQ4cOZeDAgVxyySXs2LGDt99+m+nTp/OjH/2I7OxsPv74Y8aNG8ff/vY3AGbPns2gQYMYMGAA1157Lbt37678vAkTJjB48GAGDBjAihUravx+yZ7KXPssYuzas41NX2ymYO0G7eAWaaBbb4XwOkSNJju75pkVunTpwrBhw3j55Ze58MILmTZtGpdffjlmxr333kuXLl0oLy9n5MiRLF68mOOOOy7uehYsWMC0adNYtGgRZWVlDB48mCFDhgAwatQorrvuOgB+9rOf8dhjj/H973+fCy64gPPPP59LL700al27du1i3LhxzJ49m/79+zNmzBgefvhhbr31VgC6devGwoULeeihh7j//vt59NFHq/1+yZ7KXD2LCAVrC1jyxfusLlqrk/JEWqDIoajIIajnnnuOwYMHM2jQIJYtWxY1ZBTrjTfe4OKLL6Zdu3YccMABXHDBBZWvLV26lJNOOokBAwYwdepUli1bVmM9H330EX369KF///4AjB07lrlz51a+PmrUKACGDBlCYWFhjet68803ufrqq4H4U5lPmjSJLVu2kJaWxtChQ3niiSeYOHEiS5YsoUOHDjWuuy7Us4iQX5jPnpQcKG2vy6qK7INkza124YUXctttt7Fw4UJ27NjBkCFD+OSTT7j//vuZN28enTt3Zty4cdVOTV6bcePG8cILLzBw4ECefPJJ8vPz96neimnO92WK87vuuovzzjuPGTNmMGLECF555ZXKqcxfeuklxo0bx+23377Ps9MmrGdhZr3MbI6ZLTezZWb2g7C9i5m9amYrw/vOYbuZ2SQzW2Vmi81scMS6xobLrzSzsYmqOS8rj5TUPbBHJ+WJtEQZGRmceuqpXHvttZW9im3bttG+fXs6duzIxo0befnll2tcx8knn8wLL7zAzp07KS4u5sUXX6x8rbi4mIMPPpjS0lKmTp1a2d6hQweKi4urrOuII46gsLCQVatWAfD0009zyimnNOi7VUxlDsSdynz8+PEMHTqUFStWsGbNGnr06MF1113Hd77zHRYuXNigz4yUyJ5FGfBDd19oZh2ABWb2KjAOmO3u95nZXcBdwHjgHKBfeBsOPAwMN7MuwAQgB/BwPdPd/cvGLji3Vy4nHLqZjwtLeF4n5Ym0SKNHj+biiy+uHI4aOHAggwYN4sgjj6RXr16MGDGixvcPHjyYK664goEDB3LggQdGTTP+i1/8guHDh9O9e3eGDx9eGRBXXnkl1113HZMmTarcsQ3Qpk0bnnjiCS677DLKysoYOnQoN954Y4O+V7KnMm+yKcrN7J/AH8NbnrtvMLODgXx3P8LM/hw+fjZc/iMgr+Lm7jeE7VHLxbMvU5Rfcgl89BEsXdqgt4t8bWmK8palWU5RbmZZwCDgXaCHu28IX/oM6BE+7gmsjXjburCtuvbYz7jezOab2fxNmzY1uFadZyEiUlXCw8LMMoDngVvdfVvkax50axqla+Puk909x91zunfv3uD16DwLEZGqEhoWZtaKICimuvvfw+aN4fAT4f3nYft6IHJGpsywrbr2hFDPQqTh9scrb+6PGvLvlMijoQx4DPjQ3f8Q8dJ0oOKIprHAPyPax4RHRR0PbA2Hq14BzjSzzuGRU2eGbQlRtGsjX35VrHMsROqpTZs2FBUVKTCaOXenqKiINm3a1Ot9iTwaagRwNbDEzCrO5fwJcB/wnJl9G1gDXB6+NgM4F1gF7ACuAXD3zWb2C2BeuNw97r45EQUXrC1gxuollO+6iJFTRjJbR0SJ1FlmZibr1q1jX/YZStNo06YNmZmZ9XpPwsLC3d8ErJqXR8ZZ3oGbq1nX48DjjVddfPmF+eyxDChvpZPyROqpVatW9OnTJ9llSIJouo8IeVl5pKbtgT1pOilPRCSCwiJCbq9crhhwKWm01RCUiEgEzQ0VI6trT7wcBYWISAT1LGKkpUF5OeiADhGRvRQWMVq1Cu51roWIyF4Kixhp4cCczuIWEdlLYRFDPQsRkaoUFjHUsxARqUphEUM9CxGRqhQWMdZs+xiAd9YsSHIlIiLNh8IiQsHaAv7w3m8AuOK5qzSZoIhISGERIb8wnzKCC7mXlgbPRUREYRElLyuvcgd3K9pqbigRkZDCIkJur1x+fsrPAHjsG09oyg8RkZDCIsZRPfoDcFyP7CRXIiLSfCgsYqSEW2TPnuTWISLSnCgsYlSERXl5cusQEWlOFBYxUlODe/UsRET2UljE0DCUiEhVCosYGoYSEalKYRFDw1AiIlUpLGJoGEpEpCqFRQwNQ4mIVKWwiKFhKBGRqhQWMSp6FlM/eFazzoqIhBQWMZZvWgLAk+9PYeSUkQoMEREUFlW8v3EhEAxDlZSXaJpyEREUFlXkZA4CIIVWpKema5pyEREUFlVkH3wcAFcdezWzx8zWNOUiIkBasgtobip2cI868jJyeyW3FhGR5kI9ixg6dFZEpCqFRQydwS0iUpXCIobO4BYRqUphEUPDUCIiVSUsLMzscTP73MyWRrRNNLP1ZrYovJ0b8dqPzWyVmX1kZmdFtJ8dtq0ys7sSVW8FDUOJiFSVyJ7Fk8DZcdr/P3fPDm8zAMzsaOBK4JjwPQ+ZWaqZpQIPAucARwOjw2UTRsNQIiJVJezQWXefa2ZZdVz8QmCau+8GPjGzVcCw8LVV7r4awMymhcsub+RyK2kYSkSkqmTss/iemS0Oh6k6h209gbURy6wL26prr8LMrjez+WY2f9OmTQ0uTsNQIiJVNXVYPAwcBmQDG4DfN9aK3X2yu+e4e0737t0bvB4NQ4mIVNWkZ3C7+8aKx2b2CPCv8Ol6IPJ86cywjRraE0LDUCIiVTVpz8LMDo54ejFQcaTUdOBKM2ttZn2AfsB7wDygn5n1MbN0gp3g0xNZo4ahRESqSljPwsyeBfKAbma2DpgA5JlZNuBAIXADgLsvM7PnCHZclwE3u3t5uJ7vAa8AqcDj7r4sUTWDhqFEROJJ5NFQo+M0P1bD8vcC98ZpnwHMaMTSaqRhKBGRqnQGdwwNQ4mIVKWwiFERFjNXztYlVUVEQgqLGPM+fReAf6+cqWtwi4iEFBYx3lo3FwB3XYNbRKSCwiLGKVknAWCepmtwi4iEFBYxTjj0eABGZp2pa3CLiIR0De4YFYfOntT7FF2DW0QkpJ5FDLPgXofOiojspbCIYRbcdAa3iMheCos4UlPVsxARiaSwiCMlRT0LEZFICos4UlKC8yxERCSgsIgjJUXDUCIikRQWcSgsRESiKSziUFiIiERTWMShsBARiaawiMNMYSEiEklhEYeOhhIRiVansDCz9maWEj7ub2YXmFmrxJaWPBqGEhGJVteexVygjZn1BGYCVwNPJqqoZFNYiIhEq2tYmLvvAEYBD7n7ZcAxiSsruRQWIiLR6hwWZpYLXAW8FLalJqak5FNYiIhEq2tY3Ar8GPiHuy8zs77AnMSVlVwKCxGRaHW6+JG7vw68DhDu6P7C3W9JZGHJpLAQEYlW16Oh/mJmB5hZe2ApsNzMfpTY0pJHYSEiEq2uw1BHu/s24CLgZaAPwRFR+6WSPbtY8tlSCtYWJLsUEZFmoa5h0So8r+IiYLq7lwL75WlrBWsL+HT7Wj74bAkjp4xUYIiIUPew+DNQCLQH5prZocC2RBWVTPmF+Th78D1GSXkJ+YX5yS5JRCTp6rqDexIwKaJpjZmdmpiSkisvKw9LcSCF9NR08rLykl2SiEjS1SkszKwjMAE4OWx6HbgH2JqgupImt1cuWZ120L67M3nMbHJ75Sa7JBGRpKvrMNTjQDFweXjbBjyRqKKSrX3rdvTvcpSCQkQkVKeeBXCYu18S8fx/zGxRIgpqDnTorIhItLr2LHaa2YkVT8xsBLAzMSUln8JCRCRaXXsWNwJTwn0XAF8CYxNTUvIpLEREotX1aKgPgIFmdkD4fJuZ3QosTmRxyaKwEBGJVq8r5bn7tvBMboDba1rWzB43s8/NbGlEWxcze9XMVob3ncN2M7NJZrbKzBab2eCI94wNl19pZk3Sm1FYiIhE25fLqlotrz8JnB3Tdhcw2937AbPD5wDnAP3C2/XAwxCEC8Ehu8OBYcCEioBJJIWFiEi0fQmLGqf7cPe5wOaY5guBp8LHTxFMH1LRPsUD7wCdzOxg4CzgVXff7O5fAq9SNYAanZnCQkQkUo37LMysmPihYEDbBnxeD3ffED7+DOgRPu4JrI1Ybl3YVl17vFqvJ+iV0Lt37waUtpd6FiIi0WoMC3fvkKgPdnc3s0abjNDdJwOTAXJycvZpvSkp4PvlNIkiIg2zL8NQDbExHF4ivP88bF8P9IpYLjNsq649odSzEBGJ1tRhMZ2952eMBf4Z0T4mPCrqeGBrOFz1CnCmmXUOd2yfGbYllMJCRCRaXU/KqzczexbIA7qZ2TqCo5ruA54zs28DawjmmQKYAZwLrAJ2ANcAuPtmM/sFMC9c7h53j91p3ugUFiIi0RIWFu4+upqXRsZZ1oGbq1nP4wQTGTYZhYWISLSmHoZqERQWIiLRFBZxKCxERKIpLOJQWIiIRFNYxKGwEBGJprCIQ9N9iIhEU1jEoZ6FiEg0hUUcmu5DRCSawiIO9SxERKIpLOL4ctcXbNr+BQVrC5JdiohIs6CwiFGwtoD8Na+x6asiRk4ZqcAQEUFhUUV+YT57KANPoaS8hPzC/GSXJCKSdAqLGHlZeaSkAJ5Cemo6eVl5yS5JRCTpFBYxcnvlcubhp9O5dVdmj5lNbq/cZJckIpJ0CZt1tiXr0eFAOqSjoBARCalnEYcOnRURiaawiEPTfYiIRFNYxKEzuEVEoiks4tAwlIhINIVFHAoLEZFoCos4FBYiItEUFnEoLEREoiks4lBYiIhEU1jEobAQEYmmsIhDYSEiEk1hEYfCQkQkmsIiDoWFiEg0hUUcmu5DRCSawiIOTfchIhJNYRGHhqFERKIpLOJQWIiIRFNYxJESbhUNRYmIBBQWcVSEhXoXIiIBhUUc64r/C8Dba95JciUiIs2DwiJGwdoCHl/0KABnPn02BWsLklyRiEjyJSUszKzQzJaY2SIzmx+2dTGzV81sZXjfOWw3M5tkZqvMbLGZDU5kbfmF+ZR7KQAlZWXkF+Yn8uNERFqEZPYsTnX3bHfPCZ/fBcx2937A7PA5wDlAv/B2PfBwIovKy8ojNdUASE9pQ15WXiI/TkSkRWhOw1AXAk+Fj58CLopon+KBd4BOZnZwoorI7ZXLjTnXA/DilS+R2ys3UR8lItJiJCssHJhpZgvM7PqwrYe7bwgffwb0CB/3BNZGvHdd2BbFzK43s/lmNn/Tpk37VFyfLlkADD1k+D6tR0Rkf5GWpM890d3Xm9mBwKtmtiLyRXd3M6vXWQ7uPhmYDJCTk7NPZ0joPAsRkWhJ6Vm4+/rw/nPgH8AwYGPF8FJ4/3m4+HqgV8TbM8O2hNF5FiIi0Zo8LMysvZl1qHgMnAksBaYDY8PFxgL/DB9PB8aER0UdD2yNGK5KiNTU4L60NJGfIiLSciRjGKoH8A8zq/j8v7j7v81sHvCcmX0bWANcHi4/AzgXWAXsAK5JdIHp6cG9wkJEJNDkYeHuq4GBcdqLgJFx2h24uQlKq1QRFiUlTfmpIiLNV3M6dLbZUFiIiERTWMShYSgRkWgKizgqwuLP7z6huaFERFBYxLVq63IAHn73MUZOGanAEJGvPYVFHMuK3gdgT2krdpft1mSCIvK1p7CII/PgcBzqqTns+dszPPjUZ2zYALt3J7cuEZFkUVjE8ULRr+CMH0GPD2DpFax/7H855BBo0+1TLG8iPW8eo6EpEflaMd8PJ0DKycnx+fPnN/j9HX/dkW0l24Inu9vD+mFQ8ENYeV70gkc9T+qF3+XKoWfwzKhn9qFiEZHkM7MFEZeNiKKeRRzfOOIbe5+0/gr6zoGrzoeJBjcOhIOCfRp8eAnl921k6mVPYJdfSrt72zF+1vjkFC0ikkDqWVTjW3//FlOXTK1+gbJ0WHwVLPkmfHJ60HbQ+zDoMRgymWG9B/Hude/uUw0iIk2ppp6FwqIWwx8ZznufvlfzQh+fDvNvgA8vDZ633gpXjIK+r5HZIZPnLntOF1ESkWZPYdGIvvX3b/HskmfZQ5z5y7d3h+efhU/CKa7abYI7ekCKM+yQYeppiEizprBIkMkLJvPjWT9m867N0S+sOgOembn3+fhO0HYrAB3SOzCy70juPOFO9TZEpFlRWDSB8bPGM+mdSewq3xU0lKfBr7ZDeWvIfBu+cQP0WFqvdRpG27S2ZLTOYFz2OH5z+m8SULmISEBh0cTOevosZq4OexYLr4HpjwePBz0G59wCpe2g/RdNVk96ajp5h+aRlxXc1KMRkXgUFklSeUTVxyPh6VnRL/ZYBBuzoc1mOPtW6P0WtP8cWm8PhrF6zoO2W5JSt2Ec1vkwplw8RcEi8jWisEiy4Y8M572Vq+Gp1+DzAbUsvYcaT3/p9iHs6AY7ukPHQhjySNBT6f8v2JIFm46C7h/C1jODrSYAAA0uSURBVN7QdxZ0Xw4pZZBa1ijfJdVSOfbAY3n4vIcVJCL7GYVFM/Gtv3+Lvy75P8r2lMKaU+C/I6DrfyB/InhK8Av+wGXw6dCmKSjnIWi1E8rT4cT7YOMAaLsZDvogCJiUPeCA1b6qFFLo27kvp/c9nTEDxyhIRFoghUULVLC2gO++9F2Wr93AnvIUytI/h5Ry2N4j6EGsPBe29AkCZ08r2H5QcJ8IfWZBx//C8EnQdSWk76j1LTq/RKTlUVh8TRWsLeC3b/2W2Z/MpnjnDtiWCenb4ase8MmpsLsjrDkpuO/4X1h2Rf0/5NS7gyGwNScHvZKBVefIMozObTtz8qEn65BhkWZMYSF1VtGjWbRhCRQfDNt6Bj2ZT06DhdfXbSWXXQZ9XgvCww1Son/GWqe25gfH/0CHAos0MwoLaRSTF0xmwpwJbPxqI74rAz7Lhs+PhfevhQ1xf74CfWdC39lw7DTo9N+olxQcIs2HwkISqmBtAWP/MZaVn6+D1afB+uEw9+74Cx/1Nzjp13DIwiovaT+HSHIpLKRJnfX0Wby6+lW8tHWwn+TN8fD+d+IvnL4NbukH5a2g4/rK5i5tuvDr03/N9UPqOPQlIvtMYSFJU7EPZMnnSygvSQsOGX7mlerfcNMA6PoRpJUC0L5Ve24edjOdWnfS2eciCaawkGYjag6t98fCP5+Mv2DGhmBqlCOmg5VDajmtU1szZ+wcBYZIgigspFmqnLV352b46kBYPxRmPAhbD6268KH5cM2pGMZJh57EfSPvU2iINDKFhTR7UdcJ2XUAvPQgLPlW9EJtNsPIn8Kxz0LbrRzV7SiuPu5qDU+JNBKFhbQolRMwlrWCv02DFaOqLnT9EFj47SA8rBxrs50eGT34n7z/0U5xkQZSWEiLNH7WeO5/6/6gt7H6NJgyu/qFT/0Z5PwpOGz38JexFDij7xm8cnUNO9NFJIrCQlq08bPG8/u3fk855bA7Ax4tgE3HVv+GI/8Oo66OO4eVYQw9ZKgucSsSh8JC9gtVLmNbnhbM2Lv69KBHESl1d3BEVWk72HFg0DZganDtkGouPHV458N1DQ/5WlNYyH6l8ozxL1dGv7DrAPjvicGMvKtPh6Ij4q8g+3FovykIlKP+AW2LoOPaGqdiT0tJ44pjruCZUVUnShTZXygsZL82ecFkfvXGr/i0+FNK95RGv7jHYFdn+OBqWHFRcNGo4kOCtlgHLg5Co+Ma6FQIWa9Dmy1wwLoap2VXkMj+QmEhXzvDHxnOe5++F/9FJ5heZO0I+LJPMCXJ+uHBFQi3ZUJxz6rvSS8OAqTdF3DIPCg8FY5/AA6ZD51XV3slwrZpbfn+8O9rokRpEfaLsDCzs4H/BVKBR939vuqWVVhIdc56+ixmrp5Z80JlrWDDENjZBb7sC0X9YeNxQZhsOqbq8iklwfXTD1wWXGGwrA0MfgS6rQiGuzI2VJmmPR7NwCvJ1uLDwsxSgf8AZwDrgHnAaHdfHm95hYXUV+Xkh9Th/0NJ22B/yJYs2HIofHkYLL0CSjKgrF3V5a0ccPA06D0X2n4ZDG91WQkdPoW0XfW47Q4ud7s/cuJe/2S/tcfAU4PLGtfh6pN1tS9/dNQUFmn7XFnTGAascvfVAGY2DbgQiBsWIvVV0/kYVY7CSt8JBy8KbhXOvSW4d4IeyaajgisSbjk0mL5k/TBYlxv0UHZ32rdiU0r3hkfqbrA9YB58eNR9HXkdLrIepR7L12fdJR1gV0fI2BgM+9XnOzQlN8CgpH0Q3qkltSwLUdus4v1f9gn+gEjdHewXS93dKOXt7rGY35aPBmjUXmpL6VlcCpzt7t8Jn18NDHf370Uscz1wPUDv3r2HrFmzJim1ytdLlSCpj52dwt5Im+hbaduqbTXdsL2/gCLv6/XLtp6/BxKx7pRyaLcpOAihJKN+9TQ5D0Iagt5BlZcjt394H7XNHLb2hi6rgnnR2n4Z7EdrDF1XwsifcXjnw1l5y8ral4+wP/QsauXuk4HJEAxDJbkc+Zq4fsj11U4vMnnBZO6YeQfFJcXx39x2S3ATSYBRR8eZJmcftJSwWA/0inieGbaJNFs1BUmsfeqhiERI1IESLWUYKo1gB/dIgpCYB3zT3ZfFW147uEVE6q/FD0O5e5mZfQ94heDQ2cerCwoREWl8LSIsANx9BjAj2XWIiHwdpSS7ABERaf4UFiIiUiuFhYiI1EphISIitWoRh87Wl5ltAhp6Cnc3IP7VcZq/llq76m5aqrtptaS6D3X37vFe2C/DYl+Y2fzqjjNu7lpq7aq7aanuptVS646lYSgREamVwkJERGqlsKhqcrIL2ActtXbV3bRUd9NqqXVH0T4LERGplXoWIiJSK4WFiIjUSmERwczONrOPzGyVmd2V7HoimVkvM5tjZsvNbJmZ/SBsn2hm681sUXg7N+I9Pw6/y0dmdlYSay80syVhffPDti5m9qqZrQzvO4ftZmaTwroXm9ngJNV8RMQ2XWRm28zs1ua6vc3scTP73MyWRrTVexub2dhw+ZVmNjZJdf/OzFaEtf3DzDqF7VlmtjNi2/8p4j1Dwp+xVeF3q++1Yhuj7nr/bDTn3zlVuLtuwX6bVOBjoC+QDnwAHJ3suiLqOxgYHD7uQHB9j6OBicAdcZY/OvwOrYE+4XdLTVLthUC3mLbfAneFj+8CfhM+Phd4meCixccD7zaDbZ8KfAYc2ly3N3AyMBhY2tBtDHQBVof3ncPHnZNQ95lAWvj4NxF1Z0UuF7Oe98LvYuF3OycJddfrZ6O5/86JvalnsdcwYJW7r3b3EmAacGGSa6rk7hvcfWH4uBj4EOhZw1suBKa5+253/wRYRfAdm4sLgafCx08BF0W0T/HAO0AnMzs4GQVGGAl87O41zQqQ1O3t7nOB2Mvs1XcbnwW86u6b3f1L4FXg7Kau291nuntZ+PQdgitjVius/QB3f8eD385T2PtdE6Ka7V2d6n42mvXvnFgKi716Amsjnq+j5l/GSWNmWcAg4N2w6Xthl/3xiqEGmtf3cWCmmS0ws4rrjPZw9w3h48+AHuHj5lR3hSuBZyOeN/ftXaG+27g5fodrCXoKFfqY2ftm9rqZnRS29SSotUIy667Pz0Zz3N7VUli0MGaWATwP3Oru24CHgcOAbGAD8PsklledE919MHAOcLOZnRz5YvjXYLM8htvM0oELgP8Lm1rC9q6iOW/j6pjZT4EyYGrYtAHo7e6DgNuBv5jZAcmqL44W+bNRVwqLvdYDvSKeZ4ZtzYaZtSIIiqnu/ncAd9/o7uXuvgd4hL1DH83m+7j7+vD+c+AfBDVurBheCu8/DxdvNnWHzgEWuvtGaBnbO0J9t3Gz+Q5mNg44H7gqDDrCYZyi8PECgvH+/mGNkUNVSam7AT8bzWZ714XCYq95QD8z6xP+NXklMD3JNVUKj+54DPjQ3f8Q0R45nn8xUHF0xnTgSjNrbWZ9gH4EOwGblJm1N7MOFY8Jdl4uDeurONpmLPDP8PF0YEx4xM7xwNaIoZRkGE3EEFRz394x6ruNXwHONLPO4RDKmWFbkzKzs4E7gQvcfUdEe3czSw0f9yXYxqvD2reZ2fHh/5Mx7P2uTVl3fX82mvXvnCqSvYe9Od0IjhL5D8FfLD9Ndj0xtZ1IMIywGFgU3s4FngaWhO3TgYMj3vPT8Lt8RIKPDqmh7r4ER3l8ACyr2K5AV2A2sBKYBXQJ2w14MKx7CZCTxG3eHigCOka0NcvtTRBoG4BSgrHvbzdkGxPsI1gV3q5JUt2rCMbyK37O/xQue0n4M7QIWAh8I2I9OQS/nD8G/kg4O0UT113vn43m/Dsn9qbpPkREpFYahhIRkVopLEREpFYKCxERqZXCQkREaqWwEBGRWiksROrBzMotejbaRpspNJxVdWntS4o0vbRkFyDSwux09+xkFyHS1NSzEGkEFlyz47fhNRXeM7PDw/YsM3stnFxutpn1Dtt7hNdq+CC8nRCuKtXMHrHgmiUzzaxtuPwtFlzLZLGZTUvS15SvMYWFSP20jRmGuiLita3uPoDgDOIHwrb/H3jK3Y8jmBBvUtg+CXjd3QcSXBdhWdjeD3jQ3Y8BthCctQzB9SgGheu5MVFfTqQ6OoNbpB7MbLu7Z8RpLwROc/fV4YSPn7l7VzP7gmDah9KwfYO7dzOzTUCmu++OWEcWwfUk+oXPxwOt3P2XZvZvYDvwAvCCu29P8FcViaKehUjj8Woe18fuiMfl7N2veB7BfE6DgXlmpv2N0qQUFiKN54qI+4Lw8dsEs4kCXAW8ET6eDdwEYGapZtaxupWaWQrQy93nAOOBjkCV3o1IIumvE5H6aWtmiyKe/9vdKw6f7Wxmiwl6B6PDtu8DT5jZj4BNwDVh+w+AyWb2bYIexE0Es5jGkwo8EwaKAZPcfUujfSOROtA+C5FGEO6zyHH3L5Jdi0giaBhKRERqpZ6FiIjUSj0LERGplcJCRERqpbAQEZFaKSxERKRWCgsREanV/wMLaleEH09bhgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f86dWOyZKmN9"
      },
      "source": [
        "Great results! From these graphs, we can see several exciting things:\n",
        "\n",
        "*   Our network has reached its peak accuracy much more quickly (within 200 epochs instead of 500)\n",
        "*   The overall loss and MAE are much better than our previous network\n",
        "*   Metrics are better for validation than training, which means the network is not overfitting\n",
        "\n",
        "The reason the metrics for validation are better than those for training is that validation metrics are calculated at the end of each epoch, while training metrics are calculated throughout the epoch, so validation happens on a model that has been trained slightly longer.\n",
        "\n",
        "This all means our network seems to be performing well! To confirm, let's check its predictions against the test dataset we set aside earlier:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZfztKKyhLxX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "839cc5f0-3934-4b47-dad4-10e8208d8829"
      },
      "source": [
        "# Calculate and print the loss on our test dataset\n",
        "loss = model_2.evaluate(x_test, y_test)\n",
        "\n",
        "# Make predictions based on our test dataset\n",
        "predictions = model_2.predict(x_test)\n",
        "\n",
        "# Graph the predictions against the actual values\n",
        "plt.clf()\n",
        "plt.title('Comparison of predictions and actual values')\n",
        "plt.plot(x_test, y_test, 'b.', label='Actual')\n",
        "plt.plot(x_test, predictions, 'r.', label='Predicted')\n",
        "plt.xlabel('pH value')\n",
        "plt.ylabel('Pump speed')\n",
        "plt.xlim(max(x_values), min(x_values))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step - loss: 0.0163 - mae: 0.1064\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h7IcvuOOS4J"
      },
      "source": [
        "Much better! The evaluation metrics we printed show that the model has a low loss and MAE on the test data, and the predictions line up visually with our data fairly well.\n",
        "\n",
        "\n",
        "## Generate a TensorFlow Lite Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHe-Wv47rhm8"
      },
      "source": [
        "### 1. Generate Models with or without Quantization\n",
        "We now have an acceptably accurate model. We'll use the [TensorFlow Lite Converter](https://www.tensorflow.org/lite/convert) to convert the model into a special, space-efficient format for use on memory-constrained devices.\n",
        "\n",
        "Since this model is going to be deployed on a microcontroller, we want it to be as tiny as possible! One technique for reducing the size of models is called [quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) while converting the model. It reduces the precision of the model's weights, and possibly the activations (output of each layer) as well, which saves memory, often without much impact on accuracy. Quantized models also run faster, since the calculations required are simpler.\n",
        "\n",
        "*Note: Currently, TFLite Converter produces TFlite models with float interfaces (input and output ops are always float). This is a blocker for users who require TFlite models with pure int8 or uint8 inputs/outputs. Refer to https://github.com/tensorflow/tensorflow/issues/38285*\n",
        "\n",
        "In the following cell, we'll convert the model twice: once with quantization, once without."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1muAoUm8lSXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb052ce8-7f01-4949-c9e2-438878929092"
      },
      "source": [
        "# Convert the model to the TensorFlow Lite format without quantization\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_2)\n",
        "model_no_quant_tflite = converter.convert()\n",
        "\n",
        "# # Save the model to disk\n",
        "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)\n",
        "\n",
        "# Convert the model to the TensorFlow Lite format with quantization\n",
        "def representative_dataset():\n",
        "  for i in range(int(SAMPLES/2)):\n",
        "    yield([x_train[i].reshape(1, 1)])\n",
        "# Set the optimization flag.\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# Enforce full-int8 quantization (except inputs/outputs which are always float)\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# Provide a representative dataset to ensure we quantize correctly.\n",
        "converter.representative_dataset = representative_dataset\n",
        "model_tflite = converter.convert()\n",
        "\n",
        "# Save the model to disk\n",
        "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp3xiz8xqn/assets\n",
            "INFO:tensorflow:Assets written to: /tmp/tmpa23zowbc/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmpa23zowbc/assets\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7400"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8X1yO3h5pYbt"
      },
      "source": [
        "### 2. Compare Model Sizes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAIe0dK3pXU8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceb475da-928b-4f80-b7ae-19849d3f94c9"
      },
      "source": [
        "import os\n",
        "model_no_quant_size = os.path.getsize(MODEL_NO_QUANT_TFLITE)\n",
        "print(\"Model is %d bytes\" % model_no_quant_size)\n",
        "model_size = os.path.getsize(MODEL_TFLITE)\n",
        "print(\"Quantized model is %d bytes\" % model_size)\n",
        "difference = model_no_quant_size - model_size\n",
        "print(\"Difference is %d bytes\" % difference)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is 19124 bytes\n",
            "Quantized model is 7400 bytes\n",
            "Difference is 11724 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR2OuokFpkEM"
      },
      "source": [
        "Our quantized model is only 224 bytes smaller than the original version, which only a tiny reduction in size! At around 2.5 kilobytes, this model is already so small that the weights make up only a small fraction of the overall size, meaning quantization has little effect.\n",
        "\n",
        "More complex models have many more weights, meaning the space saving from quantization will be much higher, approaching 4x for most sophisticated models.\n",
        "\n",
        "Regardless, our quantized model will take less time to execute than the original version, which is important on a tiny microcontroller!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_vE-ZDkHVxe"
      },
      "source": [
        "### 3. Test the Models\n",
        "\n",
        "To prove these models are still accurate after conversion and quantization, we'll use both of them to make predictions and compare these against our test results:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J7IKlXiYVPz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b73dfc99-0987-462f-d0fb-b2b5d28140c3"
      },
      "source": [
        "# Instantiate an interpreter for each model\n",
        "model_no_quant = tf.lite.Interpreter(MODEL_NO_QUANT_TFLITE)\n",
        "model = tf.lite.Interpreter(MODEL_TFLITE)\n",
        "\n",
        "# Allocate memory for each model\n",
        "model_no_quant.allocate_tensors()\n",
        "model.allocate_tensors()\n",
        "\n",
        "# Get the input and output tensors so we can feed in values and get the results\n",
        "model_no_quant_input = model_no_quant.tensor(model_no_quant.get_input_details()[0][\"index\"])\n",
        "model_no_quant_output = model_no_quant.tensor(model_no_quant.get_output_details()[0][\"index\"])\n",
        "model_input = model.tensor(model.get_input_details()[0][\"index\"])\n",
        "model_output = model.tensor(model.get_output_details()[0][\"index\"])\n",
        "\n",
        "# Create arrays to store the results\n",
        "model_no_quant_predictions = np.empty(x_test.size)\n",
        "model_predictions = np.empty(x_test.size)\n",
        "\n",
        "# Run each model's interpreter for each value and store the results in arrays\n",
        "for i in range(x_test.size):\n",
        "  model_no_quant_input().fill(x_test[i])\n",
        "  model_no_quant.invoke()\n",
        "  model_no_quant_predictions[i] = model_no_quant_output()[0]\n",
        "\n",
        "  model_input().fill(x_test[i])\n",
        "  model.invoke()\n",
        "  model_predictions[i] = model_output()[0]\n",
        "\n",
        "# See how they line up with the data\n",
        "plt.clf()\n",
        "plt.title('Comparison of various models against actual values')\n",
        "plt.plot(x_test, y_test, 'bo', label='Actual predictions')\n",
        "plt.plot(x_test, predictions, 'ro', label='Original predictions')\n",
        "plt.plot(x_test, model_no_quant_predictions, 'bx', label='Lite predictions')\n",
        "plt.plot(x_test, model_predictions, 'gx', label='Lite quantized predictions')\n",
        "plt.xlabel('pH value')\n",
        "plt.ylabel('Pump speed')\n",
        "plt.xlim(max(x_values), min(x_values))\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWxvLGexKv0D"
      },
      "source": [
        "We can see from the graph that the predictions for the original model, the converted model, and the quantized model are all close enough to be indistinguishable. This means that our quantized model is ready to use!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPSFmDL7pv2L"
      },
      "source": [
        "## Generate a TensorFlow Lite for Microcontrollers Model\n",
        "Convert the TensorFlow Lite quantized model into a C source file that can be loaded by TensorFlow Lite for Microcontrollers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1FB4ieeg0lw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cfaff45-ccd7-4d6a-c882-5d6f674242bc"
      },
      "source": [
        "# Install xxd if it is not available\n",
        "!apt-get update && apt-get -qq install xxd\n",
        "# Convert to a C source file\n",
        "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
        "# Update variable names\n",
        "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
        "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 14.2 kB/88.7\r                                                                               \rHit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [1 InRelease 14.2 kB/88.7\r0% [2 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (91.189.88.152)\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [1 InRelease 43.1 kB/88.7 k\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r                                                                               \r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers]\r                                                                         \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers]\r                                                                         \rHit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 88.7 kB in 2s (40.7 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JvRy0ZyMhQOX"
      },
      "source": [
        "## Deploy to a Microcontroller\n",
        "\n",
        "Follow the instructions in the [hello_world](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro/examples/hello_world) README.md for [TensorFlow Lite for MicroControllers](https://www.tensorflow.org/lite/microcontrollers/overview) to deploy this model on a specific microcontroller.\n",
        "\n",
        "**Reference Model:** If you have not modified this notebook, you can follow the instructions as is, to deploy the model. Refer to the [`hello_world/train/models`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/train/models) directory to access the models generated in this notebook.\n",
        "\n",
        "**New Model:** If you have generated a new model, then update the values assigned to the variables defined in [`hello_world/model.cc`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/hello_world/model.cc) with values displayed after running the following cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4-WhtGpvb-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d863b38d-4973-4f35-b220-8e8f6c3c490f"
      },
      "source": [
        "# Print the C source file\n",
        "!cat {MODEL_TFLITE_MICRO}"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unsigned char g_model[] = {\n",
            "  0x1c, 0x00, 0x00, 0x00, 0x54, 0x46, 0x4c, 0x33, 0x14, 0x00, 0x20, 0x00,\n",
            "  0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
            "  0x18, 0x00, 0x1c, 0x00, 0x14, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00,\n",
            "  0x18, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0xc4, 0x00, 0x00, 0x00,\n",
            "  0x24, 0x00, 0x00, 0x00, 0x6c, 0x00, 0x00, 0x00, 0x64, 0x00, 0x00, 0x00,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x7c, 0x05, 0x00, 0x00, 0x94, 0x04, 0x00, 0x00,\n",
            "  0x84, 0x01, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0xc4, 0x00, 0x00, 0x00,\n",
            "  0x11, 0x00, 0x00, 0x00, 0x8c, 0x1c, 0x00, 0x00, 0x88, 0x1c, 0x00, 0x00,\n",
            "  0x80, 0x1b, 0x00, 0x00, 0x70, 0x1a, 0x00, 0x00, 0xf8, 0x11, 0x00, 0x00,\n",
            "  0x70, 0x10, 0x00, 0x00, 0xf8, 0x07, 0x00, 0x00, 0xf0, 0x06, 0x00, 0x00,\n",
            "  0x58, 0x06, 0x00, 0x00, 0xcc, 0x05, 0x00, 0x00, 0x64, 0x1c, 0x00, 0x00,\n",
            "  0x60, 0x1c, 0x00, 0x00, 0x5c, 0x1c, 0x00, 0x00, 0x58, 0x1c, 0x00, 0x00,\n",
            "  0x54, 0x1c, 0x00, 0x00, 0x50, 0x1c, 0x00, 0x00, 0x3c, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x08, 0x00, 0x0c, 0x00, 0x04, 0x00, 0x08, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x08, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x13, 0x00, 0x00, 0x00,\n",
            "  0x6d, 0x69, 0x6e, 0x5f, 0x72, 0x75, 0x6e, 0x74, 0x69, 0x6d, 0x65, 0x5f,\n",
            "  0x76, 0x65, 0x72, 0x73, 0x69, 0x6f, 0x6e, 0x00, 0xfa, 0xe4, 0xff, 0xff,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x31, 0x2e, 0x31, 0x34,\n",
            "  0x2e, 0x30, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x0f, 0x00, 0x00, 0x00, 0x4d, 0x4c, 0x49, 0x52, 0x20, 0x43, 0x6f, 0x6e,\n",
            "  0x76, 0x65, 0x72, 0x74, 0x65, 0x64, 0x2e, 0x00, 0x00, 0x00, 0x0e, 0x00,\n",
            "  0x18, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00,\n",
            "  0x0e, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x50, 0x00, 0x00, 0x00,\n",
            "  0x54, 0x00, 0x00, 0x00, 0x58, 0x00, 0x00, 0x00, 0x70, 0x00, 0x00, 0x00,\n",
            "  0x0f, 0x00, 0x00, 0x00, 0x6c, 0x1b, 0x00, 0x00, 0xe8, 0x1a, 0x00, 0x00,\n",
            "  0x28, 0x1a, 0x00, 0x00, 0x30, 0x19, 0x00, 0x00, 0xa8, 0x10, 0x00, 0x00,\n",
            "  0x30, 0x0f, 0x00, 0x00, 0xa8, 0x06, 0x00, 0x00, 0xb0, 0x05, 0x00, 0x00,\n",
            "  0x08, 0x05, 0x00, 0x00, 0x8c, 0x04, 0x00, 0x00, 0x90, 0x03, 0x00, 0x00,\n",
            "  0x84, 0x02, 0x00, 0x00, 0x90, 0x01, 0x00, 0x00, 0xf0, 0x00, 0x00, 0x00,\n",
            "  0x74, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
            "  0x14, 0x04, 0x00, 0x00, 0x14, 0x03, 0x00, 0x00, 0x20, 0x02, 0x00, 0x00,\n",
            "  0x2c, 0x01, 0x00, 0x00, 0x90, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x6d, 0x61, 0x69, 0x6e, 0x00, 0x00, 0x0a, 0x00,\n",
            "  0x10, 0x00, 0x04, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x0a, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x0d, 0x00, 0x00, 0x00, 0x1c, 0xfc, 0xff, 0xff, 0x06, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x06, 0x02, 0x00, 0x00, 0x00, 0x54, 0xe5, 0xff, 0xff,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x0f, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n",
            "  0x30, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x49, 0x64, 0x65, 0x6e, 0x74, 0x69, 0x74, 0x79, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x3c, 0xe5, 0xff, 0xff, 0x86, 0xfe, 0xff, 0xff, 0x00, 0x00, 0x00, 0x08,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x58, 0xe5, 0xff, 0xff, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x0d, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x07, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x88, 0xfc, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x14, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x00, 0x00,\n",
            "  0x18, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x09, 0x00, 0x00, 0x00, 0x49, 0x64, 0x65, 0x6e, 0x74, 0x69, 0x74, 0x79,\n",
            "  0x31, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x3c, 0xe6, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x5d, 0xcb, 0xc8, 0x3e,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x80, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,\n",
            "  0x1e, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x08, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x1c, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x1e, 0xfe, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00,\n",
            "  0x05, 0x00, 0x00, 0x00, 0x06, 0x00, 0x00, 0x00, 0x24, 0xfd, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x14, 0x00, 0x00, 0x00, 0x0d, 0x00, 0x00, 0x00,\n",
            "  0x18, 0x00, 0x00, 0x00, 0x74, 0x00, 0x00, 0x00, 0x64, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x4c, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x32, 0x2f, 0x4d,\n",
            "  0x61, 0x74, 0x4d, 0x75, 0x6c, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e,\n",
            "  0x74, 0x69, 0x61, 0x6c, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x32,\n",
            "  0x2f, 0x52, 0x65, 0x6c, 0x75, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e,\n",
            "  0x74, 0x69, 0x61, 0x6c, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x32,\n",
            "  0x2f, 0x42, 0x69, 0x61, 0x73, 0x41, 0x64, 0x64, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x1c, 0xe7, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x29, 0x28, 0x30, 0x3e, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x80, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x0e, 0x00,\n",
            "  0x18, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x07, 0x00, 0x14, 0x00,\n",
            "  0x0e, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x1c, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x0e, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x01, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x0b, 0x00, 0x00, 0x00, 0x03, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00, 0x14, 0xfe, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x14, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x18, 0x00, 0x00, 0x00, 0x74, 0x00, 0x00, 0x00, 0x64, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00,\n",
            "  0x4c, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x31, 0x2f, 0x4d,\n",
            "  0x61, 0x74, 0x4d, 0x75, 0x6c, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e,\n",
            "  0x74, 0x69, 0x61, 0x6c, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x31,\n",
            "  0x2f, 0x52, 0x65, 0x6c, 0x75, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e,\n",
            "  0x74, 0x69, 0x61, 0x6c, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x31,\n",
            "  0x2f, 0x42, 0x69, 0x61, 0x73, 0x41, 0x64, 0x64, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff, 0x40, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0xe8, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xe5, 0xfe, 0x10, 0x3d, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x80, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0x00, 0x00, 0x0e, 0x00,\n",
            "  0x1a, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x07, 0x00, 0x14, 0x00,\n",
            "  0x0e, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x08, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x24, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x07, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x01, 0x01, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x28, 0xff, 0xff, 0xff, 0x09, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x04, 0x00, 0x00, 0x00, 0x1c, 0xff, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x14, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00,\n",
            "  0x18, 0x00, 0x00, 0x00, 0x6c, 0x00, 0x00, 0x00, 0x5c, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x46, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x2f, 0x4d, 0x61, 0x74,\n",
            "  0x4d, 0x75, 0x6c, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x2f, 0x52, 0x65, 0x6c,\n",
            "  0x75, 0x3b, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c,\n",
            "  0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x2f, 0x42, 0x69, 0x61, 0x73, 0x41,\n",
            "  0x64, 0x64, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,\n",
            "  0x20, 0x00, 0x00, 0x00, 0x0c, 0xe9, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x3d, 0x55, 0xf7, 0x3c,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x80, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x0a, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x04, 0x00, 0x08, 0x00,\n",
            "  0x0a, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x0b, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x04, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x72, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x72, 0x01, 0x00, 0x00, 0x00, 0x14, 0x00, 0x1c, 0x00,\n",
            "  0x08, 0x00, 0x07, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x18, 0x00, 0x14, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x09,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x0a, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00,\n",
            "  0x34, 0x00, 0x00, 0x00, 0x24, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x74, 0x66, 0x6c, 0x2e, 0x71, 0x75, 0x61, 0x6e, 0x74, 0x69, 0x7a, 0x65,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0xff, 0xff, 0xff, 0xff,\n",
            "  0x01, 0x00, 0x00, 0x00, 0xcc, 0xe9, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0xe1, 0xe0, 0x60, 0x3d,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x80, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff,\n",
            "  0x6e, 0xea, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x87, 0x00, 0x00, 0x00, 0x4a, 0xea, 0xff, 0xff, 0x00, 0x00, 0x00, 0x02,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x09, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x44, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x32, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x33, 0x2f, 0x42,\n",
            "  0x69, 0x61, 0x73, 0x41, 0x64, 0x64, 0x2f, 0x52, 0x65, 0x61, 0x64, 0x56,\n",
            "  0x61, 0x72, 0x69, 0x61, 0x62, 0x6c, 0x65, 0x4f, 0x70, 0x2f, 0x72, 0x65,\n",
            "  0x73, 0x6f, 0x75, 0x72, 0x63, 0x65, 0x00, 0x00, 0x54, 0xea, 0xff, 0xff,\n",
            "  0x08, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x91, 0x32, 0x68, 0x3b, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0xf6, 0xea, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x20, 0x00, 0x00, 0x00, 0xf5, 0xf5, 0x22, 0x25, 0x21, 0x0f, 0x9f, 0x05,\n",
            "  0xf5, 0x0f, 0x00, 0x1c, 0xed, 0x24, 0x05, 0x8f, 0xfd, 0xf3, 0x0b, 0x00,\n",
            "  0xf5, 0xf9, 0x27, 0xfc, 0xf5, 0xff, 0x03, 0x1b, 0xfe, 0xfb, 0x81, 0xee,\n",
            "  0xee, 0xea, 0xff, 0xff, 0x00, 0x00, 0x00, 0x09, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x08, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x19, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x33, 0x2f, 0x4d,\n",
            "  0x61, 0x74, 0x4d, 0x75, 0x6c, 0x00, 0x00, 0x00, 0xe4, 0xea, 0xff, 0xff,\n",
            "  0x08, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x75, 0xb8, 0xa8, 0x3c, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x8a, 0xeb, 0xff, 0xff,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x5e, 0x02, 0x00, 0x00, 0x72, 0x02, 0x00, 0x00,\n",
            "  0x82, 0x02, 0x00, 0x00, 0xf0, 0xff, 0xff, 0xff, 0xdf, 0x04, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0xd2, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n",
            "  0xf4, 0xff, 0xff, 0xff, 0x50, 0x02, 0x00, 0x00, 0xf4, 0xff, 0xff, 0xff,\n",
            "  0x86, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xa6, 0x03, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0xd6, 0xff, 0xff, 0xff, 0xf6, 0xff, 0xff, 0xff, 0xdf, 0xff, 0xff, 0xff,\n",
            "  0x73, 0x02, 0x00, 0x00, 0x1b, 0x00, 0x00, 0x00, 0xd4, 0xff, 0xff, 0xff,\n",
            "  0xe7, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x76, 0x02, 0x00, 0x00,\n",
            "  0xe4, 0xff, 0xff, 0xff, 0xc8, 0xff, 0xff, 0xff, 0xf8, 0xfe, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x00, 0xe2, 0xeb, 0xff, 0xff, 0x00, 0x00, 0x00, 0x02,\n",
            "  0x10, 0x00, 0x00, 0x00, 0x07, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x44, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00,\n",
            "  0x32, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x32, 0x2f, 0x42,\n",
            "  0x69, 0x61, 0x73, 0x41, 0x64, 0x64, 0x2f, 0x52, 0x65, 0x61, 0x64, 0x56,\n",
            "  0x61, 0x72, 0x69, 0x61, 0x62, 0x6c, 0x65, 0x4f, 0x70, 0x2f, 0x72, 0x65,\n",
            "  0x73, 0x6f, 0x75, 0x72, 0x63, 0x65, 0x00, 0x00, 0xec, 0xeb, 0xff, 0xff,\n",
            "  0x08, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0xd1, 0x51, 0x5a, 0x3a, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x8e, 0xec, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x08, 0x00, 0x00, 0x07, 0x0a, 0xfe, 0xfb, 0x09, 0x08, 0x00, 0xf8,\n",
            "  0x06, 0xfe, 0xfa, 0xfc, 0xfb, 0xfd, 0x01, 0x09, 0x0a, 0x03, 0xf7, 0xf7,\n",
            "  0xfb, 0xf7, 0x06, 0x0a, 0xfb, 0xfa, 0x05, 0x05, 0xfa, 0x01, 0xf6, 0xfb,\n",
            "  0x08, 0x03, 0x04, 0x07, 0x07, 0xff, 0xf6, 0xfc, 0x0a, 0xfa, 0xfc, 0x03,\n",
            "  0x01, 0xf9, 0x03, 0xfa, 0xfc, 0xfc, 0xfb, 0xfb, 0xfb, 0xf8, 0xfd, 0x09,\n",
            "  0x07, 0x0a, 0xfd, 0x00, 0xfd, 0xfb, 0xfa, 0x0a, 0x03, 0x00, 0xfc, 0xfa,\n",
            "  0x06, 0xfe, 0xf6, 0xff, 0xf8, 0x02, 0xfa, 0x04, 0x01, 0x06, 0x01, 0x04,\n",
            "  0xfe, 0x02, 0x03, 0xfb, 0x00, 0xfe, 0xfc, 0xfe, 0xff, 0x05, 0xfc, 0xf9,\n",
            "  0xfb, 0xf8, 0xfd, 0xf6, 0x08, 0xfb, 0xfa, 0xfb, 0xff, 0xfa, 0x00, 0x0a,\n",
            "  0xf6, 0x06, 0xfd, 0x04, 0x04, 0x05, 0xfb, 0xf7, 0xf6, 0xfd, 0x0a, 0x00,\n",
            "  0x00, 0x06, 0x0a, 0xfd, 0xfb, 0x06, 0xf7, 0xff, 0xfa, 0xfc, 0x00, 0x08,\n",
            "  0x00, 0x01, 0x07, 0x05, 0x08, 0x11, 0x04, 0xfe, 0xf9, 0xf6, 0x07, 0x01,\n",
            "  0x04, 0xfb, 0xf8, 0x0f, 0x02, 0x07, 0x00, 0x06, 0xfe, 0xfd, 0xf3, 0xf9,\n",
            "  0x5e, 0x09, 0x09, 0x02, 0x11, 0x06, 0x02, 0xfe, 0x08, 0x05, 0xff, 0xfd,\n",
            "  0x01, 0xfe, 0x9d, 0xf8, 0xfa, 0xfc, 0x03, 0x0a, 0x07, 0x04, 0x03, 0x10,\n",
            "  0x7e, 0x46, 0x30, 0xfe, 0x0e, 0x0a, 0xfc, 0x0a, 0xfc, 0xfb, 0xff, 0x13,\n",
            "  0xa7, 0x07, 0x05, 0x04, 0xfe, 0x06, 0x10, 0x09, 0x14, 0x16, 0x08, 0x0d,\n",
            "  0x07, 0xfb, 0x01, 0x0e, 0x07, 0x07, 0xfc, 0x0f, 0x08, 0x04, 0x02, 0x0f,\n",
            "  0xf6, 0xfe, 0xfb, 0xf7, 0x58, 0x09, 0x00, 0xf5, 0x0f, 0x00, 0x08, 0xf8,\n",
            "  0x01, 0xfa, 0x05, 0x09, 0x00, 0xfe, 0x9f, 0xfa, 0xfd, 0xf8, 0x03, 0x00,\n",
            "  0x02, 0xf8, 0xfe, 0x06, 0x51, 0x3f, 0x19, 0x00, 0x11, 0xfb, 0xf7, 0xfc,\n",
            "  0xfa, 0x01, 0xf7, 0x05, 0xb5, 0x03, 0x00, 0xf8, 0x02, 0x06, 0x04, 0xfc,\n",
            "  0x09, 0x19, 0xf8, 0x0c, 0xf7, 0xf7, 0x08, 0x04, 0xfc, 0x0a, 0xfa, 0x0f,\n",
            "  0xfc, 0x01, 0xfc, 0x04, 0x05, 0x03, 0xed, 0x02, 0x60, 0x0c, 0x02, 0x06,\n",
            "  0x0b, 0xf6, 0x0d, 0x06, 0x04, 0x07, 0xf7, 0xfa, 0xf6, 0x11, 0xa5, 0x03,\n",
            "  0x07, 0x07, 0xff, 0x07, 0xf8, 0xff, 0x07, 0x0d, 0x70, 0x35, 0x21, 0x08,\n",
            "  0x1c, 0xfd, 0x09, 0xfc, 0x01, 0xf8, 0x04, 0x0f, 0xb8, 0xff, 0x00, 0xfc,\n",
            "  0xf6, 0xfd, 0xf7, 0x04, 0x09, 0xfd, 0x03, 0x05, 0x04, 0x07, 0xf9, 0xfe,\n",
            "  0xf7, 0xfd, 0x00, 0xf6, 0xf8, 0x0a, 0x09, 0x04, 0x04, 0x00, 0xf8, 0x04,\n",
            "  0xfa, 0xfb, 0x07, 0xfc, 0x02, 0xf7, 0xff, 0xfb, 0x03, 0x09, 0xf7, 0xf9,\n",
            "  0xfe, 0xff, 0xfe, 0x05, 0x01, 0xfb, 0x04, 0xfd, 0x00, 0xfc, 0xf9, 0x04,\n",
            "  0xf7, 0xfa, 0xfd, 0xfb, 0xf8, 0x07, 0xfe, 0xfa, 0x08, 0x08, 0x05, 0x01,\n",
            "  0x09, 0x05, 0xf5, 0x06, 0xf9, 0xe7, 0x11, 0x01, 0xfc, 0xf8, 0x0a, 0xef,\n",
            "  0x05, 0xf8, 0xfa, 0xfd, 0xfe, 0x0a, 0xfb, 0x04, 0x08, 0x04, 0xf9, 0x06,\n",
            "  0x03, 0x03, 0xdd, 0xff, 0x2b, 0x0b, 0xf7, 0xfa, 0x06, 0x04, 0x0a, 0x09,\n",
            "  0x13, 0xf3, 0xff, 0x07, 0x01, 0x10, 0x6d, 0xf9, 0x05, 0x09, 0x01, 0xfe,\n",
            "  0x07, 0xfd, 0xf7, 0x00, 0x5f, 0x24, 0x34, 0xff, 0xe8, 0xfd, 0xf6, 0x02,\n",
            "  0x07, 0xf9, 0xfa, 0xef, 0x5f, 0x08, 0xf3, 0x0a, 0x04, 0x00, 0xf7, 0xf9,\n",
            "  0x06, 0x03, 0x05, 0xf9, 0xf7, 0xfd, 0x00, 0x01, 0x09, 0xf9, 0x0a, 0xfe,\n",
            "  0xf7, 0xfa, 0x00, 0xfd, 0x07, 0xfa, 0xf9, 0xfc, 0xfc, 0xf8, 0xfd, 0x05,\n",
            "  0x03, 0x00, 0xff, 0x0a, 0xfd, 0x04, 0xfc, 0xff, 0xf8, 0xfd, 0x06, 0x06,\n",
            "  0x04, 0xff, 0xf5, 0x0a, 0xfd, 0xf6, 0x08, 0xfc, 0xfe, 0xfe, 0xfe, 0x05,\n",
            "  0x09, 0x05, 0x05, 0x06, 0x06, 0x0a, 0xf6, 0xfc, 0xfa, 0x06, 0x00, 0x03,\n",
            "  0x00, 0x07, 0x03, 0x07, 0xf8, 0x00, 0xf7, 0x08, 0xf7, 0x03, 0x03, 0xfb,\n",
            "  0xf9, 0x04, 0x01, 0x09, 0xff, 0x02, 0x00, 0xf8, 0x08, 0xfb, 0x04, 0x08,\n",
            "  0x01, 0x04, 0xf9, 0x06, 0xf7, 0x03, 0x05, 0x06, 0x07, 0xfb, 0xf9, 0x07,\n",
            "  0x00, 0xfe, 0xfd, 0x0b, 0xf8, 0x05, 0x0a, 0xfa, 0xfb, 0xfe, 0x06, 0xfa,\n",
            "  0x03, 0x00, 0x06, 0x09, 0xff, 0x01, 0xfb, 0xfe, 0x05, 0x05, 0x04, 0xfb,\n",
            "  0x05, 0xf8, 0x08, 0x08, 0xfd, 0x00, 0xfd, 0x0a, 0xf7, 0xf8, 0xfb, 0x08,\n",
            "  0xf6, 0xf7, 0xf6, 0xfb, 0xf8, 0xfc, 0x03, 0xfa, 0x07, 0x01, 0x05, 0xf9,\n",
            "  0xfb, 0x04, 0xf9, 0xfe, 0xfa, 0x07, 0xf6, 0x02, 0xfa, 0x05, 0x0b, 0xf8,\n",
            "  0x02, 0x01, 0xf6, 0x01, 0x07, 0xfe, 0xfe, 0xff, 0x01, 0xf8, 0x01, 0x04,\n",
            "  0xf7, 0x0a, 0xf8, 0xf7, 0x01, 0x03, 0x08, 0x09, 0x08, 0x05, 0xf9, 0xf6,\n",
            "  0xf5, 0xf8, 0x07, 0xf9, 0x07, 0x01, 0x0b, 0x02, 0x00, 0x00, 0xf7, 0x04,\n",
            "  0xfb, 0x05, 0xf7, 0xf8, 0x01, 0xf6, 0x02, 0xf6, 0xfa, 0x05, 0x0a, 0x00,\n",
            "  0x03, 0x03, 0xf8, 0x0a, 0xfc, 0x06, 0xfe, 0x09, 0x01, 0x08, 0xfa, 0xf9,\n",
            "  0x01, 0x04, 0xfa, 0xf6, 0x08, 0xf9, 0x08, 0xf7, 0xff, 0x07, 0xf7, 0x05,\n",
            "  0xf9, 0xff, 0x06, 0xf7, 0xfa, 0x06, 0xfb, 0xff, 0xfe, 0xfc, 0xfc, 0x02,\n",
            "  0x02, 0xff, 0x0a, 0x0a, 0x04, 0xfc, 0xff, 0x09, 0xf8, 0x08, 0x05, 0x0a,\n",
            "  0xfa, 0x05, 0x08, 0xf9, 0x0a, 0x15, 0x0a, 0x08, 0xf6, 0x09, 0x10, 0x15,\n",
            "  0xfe, 0xfb, 0xf8, 0x0c, 0xf7, 0x06, 0xfc, 0x08, 0xfa, 0x04, 0xef, 0x07,\n",
            "  0x69, 0x04, 0x04, 0x05, 0x0e, 0xf7, 0xfc, 0xff, 0x13, 0x08, 0x02, 0x05,\n",
            "  0x05, 0x07, 0x98, 0xfe, 0x02, 0x07, 0xfa, 0x01, 0x00, 0x02, 0xf8, 0x08,\n",
            "  0x6f, 0x3c, 0x20, 0xfe, 0x14, 0xfb, 0xf6, 0xf6, 0x02, 0x06, 0x02, 0x12,\n",
            "  0xaf, 0xfb, 0x0b, 0x02, 0x07, 0x0a, 0xfa, 0xff, 0x07, 0x00, 0x06, 0xfd,\n",
            "  0x07, 0xff, 0xfc, 0x0a, 0xfb, 0xfa, 0xfa, 0x05, 0x04, 0x0a, 0xfc, 0xfa,\n",
            "  0x05, 0xf6, 0xf9, 0x07, 0xf6, 0xfd, 0xf9, 0x03, 0xf9, 0x09, 0x02, 0x04,\n",
            "  0x04, 0x06, 0x04, 0xfb, 0xfd, 0xff, 0xfc, 0xf8, 0xfd, 0x04, 0xfa, 0x08,\n",
            "  0xf8, 0xfc, 0xff, 0xf9, 0xf9, 0x08, 0x08, 0xf9, 0x01, 0xfa, 0xfa, 0xff,\n",
            "  0x08, 0x07, 0xf6, 0x08, 0x01, 0xfd, 0x07, 0xfe, 0x09, 0x06, 0x09, 0x01,\n",
            "  0x0f, 0x05, 0xf8, 0x01, 0x00, 0x05, 0x0a, 0x08, 0xf8, 0x07, 0x03, 0x14,\n",
            "  0xff, 0xfc, 0xf6, 0x12, 0xfa, 0x00, 0xf2, 0xf4, 0x59, 0x03, 0x05, 0x00,\n",
            "  0x0f, 0xff, 0xfb, 0xfb, 0x0f, 0x0a, 0xfa, 0x01, 0x0a, 0x00, 0x9e, 0xfb,\n",
            "  0xfa, 0xf8, 0xf8, 0x05, 0x08, 0x01, 0x05, 0x14, 0x60, 0x36, 0x21, 0x01,\n",
            "  0x11, 0xfa, 0x08, 0xff, 0xfe, 0x01, 0x01, 0x09, 0xab, 0x04, 0x09, 0x04,\n",
            "  0x01, 0x08, 0x09, 0xf7, 0x02, 0x03, 0x01, 0x08, 0x0a, 0x06, 0x04, 0xfb,\n",
            "  0x03, 0xfd, 0x00, 0xf8, 0x08, 0xfb, 0xfb, 0xf9, 0x05, 0x05, 0xfb, 0x0a,\n",
            "  0x01, 0x03, 0xf8, 0x05, 0xfb, 0x06, 0xfc, 0x00, 0xfe, 0xf7, 0xfb, 0x02,\n",
            "  0x0a, 0xf8, 0x04, 0x09, 0x07, 0x01, 0x05, 0x08, 0xff, 0xfb, 0x0a, 0xfe,\n",
            "  0x03, 0x05, 0xfb, 0xff, 0xf6, 0x09, 0x04, 0x02, 0x06, 0x06, 0xfc, 0x08,\n",
            "  0x08, 0xfb, 0xf8, 0x08, 0xfd, 0xe7, 0x02, 0xf9, 0xf2, 0xf1, 0x0a, 0xf1,\n",
            "  0xf8, 0x01, 0xfd, 0xf5, 0x02, 0xfd, 0xfa, 0x0c, 0x02, 0xf6, 0xed, 0x08,\n",
            "  0xfd, 0xfd, 0xf0, 0xf7, 0x32, 0x0e, 0x04, 0x01, 0x0d, 0x07, 0x0d, 0x05,\n",
            "  0x10, 0x05, 0xfe, 0x04, 0x07, 0x0f, 0x75, 0x07, 0xfd, 0xfa, 0x02, 0x05,\n",
            "  0x01, 0xf7, 0xff, 0x08, 0x19, 0x36, 0x29, 0xfc, 0xf9, 0xff, 0xf9, 0xfa,\n",
            "  0xf9, 0x03, 0xf9, 0xef, 0x47, 0xfa, 0xe8, 0xf8, 0xfb, 0xff, 0x06, 0x06,\n",
            "  0x07, 0xfe, 0xfb, 0xff, 0x00, 0x02, 0xfa, 0xf6, 0x03, 0xf9, 0xfc, 0xfe,\n",
            "  0xff, 0xfa, 0xf8, 0xfa, 0x07, 0xf8, 0x0a, 0xfe, 0xf6, 0xf5, 0x09, 0x04,\n",
            "  0xfe, 0x04, 0x05, 0xf9, 0xf8, 0xfc, 0xf8, 0xfc, 0x05, 0x00, 0x07, 0x03,\n",
            "  0xfa, 0xf8, 0x06, 0x06, 0x06, 0xfe, 0xfa, 0xfc, 0x08, 0x06, 0xfe, 0x09,\n",
            "  0x01, 0x04, 0xf6, 0xfd, 0xfa, 0x01, 0xf8, 0x06, 0xf6, 0xfb, 0x02, 0xfe,\n",
            "  0xf6, 0xf7, 0xf8, 0xf7, 0xfd, 0xfb, 0xfd, 0x0a, 0x08, 0xfc, 0x04, 0x06,\n",
            "  0x04, 0xfe, 0x01, 0xfd, 0xf6, 0x07, 0xfb, 0xf6, 0x01, 0x06, 0xf6, 0xfe,\n",
            "  0xfc, 0xf8, 0xf6, 0xff, 0x08, 0xfb, 0xfb, 0x03, 0x01, 0xfb, 0x05, 0xf8,\n",
            "  0xf9, 0x02, 0x09, 0x00, 0x00, 0xfc, 0x08, 0xfc, 0xf7, 0x05, 0x05, 0xf8,\n",
            "  0xf9, 0xf9, 0x00, 0xfa, 0x00, 0x04, 0xf6, 0xfa, 0xff, 0x04, 0xfa, 0xf8,\n",
            "  0xf6, 0xfb, 0x00, 0xf8, 0xff, 0xfd, 0x06, 0xfa, 0xf8, 0x06, 0xf8, 0x00,\n",
            "  0xfe, 0x09, 0xf6, 0xfa, 0xfe, 0x0a, 0x03, 0xf6, 0xfe, 0xf7, 0xf8, 0xfa,\n",
            "  0xf7, 0xfe, 0xfb, 0x04, 0xfa, 0x03, 0x08, 0x03, 0x01, 0xfa, 0xfe, 0x04,\n",
            "  0xfc, 0x05, 0xfa, 0x04, 0x01, 0x06, 0x00, 0xfe, 0xf7, 0xfc, 0xfb, 0x00,\n",
            "  0xfe, 0xf9, 0x00, 0xf6, 0xf6, 0x06, 0x02, 0x0a, 0xfe, 0xf9, 0xfc, 0x00,\n",
            "  0xf8, 0xfc, 0x08, 0xf7, 0x06, 0xfc, 0xfc, 0xfa, 0xf7, 0x04, 0x03, 0xf9,\n",
            "  0x05, 0x06, 0x09, 0xf8, 0x04, 0x02, 0xf6, 0xfa, 0xfa, 0xfb, 0x06, 0x02,\n",
            "  0x02, 0x04, 0xfe, 0xfd, 0x04, 0xf6, 0xfa, 0xf6, 0xf9, 0xff, 0x07, 0xfb,\n",
            "  0x05, 0xfe, 0x06, 0xfe, 0x06, 0x04, 0x07, 0x06, 0x03, 0x08, 0xf9, 0x02,\n",
            "  0xfa, 0x08, 0x0a, 0xf7, 0xf7, 0x01, 0xff, 0x00, 0xf7, 0x06, 0x02, 0x01,\n",
            "  0xfb, 0xf7, 0x03, 0x01, 0x03, 0xf9, 0xff, 0xf6, 0x08, 0xfc, 0x04, 0x01,\n",
            "  0x0a, 0xff, 0xf7, 0xfe, 0x0a, 0xf8, 0xf9, 0x09, 0xf7, 0x09, 0xf7, 0xfe,\n",
            "  0x09, 0xfe, 0x07, 0x07, 0xfd, 0xf7, 0xfd, 0xfc, 0x08, 0xff, 0xf9, 0x02,\n",
            "  0xfb, 0xf8, 0x06, 0xfd, 0x03, 0xf8, 0x05, 0xf6, 0x06, 0xfc, 0x00, 0xfe,\n",
            "  0xfd, 0x05, 0x05, 0xfa, 0xfc, 0xf6, 0x04, 0x00, 0xfd, 0x08, 0x05, 0xfa,\n",
            "  0x03, 0x00, 0x07, 0x03, 0x01, 0x08, 0x0a, 0xf7, 0xfc, 0x09, 0xf9, 0xf6,\n",
            "  0x01, 0xff, 0xf7, 0x09, 0x05, 0x00, 0x07, 0x00, 0x07, 0xfc, 0xff, 0x09,\n",
            "  0x02, 0x02, 0xfc, 0xfd, 0x03, 0x01, 0xf8, 0xfe, 0x00, 0x0a, 0x03, 0x06,\n",
            "  0xfc, 0x0a, 0xf6, 0xfc, 0xf9, 0xf6, 0xfc, 0x05, 0xf8, 0xf8, 0x00, 0xf9,\n",
            "  0xf9, 0x06, 0xf9, 0xf8, 0x04, 0x07, 0xf9, 0xfa, 0xfa, 0xf8, 0xf6, 0x00,\n",
            "  0x01, 0x08, 0xf9, 0xfb, 0x00, 0xfb, 0x07, 0x07, 0xfa, 0x06, 0x08, 0xfe,\n",
            "  0x0a, 0x05, 0x08, 0xf5, 0xfc, 0x09, 0x06, 0xf8, 0x04, 0xf8, 0x0d, 0xf7,\n",
            "  0x06, 0x09, 0x0a, 0x0a, 0xf6, 0x09, 0x0d, 0x03, 0xfd, 0x03, 0x00, 0x05,\n",
            "  0xf8, 0xf8, 0xfa, 0x0e, 0x00, 0xf9, 0xec, 0xf9, 0x5e, 0x09, 0x0e, 0x07,\n",
            "  0x11, 0xfd, 0x0d, 0xfa, 0x0d, 0x00, 0x07, 0xf8, 0x04, 0x12, 0x9f, 0x09,\n",
            "  0xf6, 0xf6, 0x06, 0xf8, 0x09, 0xfa, 0xfd, 0x13, 0x56, 0x39, 0x1d, 0xfd,\n",
            "  0x1b, 0x04, 0xf9, 0x07, 0x0a, 0x02, 0xfd, 0x0f, 0xb1, 0xf6, 0xf7, 0x02,\n",
            "  0x01, 0xf7, 0xfe, 0xf9, 0x04, 0xfe, 0x01, 0xf9, 0xfe, 0xfc, 0xf6, 0x01,\n",
            "  0x08, 0xf6, 0x09, 0x08, 0xf8, 0x04, 0x00, 0x05, 0xfc, 0xfc, 0xf9, 0xfb,\n",
            "  0xf7, 0x01, 0xfd, 0xf8, 0x05, 0xf8, 0xfc, 0x04, 0x01, 0x01, 0x08, 0x08,\n",
            "  0x0a, 0xfd, 0xff, 0x07, 0xff, 0xff, 0xf8, 0x05, 0x08, 0xf8, 0xff, 0xfd,\n",
            "  0xff, 0x07, 0xfb, 0xfa, 0xfe, 0x02, 0x08, 0xfa, 0x04, 0x06, 0x08, 0x00,\n",
            "  0x08, 0xfa, 0x06, 0x04, 0xfc, 0x05, 0xf5, 0x08, 0x07, 0x09, 0xfe, 0x02,\n",
            "  0xf6, 0x01, 0x03, 0xfb, 0x07, 0x05, 0xf9, 0x08, 0xf5, 0x08, 0x04, 0x01,\n",
            "  0xf8, 0x02, 0xfd, 0xff, 0xff, 0xff, 0xfa, 0xf6, 0xf4, 0x01, 0x02, 0xfc,\n",
            "  0x01, 0x05, 0xf6, 0x05, 0xfd, 0xf9, 0x03, 0xf9, 0xf6, 0xfa, 0xfd, 0x00,\n",
            "  0x02, 0xf8, 0xfc, 0x03, 0xfd, 0xf8, 0xf6, 0xf7, 0x04, 0xfd, 0xfd, 0x06,\n",
            "  0x08, 0x01, 0x0b, 0xff, 0x04, 0x03, 0xfe, 0x08, 0xfe, 0x07, 0xfc, 0xfe,\n",
            "  0x05, 0xfa, 0x0a, 0xfe, 0xfc, 0x04, 0xff, 0xfa, 0x09, 0x03, 0xf7, 0x04,\n",
            "  0xfe, 0xfa, 0xfa, 0xff, 0x08, 0x03, 0xfc, 0x03, 0xf9, 0x03, 0xff, 0xf8,\n",
            "  0x08, 0xfe, 0x01, 0xf8, 0xff, 0xf7, 0x04, 0x08, 0xf9, 0xf5, 0xfc, 0xfb,\n",
            "  0xf7, 0x09, 0x0a, 0xf7, 0xfa, 0x0a, 0x04, 0xf9, 0x01, 0xff, 0xfd, 0xfa,\n",
            "  0x05, 0x02, 0xfe, 0xf9, 0x06, 0x08, 0xfb, 0xfd, 0x00, 0x09, 0xfb, 0x02,\n",
            "  0xfa, 0x0a, 0x04, 0xfa, 0xfc, 0xff, 0x03, 0xfb, 0x01, 0xfc, 0xfa, 0x06,\n",
            "  0x05, 0xfc, 0xfa, 0xfe, 0xfa, 0xf8, 0x05, 0xf8, 0x02, 0x0a, 0xfa, 0xfe,\n",
            "  0xfa, 0x00, 0x06, 0xfa, 0x0a, 0xff, 0xfe, 0x05, 0x09, 0xff, 0x09, 0x00,\n",
            "  0xfe, 0x00, 0xf7, 0xff, 0x02, 0x09, 0x01, 0x01, 0xf7, 0xfd, 0x04, 0xf6,\n",
            "  0x03, 0x04, 0x02, 0xff, 0xfa, 0x05, 0xfc, 0x07, 0xfc, 0xf8, 0x0a, 0xfa,\n",
            "  0x04, 0xfd, 0x01, 0x08, 0x07, 0x01, 0x08, 0x00, 0x05, 0x17, 0x06, 0x0f,\n",
            "  0xfc, 0xfc, 0x0b, 0x11, 0xfc, 0xfe, 0x0a, 0x0c, 0x02, 0x01, 0xfa, 0x10,\n",
            "  0xfa, 0x05, 0xf3, 0xfa, 0x5a, 0x0a, 0x11, 0x00, 0x0f, 0xfb, 0x00, 0x07,\n",
            "  0x0f, 0xfb, 0xf8, 0x09, 0xfd, 0x01, 0x9a, 0xfd, 0xfc, 0xfa, 0x04, 0xff,\n",
            "  0xfb, 0xfa, 0xfd, 0x14, 0x64, 0x45, 0x1d, 0xfb, 0x17, 0xfe, 0xfd, 0xf8,\n",
            "  0x05, 0x04, 0x01, 0x10, 0xb2, 0x06, 0xfb, 0xfd, 0xf9, 0x02, 0xf9, 0xf8,\n",
            "  0xfc, 0xfe, 0x0a, 0x01, 0x07, 0xfc, 0x06, 0x00, 0x06, 0xfc, 0x03, 0x04,\n",
            "  0xf6, 0xf8, 0xf7, 0x05, 0xfd, 0xfd, 0xf8, 0x04, 0xf8, 0xfc, 0xfc, 0xf8,\n",
            "  0x03, 0xf8, 0x06, 0x08, 0xf7, 0x08, 0xfe, 0x04, 0x02, 0xf5, 0xf8, 0x09,\n",
            "  0xfc, 0x02, 0xfd, 0x05, 0xfe, 0x03, 0x0b, 0xf6, 0x04, 0xfc, 0xf7, 0x0a,\n",
            "  0x08, 0xff, 0xff, 0x02, 0xfd, 0x03, 0x04, 0xfe, 0x01, 0x03, 0x07, 0xf6,\n",
            "  0x02, 0x02, 0x02, 0xf9, 0xf3, 0x05, 0xfa, 0xf4, 0x05, 0x05, 0x03, 0x03,\n",
            "  0x05, 0xf8, 0x00, 0xf7, 0x08, 0xf7, 0xf4, 0x07, 0xf9, 0xf8, 0x07, 0xfb,\n",
            "  0xf8, 0x04, 0x04, 0xfc, 0x06, 0x07, 0x00, 0x06, 0x07, 0x00, 0x05, 0x07,\n",
            "  0xfe, 0x00, 0xfe, 0xf6, 0xfb, 0xfc, 0xf6, 0xfc, 0x01, 0xf8, 0xf7, 0xf5,\n",
            "  0x06, 0x01, 0xff, 0x06, 0x02, 0xf8, 0x0a, 0xfd, 0xfe, 0xf9, 0xf6, 0x05,\n",
            "  0x02, 0xf9, 0x02, 0x08, 0x03, 0x0d, 0x02, 0x09, 0x0e, 0x0c, 0x09, 0x12,\n",
            "  0x08, 0xf7, 0x03, 0xfb, 0x07, 0x01, 0xf6, 0xf2, 0x00, 0x07, 0x0e, 0x08,\n",
            "  0x02, 0xfa, 0x16, 0xf9, 0xa5, 0xe7, 0xfe, 0xfd, 0xf7, 0xfc, 0xf2, 0xf7,\n",
            "  0xd1, 0xfa, 0x01, 0xfe, 0x02, 0xfd, 0x81, 0xf6, 0xf9, 0x01, 0x08, 0xf8,\n",
            "  0x01, 0xf6, 0x09, 0x06, 0xa4, 0xa8, 0xac, 0x05, 0xf5, 0xfa, 0x03, 0x04,\n",
            "  0x03, 0xff, 0x09, 0x0e, 0xfa, 0x05, 0x17, 0xff, 0x09, 0xfc, 0x02, 0x00,\n",
            "  0xfe, 0xfd, 0x05, 0x0a, 0xf9, 0xfd, 0x00, 0xf6, 0xf6, 0x08, 0x08, 0x06,\n",
            "  0xfd, 0xfb, 0xfd, 0xf7, 0xf7, 0xfd, 0x08, 0xfd, 0xfb, 0xf6, 0x05, 0xf7,\n",
            "  0xfe, 0x08, 0xff, 0xfa, 0xff, 0xfe, 0xf6, 0x02, 0xfb, 0xfa, 0x05, 0x09,\n",
            "  0x0a, 0x0b, 0xf9, 0xfd, 0x04, 0x06, 0x01, 0xfa, 0x04, 0x07, 0x06, 0xfa,\n",
            "  0x02, 0x06, 0x05, 0x0a, 0xf7, 0xfc, 0xf9, 0xf8, 0x02, 0xf6, 0xf8, 0xff,\n",
            "  0x66, 0xf4, 0xff, 0xff, 0x00, 0x00, 0x00, 0x09, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x06, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00,\n",
            "  0x02, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00,\n",
            "  0x19, 0x00, 0x00, 0x00, 0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69,\n",
            "  0x61, 0x6c, 0x2f, 0x64, 0x65, 0x6e, 0x73, 0x65, 0x5f, 0x32, 0x2f, 0x4d,\n",
            "  0x61, 0x74, 0x4d, 0x75, 0x6c, 0x00, 0x00, 0x00, 0x5c, 0xf4, 0xff, 0xff,\n",
            "  0x08, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0xb0, 0xba, 0xc0, 0x3c, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x02, 0xf5, 0xff, 0xff,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x7a, 0xfb, 0xff, 0xff, 0x14, 0x04, 0x00, 0x00, 0xeb, 0xff, 0xff, 0xff,\n",
            "  0x02, 0x01, 0x00, 0x00, 0xca, 0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x96, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x18, 0x02, 0x00, 0x00, 0x64, 0x00, 0x00, 0x00, 0xb3, 0xff, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xe7, 0x04, 0x00, 0x00,\n",
            "  0xd1, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x63, 0xfa, 0xff, 0xff,\n",
            "  0x6c, 0x04, 0x00, 0x00, 0xdd, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n",
            "  0xf4, 0xf9, 0xff, 0xff, 0xc8, 0xff, 0xff, 0xff, 0x07, 0x0d, 0x00, 0x00,\n",
            "  0xd9, 0x03, 0x00, 0x00, 0x68, 0x02, 0x00, 0x00, 0xa3, 0xff, 0xff, 0xff,\n",
            "  0xb2, 0x04, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x2c, 0x04, 0x00, 0x00,\n",
            "  0xc8, 0xff, 0xff, 0xff, 0xa8, 0x04, 0x00, 0x00, 0xb7, 0xff, 0xff, 0xff,\n",
            "  0xef, 0xff, 0xff, 0xff, 0xd2, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n",
            "  0xcd, 0x04, 0x00, 0x00, 0x32, 0x08, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0xd5, 0xff, 0xff, 0xff, 0xc8, 0xff, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x00, 0xfb, 0x03, 0x00, 0x00, 0xa7, 0x0b, 0x00, 0x00,\n",
            "  0xb7, 0x0b, 0x00, 0x00, 0xbe, 0x06, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0xfa, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0xbd, 0xff, 0xff, 0xff,\n",
            "  0xa1, 0xff, 0xff, 0xff, 0x7a, 0x00, 0x00, 0x00, 0x99, 0xff, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x85, 0xfc, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00,\n",
            "  0xda, 0xf5, 0xff, 0xff, 0x00, 0x00, 0x00, 0x02, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x05, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x44, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x40, 0x00, 0x00, 0x00, 0x32, 0x00, 0x00, 0x00,\n",
            "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x2f, 0x64,\n",
            "  0x65, 0x6e, 0x73, 0x65, 0x5f, 0x31, 0x2f, 0x42, 0x69, 0x61, 0x73, 0x41,\n",
            "  0x64, 0x64, 0x2f, 0x52, 0x65, 0x61, 0x64, 0x56, 0x61, 0x72, 0x69, 0x61,\n",
            "  0x62, 0x6c, 0x65, 0x4f, 0x70, 0x2f, 0x72, 0x65, 0x73, 0x6f, 0x75, 0x72,\n",
            "  0x63, 0x65, 0x00, 0x00, 0xe4, 0xf5, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0xf2, 0xc6, 0x14, 0x3a,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x86, 0xf6, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00,\n",
            "  0x00, 0x01, 0xf3, 0x07, 0xf6, 0x00, 0xf5, 0xf6, 0xf4, 0xfe, 0xfc, 0x03,\n",
            "  0x05, 0x0b, 0x03, 0x01, 0x03, 0x0a, 0xff, 0xf7, 0xf9, 0x0a, 0x02, 0x03,\n",
            "  0xfe, 0x0a, 0x06, 0xf7, 0xfd, 0x04, 0x07, 0xfa, 0xfe, 0x08, 0x07, 0x07,\n",
            "  0xf3, 0x0b, 0x07, 0xf5, 0x58, 0x0c, 0x0a, 0x4a, 0x08, 0x01, 0x05, 0xf8,\n",
            "  0x0d, 0xf6, 0xfa, 0x08, 0x05, 0x02, 0x00, 0xf3, 0xfb, 0xf1, 0xfd, 0x02,\n",
            "  0x0d, 0x05, 0xfc, 0x07, 0xfe, 0x14, 0xee, 0xf5, 0x0d, 0x07, 0x0d, 0x02,\n",
            "  0xfa, 0xe9, 0xf2, 0xf9, 0xf2, 0x01, 0xea, 0xff, 0xfd, 0x09, 0x0f, 0x0b,\n",
            "  0x0d, 0x0c, 0x0a, 0x07, 0x08, 0x0d, 0xfd, 0x05, 0xe0, 0x02, 0xfc, 0xfc,\n",
            "  0x0d, 0xfc, 0x02, 0x0c, 0x08, 0xf7, 0x03, 0x0d, 0x04, 0x0b, 0xf4, 0x08,\n",
            "  0x0a, 0x06, 0xfb, 0x02, 0x0d, 0x02, 0xfb, 0xf9, 0x01, 0x0c, 0x03, 0xf5,\n",
            "  0xfa, 0x01, 0xf3, 0xfa, 0x0c, 0x0b, 0xf3, 0x0a, 0x05, 0x01, 0xf6, 0x02,\n",
            "  0x0a, 0x0c, 0x03, 0xfe, 0x5e, 0xfc, 0x07, 0x60, 0xf8, 0x0f, 0xef, 0x0a,\n",
            "  0xf7, 0x06, 0xfc, 0x00, 0xfa, 0x08, 0xf3, 0xfc, 0x05, 0x0b, 0xfa, 0xf4,\n",
            "  0xee, 0xf6, 0x10, 0x00, 0xfc, 0x0b, 0xf1, 0x05, 0x09, 0x0a, 0xfe, 0x07,\n",
            "  0x5c, 0xec, 0x06, 0x5c, 0xf5, 0x07, 0xf5, 0x0d, 0xf5, 0x0c, 0xfb, 0x09,\n",
            "  0x04, 0xfd, 0xf7, 0xff, 0x0c, 0x02, 0xfd, 0xfc, 0xe6, 0xf3, 0xfe, 0xff,\n",
            "  0xfe, 0x00, 0xfb, 0xfd, 0xf8, 0x08, 0xf4, 0xf3, 0xfb, 0x07, 0xf7, 0x09,\n",
            "  0xf7, 0x01, 0x03, 0x0c, 0xfb, 0xff, 0xf3, 0xff, 0xf3, 0x01, 0xfe, 0xf9,\n",
            "  0x08, 0xf9, 0xff, 0x00, 0xf3, 0x02, 0xff, 0x0b, 0x03, 0xfd, 0x05, 0xf9,\n",
            "  0xf6, 0xfa, 0x10, 0x02, 0x63, 0xfa, 0x08, 0x5d, 0x03, 0x11, 0x04, 0xf8,\n",
            "  0x03, 0xf7, 0x09, 0x08, 0x0d, 0xf9, 0x02, 0x0c, 0xf8, 0xfe, 0x0d, 0x01,\n",
            "  0x03, 0xf7, 0xf9, 0x04, 0xff, 0xf5, 0xfa, 0x01, 0x00, 0xf5, 0x05, 0x01,\n",
            "  0xf9, 0x08, 0xf6, 0x0c, 0x00, 0xfc, 0xfa, 0x02, 0x07, 0x02, 0xfd, 0x0c,\n",
            "  0x04, 0xf4, 0xf8, 0xf5, 0x03, 0xfb, 0xf3, 0xf8, 0x06, 0xfa, 0xfe, 0x06,\n",
            "  0x07, 0xf3, 0x0d, 0xf5, 0x08, 0xf7, 0x06, 0xf6, 0x09, 0xfe, 0x00, 0xf7,\n",
            "  0xfd, 0x0b, 0xf7, 0x00, 0x02, 0xfb, 0xf6, 0x02, 0xf6, 0xf3, 0xfd, 0x03,\n",
            "  0x0a, 0xf7, 0xfd, 0xfb, 0x0b, 0xfd, 0xfd, 0xfb, 0xf8, 0x0f, 0xf2, 0x0b,\n",
            "  0x0b, 0x0d, 0x07, 0x06, 0x3d, 0xf7, 0xf7, 0x3a, 0xfe, 0x0d, 0xee, 0x0d,\n",
            "  0xf3, 0x0b, 0x0a, 0x02, 0x0d, 0x01, 0xfe, 0x0b, 0x02, 0x05, 0x0a, 0x05,\n",
            "  0xfb, 0x08, 0x12, 0x02, 0x01, 0x0d, 0xf6, 0xf3, 0x04, 0xfa, 0x08, 0xf6,\n",
            "  0x3a, 0xf0, 0xef, 0x36, 0xf8, 0xf7, 0xf0, 0xfa, 0x02, 0x06, 0x08, 0x08,\n",
            "  0xfa, 0x02, 0xfb, 0x01, 0x08, 0x06, 0xff, 0x0c, 0xe1, 0xef, 0xfd, 0x0e,\n",
            "  0x01, 0x05, 0x06, 0x03, 0xf7, 0x06, 0xf5, 0x04, 0x0a, 0x09, 0xfc, 0xfb,\n",
            "  0x0a, 0xfc, 0x05, 0x0c, 0xfd, 0xf9, 0xfd, 0xf6, 0xff, 0xfe, 0xf4, 0x01,\n",
            "  0xf3, 0x03, 0xfd, 0x02, 0xfa, 0x01, 0x06, 0xfd, 0x01, 0xf5, 0xf5, 0xfc,\n",
            "  0xfc, 0xf4, 0x0a, 0xf9, 0xfe, 0xfa, 0xfc, 0x00, 0x05, 0xfd, 0xf7, 0xfa,\n",
            "  0x06, 0x0d, 0xfb, 0x07, 0x01, 0x0d, 0xfe, 0xf6, 0xfe, 0x01, 0x07, 0xfd,\n",
            "  0x03, 0xf3, 0xf5, 0x0c, 0xfa, 0x0c, 0x00, 0xf8, 0xfc, 0xfe, 0x00, 0x07,\n",
            "  0xfe, 0x04, 0xf9, 0x06, 0x09, 0xfb, 0xf5, 0xf8, 0xf3, 0x05, 0xf6, 0xf6,\n",
            "  0x0b, 0x06, 0xf8, 0x02, 0xfb, 0xf6, 0xf7, 0x09, 0xfb, 0x00, 0x01, 0x05,\n",
            "  0xf6, 0x11, 0xdc, 0xfc, 0xf6, 0x0d, 0x0a, 0xf8, 0x02, 0xdb, 0xea, 0xff,\n",
            "  0xe7, 0x07, 0xee, 0x02, 0xff, 0xfc, 0x0b, 0x0d, 0xf7, 0xf8, 0x01, 0x08,\n",
            "  0x00, 0x05, 0xf4, 0x08, 0xe1, 0xf0, 0x01, 0xf9, 0x03, 0x0a, 0x0a, 0x07,\n",
            "  0xfe, 0xf4, 0xf7, 0xfc, 0x09, 0x0c, 0x09, 0x05, 0xf4, 0xf7, 0xfe, 0xfa,\n",
            "  0x0d, 0x09, 0xfd, 0xf8, 0x04, 0x03, 0xfe, 0x06, 0x03, 0x09, 0xfe, 0xf4,\n",
            "  0x0a, 0xf9, 0x00, 0x06, 0x0a, 0xf3, 0x07, 0xf7, 0x0c, 0xf9, 0xfd, 0xfa,\n",
            "  0x0b, 0x07, 0x07, 0x0b, 0x06, 0x04, 0x05, 0x07, 0xf7, 0xfb, 0xf4, 0x02,\n",
            "  0xf4, 0x0d, 0x0a, 0xf3, 0x07, 0x07, 0xf3, 0xf7, 0x0a, 0xf3, 0xfa, 0x0d,\n",
            "  0x01, 0x05, 0x22, 0x00, 0xf7, 0x02, 0x02, 0xf6, 0x40, 0x18, 0xff, 0x3c,\n",
            "  0x0b, 0xfc, 0x1d, 0xfe, 0xfc, 0xfb, 0x08, 0x00, 0x09, 0xf7, 0xf8, 0xf5,\n",
            "  0xfe, 0x0c, 0x05, 0x0d, 0x1e, 0xfe, 0xf6, 0x0a, 0x02, 0x07, 0xf1, 0x0c,\n",
            "  0x01, 0x07, 0x02, 0xfa, 0x11, 0xf3, 0xff, 0x08, 0xf9, 0x0e, 0xf4, 0x08,\n",
            "  0x03, 0xfd, 0x08, 0x0e, 0x08, 0x04, 0x01, 0x07, 0x03, 0x08, 0xf6, 0xf6,\n",
            "  0xe8, 0x0c, 0x0a, 0x04, 0xfb, 0xf7, 0xff, 0x0a, 0xf3, 0x07, 0x07, 0x0b,\n",
            "  0xfd, 0xf5, 0xf6, 0x06, 0x06, 0xf7, 0x07, 0xf9, 0x09, 0x01, 0xfd, 0xfe,\n",
            "  0xf2, 0x08, 0xfa, 0xf7, 0xf6, 0x08, 0xfe, 0x02, 0xfc, 0xfd, 0x06, 0x00,\n",
            "  0x0b, 0xf5, 0x05, 0x03, 0x05, 0x03, 0xfd, 0x0b, 0x00, 0x05, 0xf3, 0x07,\n",
            "  0xff, 0xfa, 0x08, 0xf8, 0x0a, 0x05, 0x07, 0x02, 0x05, 0x08, 0x08, 0x0d,\n",
            "  0xfc, 0xf8, 0xf9, 0xf7, 0x02, 0xfb, 0xf3, 0x01, 0xf6, 0xf5, 0x21, 0xfb,\n",
            "  0x0a, 0x0c, 0xfc, 0xfc, 0x2f, 0x1d, 0x0c, 0x36, 0x17, 0x0d, 0x29, 0x01,\n",
            "  0x06, 0xf7, 0x00, 0x0d, 0x06, 0xfd, 0x07, 0x0b, 0x0b, 0xfc, 0x07, 0xf6,\n",
            "  0x2a, 0x01, 0x0b, 0xff, 0x0c, 0xfc, 0x0b, 0xf4, 0xfa, 0x07, 0xf2, 0x02,\n",
            "  0xff, 0x06, 0x08, 0x08, 0xf4, 0xf8, 0x03, 0xfb, 0xfd, 0xfe, 0x07, 0x05,\n",
            "  0xfb, 0x08, 0xf4, 0xf6, 0xff, 0xf1, 0x08, 0xf9, 0x00, 0x05, 0x00, 0x06,\n",
            "  0x05, 0x0b, 0xbe, 0x01, 0xf3, 0xf7, 0x0f, 0xf7, 0xfc, 0xcf, 0xf0, 0xf1,\n",
            "  0xeb, 0x05, 0xc3, 0xf5, 0xf4, 0xfb, 0x06, 0x08, 0xfc, 0xfd, 0x07, 0x00,\n",
            "  0x03, 0x02, 0x0c, 0x0a, 0xd3, 0xf2, 0x13, 0xfd, 0xfa, 0x06, 0xdb, 0x03,\n",
            "  0x05, 0x06, 0x07, 0xfb, 0xda, 0xf4, 0xf0, 0xe6, 0xed, 0x0e, 0xe6, 0x01,\n",
            "  0x0c, 0x01, 0xf9, 0x0a, 0xfe, 0xf3, 0xf5, 0x06, 0xfd, 0xff, 0x08, 0x00,\n",
            "  0xe0, 0x05, 0x0d, 0xf5, 0x08, 0xfd, 0xf4, 0xf8, 0xfe, 0xf6, 0x0c, 0xfc,\n",
            "  0x1b, 0xea, 0xfe, 0x29, 0x04, 0xfe, 0xec, 0x0c, 0xfb, 0xfb, 0x0e, 0x01,\n",
            "  0xf7, 0x04, 0xfe, 0x02, 0x00, 0x0e, 0x00, 0x0b, 0xf4, 0xf9, 0x04, 0xf9,\n",
            "  0xf5, 0x00, 0x0b, 0xf6, 0x03, 0xf3, 0x06, 0x08, 0x01, 0xfd, 0xf6, 0xf4,\n",
            "  0xf3, 0x04, 0x01, 0x0b, 0x00, 0x00, 0x01, 0xfd, 0x02, 0x07, 0x0b, 0x02,\n",
            "  0xf6, 0xf6, 0x0b, 0xff, 0xf1, 0xfb, 0xfc, 0x02, 0x0d, 0x11, 0xde, 0x01,\n",
            "  0xf7, 0x10, 0xfc, 0xf3, 0xf7, 0xdd, 0x05, 0x08, 0xee, 0x0a, 0xf3, 0x01,\n",
            "  0xfa, 0x04, 0x0a, 0x12, 0x0d, 0x09, 0xf7, 0x02, 0x06, 0x04, 0x0d, 0x06,\n",
            "  0xec, 0xff, 0x0c, 0xfa, 0x09, 0x03, 0xfb, 0x01, 0xfc, 0x03, 0xf9, 0x03,\n",
            "  0x00, 0x03, 0x03, 0x09, 0xf3, 0xfb, 0xfe, 0x01, 0xfe, 0xfe, 0x02, 0xf3,\n",
            "  0xfe, 0xff, 0x0d, 0x03, 0x09, 0x0a, 0xf6, 0x07, 0xfe, 0xf6, 0x05, 0x04,\n",
            "  0x0a, 0x03, 0xee, 0xf8, 0x04, 0x0d, 0xfd, 0x0a, 0xe0, 0xe5, 0x03, 0xde,\n",
            "  0x04, 0xfc, 0xf5, 0xfd, 0x08, 0xf7, 0x12, 0xfe, 0x08, 0xf6, 0xfe, 0xf4,\n",
            "  0x07, 0xfd, 0x06, 0x00, 0xee, 0x00, 0x0b, 0xf5, 0x04, 0x04, 0xfb, 0xf9,\n",
            "  0x00, 0xf2, 0x04, 0xfc, 0xf4, 0x02, 0x09, 0x04, 0xf8, 0xfc, 0xf3, 0xfa,\n",
            "  0x0a, 0x01, 0xf8, 0x08, 0xfa, 0xfc, 0x0b, 0x0b, 0x01, 0xfd, 0x01, 0x08,\n",
            "  0xf3, 0xf3, 0xf7, 0xf9, 0xf7, 0xfe, 0xe5, 0x08, 0xf6, 0xf5, 0x08, 0x0c,\n",
            "  0xd4, 0xea, 0xff, 0xe4, 0xfe, 0xf5, 0xd8, 0xfb, 0x07, 0xfb, 0x11, 0x01,\n",
            "  0xfa, 0x0c, 0x0b, 0x01, 0xfd, 0xff, 0xfa, 0x02, 0xdf, 0xf2, 0x0d, 0xfd,\n",
            "  0x0c, 0xfb, 0x01, 0x0a, 0xfd, 0xf6, 0xf6, 0xf5, 0xff, 0xff, 0xf7, 0x0d,\n",
            "  0x05, 0xf6, 0xf8, 0xff, 0x09, 0xf8, 0x09, 0x0b, 0xf2, 0x08, 0x09, 0xf7,\n",
            "  0xf9, 0xf2, 0xf7, 0x02, 0x0b, 0xf6, 0x05, 0x09, 0x08, 0xf3, 0x02, 0x06,\n",
            "  0xf4, 0x0c, 0x0a, 0xfc, 0x07, 0xfc, 0x01, 0x0b, 0xf9, 0xff, 0x01, 0xfc,\n",
            "  0x02, 0xf4, 0x01, 0xf9, 0x09, 0x08, 0xf5, 0xfd, 0xf5, 0x00, 0xf3, 0x01,\n",
            "  0xf5, 0xfc, 0xf7, 0x05, 0x0d, 0xff, 0x07, 0xf6, 0x02, 0xf8, 0x01, 0xf3,\n",
            "  0x01, 0x02, 0x0a, 0x01, 0x07, 0xf7, 0x0a, 0x01, 0x00, 0xf8, 0x05, 0xf2,\n",
            "  0x03, 0xfe, 0x04, 0xf5, 0x02, 0x0a, 0xf7, 0xfb, 0xfb, 0xf9, 0xf2, 0x04,\n",
            "  0x0d, 0xf3, 0xfd, 0x00, 0x0b, 0xfb, 0xf3, 0x02, 0xf7, 0xfe, 0x06, 0xfa,\n",
            "  0x02, 0xfe, 0xfc, 0x0a, 0xf3, 0x03, 0x03, 0xfa, 0x04, 0x06, 0x08, 0x0b,\n",
            "  0x05, 0xf3, 0xf9, 0x0d, 0xf3, 0x06, 0x07, 0xf7, 0xf4, 0x0a, 0xe0, 0xfd,\n",
            "  0xff, 0x10, 0x05, 0xf8, 0xce, 0xe3, 0xfe, 0xca, 0xfc, 0x13, 0xee, 0xf6,\n",
            "  0x05, 0x07, 0x0c, 0x0b, 0x0c, 0x06, 0xfb, 0x08, 0x04, 0xff, 0x0a, 0xf8,\n",
            "  0xee, 0x0a, 0x12, 0xfb, 0xfe, 0x10, 0xd6, 0xf3, 0x0d, 0x01, 0x09, 0x05,\n",
            "  0xa1, 0xcd, 0xf6, 0x9a, 0xf6, 0x06, 0xde, 0xfa, 0xfe, 0xf5, 0x10, 0xfd,\n",
            "  0x04, 0xfe, 0x07, 0xf4, 0x06, 0x03, 0xf8, 0xf7, 0xd9, 0xfc, 0x00, 0x02,\n",
            "  0x02, 0xfd, 0xfa, 0x0b, 0xfc, 0xff, 0xfc, 0x03, 0x07, 0x07, 0x02, 0xf7,\n",
            "  0xfe, 0xfa, 0xf8, 0x09, 0x01, 0xf6, 0xfd, 0x0a, 0xf7, 0xfb, 0xfc, 0xfa,\n",
            "  0x05, 0xf5, 0x0d, 0x0a, 0xff, 0xf8, 0x09, 0xfe, 0xfd, 0xf5, 0x05, 0x0a,\n",
            "  0xff, 0x0c, 0xfa, 0xfc, 0xfd, 0xfb, 0xff, 0xf4, 0x0c, 0x0a, 0xfd, 0xfc,\n",
            "  0x08, 0x0a, 0x07, 0xf6, 0x09, 0xf8, 0x05, 0xfa, 0xf7, 0xf9, 0xff, 0x02,\n",
            "  0xfb, 0xf4, 0x00, 0xfb, 0xf8, 0xf3, 0x01, 0x00, 0x05, 0xfe, 0xfa, 0x05,\n",
            "  0xfc, 0xf5, 0x0a, 0xfb, 0xf4, 0x07, 0xf4, 0x01, 0xfb, 0xf4, 0xf8, 0xfe,\n",
            "  0x08, 0x0a, 0xfc, 0x07, 0x0b, 0x06, 0x08, 0x03, 0x04, 0x0d, 0xf8, 0x03,\n",
            "  0x00, 0x07, 0x02, 0xfd, 0xfc, 0xfd, 0xf4, 0x07, 0xfa, 0xf9, 0xf4, 0x06,\n",
            "  0x01, 0xf3, 0xf8, 0x04, 0xf8, 0x06, 0x07, 0xf5, 0x02, 0x03, 0x07, 0xfc,\n",
            "  0x03, 0x03, 0x01, 0x0c, 0x02, 0xff, 0xf6, 0xfc, 0xfd, 0xf4, 0x01, 0xf8,\n",
            "  0xf7, 0xf9, 0x0b, 0xf5, 0xf5, 0xf8, 0x03, 0x09, 0x0a, 0x05, 0x04, 0xff,\n",
            "  0x0c, 0x04, 0x0b, 0xf5, 0xf9, 0xf5, 0xf9, 0x03, 0xf8, 0xf7, 0x01, 0xff,\n",
            "  0xfa, 0xfc, 0x03, 0x00, 0xf9, 0x08, 0xf5, 0x0d, 0xf4, 0x09, 0xfa, 0x05,\n",
            "  0x0a, 0x05, 0xf6, 0xf8, 0xf4, 0xf2, 0xf3, 0xf9, 0x03, 0x03, 0x03, 0x03,\n",
            "  0x09, 0x06, 0x0a, 0xf4, 0xfa, 0xf9, 0xfa, 0xfe, 0xf9, 0xfa, 0xf3, 0x03,\n",
            "  0x04, 0x03, 0x00, 0xfb, 0xf7, 0xfa, 0xf4, 0xfe, 0x05, 0xfa, 0xf3, 0xf8,\n",
            "  0xf3, 0x0c, 0x02, 0x01, 0x09, 0x0b, 0xfc, 0x05, 0xf3, 0x01, 0xfe, 0x0c,\n",
            "  0x05, 0x0a, 0xff, 0x04, 0xf5, 0x03, 0xfb, 0x0c, 0xf8, 0xf4, 0x06, 0x0b,\n",
            "  0x0a, 0x07, 0xf9, 0xf5, 0x00, 0x0a, 0xf7, 0xfd, 0xf8, 0x01, 0xf5, 0xfe,\n",
            "  0x08, 0x0d, 0x01, 0xf6, 0xfb, 0xf8, 0xf8, 0x00, 0x02, 0x09, 0xf5, 0x09,\n",
            "  0x04, 0x0a, 0x01, 0xf8, 0x08, 0x11, 0xe2, 0xf7, 0x03, 0x0e, 0x0e, 0x03,\n",
            "  0x1b, 0xe9, 0xf8, 0x14, 0xf2, 0x12, 0xe5, 0x00, 0xfa, 0x00, 0x13, 0x00,\n",
            "  0x0a, 0xf6, 0x05, 0xf8, 0x0d, 0x06, 0x01, 0xf7, 0xe3, 0xf9, 0x07, 0x07,\n",
            "  0xf4, 0x0e, 0xc5, 0x08, 0x0b, 0x03, 0x0b, 0x09, 0xf7, 0xd1, 0xe8, 0xf0,\n",
            "  0xfc, 0xfd, 0xc1, 0x01, 0x00, 0x08, 0x0e, 0x0d, 0xf7, 0x01, 0x04, 0x03,\n",
            "  0x03, 0xf4, 0x09, 0x0c, 0xc2, 0xf7, 0x11, 0x04, 0xfc, 0x11, 0xc2, 0xf8,\n",
            "  0xf6, 0xf8, 0x0c, 0x0a, 0xe0, 0xc9, 0xfd, 0xf8, 0xf0, 0x01, 0xca, 0xf7,\n",
            "  0xf6, 0xf6, 0x0a, 0x0e, 0xfb, 0xf6, 0xf3, 0x0b, 0xf7, 0xf8, 0xf3, 0x06,\n",
            "  0xc0, 0xfa, 0x11, 0x0a, 0x01, 0x06, 0xe2, 0x00, 0xfb, 0x10, 0xf9, 0x08,\n",
            "  0xd3, 0xeb, 0xf0, 0xda, 0xef, 0xfd, 0xf0, 0xf3, 0x05, 0xf5, 0x0f, 0x0a,\n",
            "  0x01, 0xfb, 0xfd, 0x0d, 0x05, 0x10, 0xff, 0x00, 0xd5, 0xf0, 0x07, 0x0a,\n",
            "  0x07, 0xfc, 0x0a, 0xf4, 0x0a, 0xfa, 0x01, 0x01, 0x00, 0xfc, 0x06, 0x08,\n",
            "  0xfb, 0x08, 0x0a, 0xf6, 0x0b, 0x0b, 0x09, 0x05, 0xf7, 0xf6, 0xf6, 0xf6,\n",
            "  0x03, 0xfb, 0x09, 0xf9, 0xfd, 0xf6, 0xf3, 0xff, 0x01, 0x02, 0xc7, 0xf8,\n",
            "  0x07, 0x05, 0x02, 0x0b, 0x14, 0xdd, 0xe4, 0x0a, 0xef, 0xff, 0xd7, 0x00,\n",
            "  0xf4, 0xf4, 0x0e, 0xff, 0xf5, 0x08, 0x0c, 0xfe, 0x0b, 0x09, 0xf4, 0x0d,\n",
            "  0xd5, 0xdb, 0xf8, 0xff, 0x02, 0x07, 0x0a, 0x0b, 0xfa, 0x09, 0xfd, 0xff,\n",
            "  0x06, 0x0a, 0xfd, 0xf3, 0x0b, 0x00, 0xf8, 0x08, 0x0c, 0xfa, 0xf6, 0xff,\n",
            "  0x02, 0x09, 0xf6, 0xf4, 0x0b, 0xfd, 0xf9, 0x0d, 0xfb, 0xf6, 0xf3, 0x0d,\n",
            "  0xf4, 0x03, 0xf6, 0xff, 0xfa, 0xfe, 0x06, 0xf4, 0xfc, 0x07, 0x04, 0xfc,\n",
            "  0xf7, 0x00, 0xf7, 0x06, 0x0c, 0xfb, 0x05, 0xfc, 0xf6, 0x00, 0x05, 0xfc,\n",
            "  0xf8, 0x05, 0xf9, 0x0d, 0x02, 0xfe, 0xf3, 0x03, 0x06, 0xfd, 0x00, 0xfb,\n",
            "  0x09, 0xf4, 0x00, 0x07, 0x08, 0x01, 0x09, 0xfc, 0xf8, 0x09, 0x0c, 0xfe,\n",
            "  0xf4, 0xfa, 0xf9, 0xf3, 0x03, 0x0b, 0x05, 0xf9, 0x03, 0xfe, 0x04, 0xfc,\n",
            "  0xfb, 0x0d, 0xf3, 0x07, 0xf4, 0x05, 0x05, 0x07, 0x08, 0xf3, 0x01, 0xfc,\n",
            "  0x01, 0x04, 0xf6, 0xfd, 0xf5, 0x0b, 0xfb, 0x07, 0xf5, 0xfe, 0x06, 0xfb,\n",
            "  0xf7, 0xfe, 0x0d, 0xf9, 0x03, 0xf8, 0xf8, 0x09, 0x02, 0x08, 0xf9, 0x05,\n",
            "  0xf6, 0x07, 0x03, 0x04, 0xff, 0x01, 0x06, 0x0c, 0xfb, 0x09, 0x0a, 0x09,\n",
            "  0xfe, 0xf3, 0xfd, 0x02, 0x09, 0x08, 0xf2, 0x00, 0xfb, 0xf6, 0x0c, 0x00,\n",
            "  0x0d, 0xf8, 0x07, 0x03, 0xf9, 0xf6, 0x02, 0x01, 0x04, 0xf4, 0xfe, 0xf8,\n",
            "  0x01, 0xfa, 0x03, 0x04, 0xfb, 0xf8, 0x01, 0xf7, 0x01, 0x02, 0xf8, 0xf3,\n",
            "  0xf9, 0x09, 0x09, 0x03, 0xf4, 0x09, 0x07, 0x08, 0xfd, 0xfa, 0xfd, 0x06,\n",
            "  0x01, 0xf2, 0xfd, 0xf5, 0xf9, 0x06, 0xec, 0xf3, 0x01, 0x07, 0x0f, 0xfa,\n",
            "  0x59, 0x04, 0xfd, 0x5a, 0x09, 0x0a, 0x00, 0xf6, 0xf7, 0x08, 0x03, 0xff,\n",
            "  0xfd, 0xfe, 0x0c, 0xfa, 0xfa, 0xfe, 0xfd, 0xf7, 0xeb, 0x02, 0x03, 0x09,\n",
            "  0x08, 0xfb, 0x93, 0x08, 0x09, 0xff, 0x0d, 0x00, 0x0c, 0x9c, 0xaa, 0xfc,\n",
            "  0xc1, 0x04, 0x81, 0x01, 0x02, 0x0d, 0x00, 0x0b, 0xfa, 0x09, 0xf9, 0xf7,\n",
            "  0x0d, 0xf7, 0x0b, 0x08, 0x8a, 0x99, 0x08, 0x00, 0x02, 0xf5, 0xf3, 0x03,\n",
            "  0xfc, 0x09, 0x03, 0xf4, 0xff, 0xf7, 0xfb, 0x08, 0xff, 0xf4, 0x03, 0x0b,\n",
            "  0xfb, 0xf9, 0x0c, 0xfc, 0xf7, 0x03, 0xfb, 0x06, 0x02, 0x0d, 0xfd, 0x04,\n",
            "  0xfe, 0xf6, 0xf7, 0x03, 0xfa, 0x00, 0x15, 0xf9, 0x01, 0x02, 0xff, 0x0a,\n",
            "  0x49, 0x16, 0x0f, 0x47, 0xf5, 0xf3, 0xfc, 0xf7, 0xfa, 0x08, 0xf6, 0x06,\n",
            "  0x0a, 0x0c, 0x08, 0xf5, 0xfc, 0x0b, 0x09, 0x04, 0x11, 0x0b, 0x0a, 0xf7,\n",
            "  0x04, 0x04, 0xfa, 0x07, 0xf8, 0xf5, 0xfe, 0x04, 0xf5, 0x00, 0x05, 0x0c,\n",
            "  0x09, 0xf8, 0x0c, 0xf8, 0xfd, 0xff, 0xfc, 0xf6, 0x0a, 0xf9, 0x0a, 0xfd,\n",
            "  0x04, 0xfc, 0xfc, 0xf3, 0xfb, 0xf9, 0xf9, 0xff, 0x5e, 0xfe, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x10, 0x00, 0x00, 0x00, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x40, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x19, 0x00, 0x00, 0x00,\n",
            "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x2f, 0x64,\n",
            "  0x65, 0x6e, 0x73, 0x65, 0x5f, 0x31, 0x2f, 0x4d, 0x61, 0x74, 0x4d, 0x75,\n",
            "  0x6c, 0x00, 0x00, 0x00, 0x54, 0xfe, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x96, 0xfd, 0x99, 0x3c,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0xfa, 0xfe, 0xff, 0xff, 0x04, 0x00, 0x00, 0x00,\n",
            "  0x80, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x8b, 0x10, 0x00, 0x00,\n",
            "  0x39, 0xe7, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x7d, 0x01, 0x00, 0x00, 0xaa, 0x0b, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x04, 0xe1, 0xff, 0xff, 0x9e, 0xeb, 0xff, 0xff, 0x9b, 0xf0, 0xff, 0xff,\n",
            "  0x6d, 0xe0, 0xff, 0xff, 0x0a, 0xe9, 0xff, 0xff, 0x3c, 0x04, 0x00, 0x00,\n",
            "  0x0b, 0xec, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x3b, 0x10, 0x00, 0x00, 0x81, 0x09, 0x00, 0x00,\n",
            "  0x02, 0xf8, 0xff, 0xff, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x4f, 0xfc, 0xff, 0xff,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x6f, 0xe7, 0xff, 0xff,\n",
            "  0x05, 0xf3, 0xff, 0xff, 0x0b, 0x0d, 0x00, 0x00, 0xeb, 0xfe, 0xff, 0xff,\n",
            "  0x52, 0xff, 0xff, 0xff, 0x00, 0x00, 0x00, 0x02, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x03, 0x00, 0x00, 0x00, 0x10, 0x00, 0x00, 0x00, 0x44, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00,\n",
            "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x2f, 0x64,\n",
            "  0x65, 0x6e, 0x73, 0x65, 0x2f, 0x42, 0x69, 0x61, 0x73, 0x41, 0x64, 0x64,\n",
            "  0x2f, 0x52, 0x65, 0x61, 0x64, 0x56, 0x61, 0x72, 0x69, 0x61, 0x62, 0x6c,\n",
            "  0x65, 0x4f, 0x70, 0x2f, 0x72, 0x65, 0x73, 0x6f, 0x75, 0x72, 0x63, 0x65,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x5c, 0xff, 0xff, 0xff, 0x08, 0x00, 0x00, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0xe7, 0x73, 0x5c, 0x39,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x06, 0x00, 0x08, 0x00, 0x04, 0x00, 0x06, 0x00, 0x00, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0xb5, 0x7f, 0x40, 0xf1,\n",
            "  0xd2, 0x1b, 0x7d, 0xf2, 0x2c, 0x35, 0x28, 0x2c, 0x3c, 0x1c, 0x34, 0x96,\n",
            "  0xf3, 0xc9, 0x7b, 0x71, 0x44, 0x9e, 0xa0, 0xd5, 0xc9, 0x40, 0xfa, 0xc7,\n",
            "  0x40, 0x22, 0x71, 0x00, 0x00, 0x00, 0x0e, 0x00, 0x18, 0x00, 0x08, 0x00,\n",
            "  0x07, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x14, 0x00, 0x0e, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x09, 0x10, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x14, 0x00, 0x00, 0x00, 0x38, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0x20, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00, 0x17, 0x00, 0x00, 0x00,\n",
            "  0x73, 0x65, 0x71, 0x75, 0x65, 0x6e, 0x74, 0x69, 0x61, 0x6c, 0x2f, 0x64,\n",
            "  0x65, 0x6e, 0x73, 0x65, 0x2f, 0x4d, 0x61, 0x74, 0x4d, 0x75, 0x6c, 0x00,\n",
            "  0x0c, 0x00, 0x0c, 0x00, 0x00, 0x00, 0x00, 0x00, 0x04, 0x00, 0x08, 0x00,\n",
            "  0x0c, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00, 0x0c, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x3a, 0xf6, 0x7a, 0x3b, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x14, 0x00, 0x18, 0x00,\n",
            "  0x04, 0x00, 0x00, 0x00, 0x08, 0x00, 0x0c, 0x00, 0x10, 0x00, 0x00, 0x00,\n",
            "  0x00, 0x00, 0x14, 0x00, 0x14, 0x00, 0x00, 0x00, 0x14, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x18, 0x00, 0x00, 0x00, 0x30, 0x00, 0x00, 0x00,\n",
            "  0x20, 0x00, 0x00, 0x00, 0x02, 0x00, 0x00, 0x00, 0x01, 0x00, 0x00, 0x00,\n",
            "  0x01, 0x00, 0x00, 0x00, 0x0b, 0x00, 0x00, 0x00, 0x64, 0x65, 0x6e, 0x73,\n",
            "  0x65, 0x5f, 0x69, 0x6e, 0x70, 0x75, 0x74, 0x00, 0x02, 0x00, 0x00, 0x00,\n",
            "  0xff, 0xff, 0xff, 0xff, 0x01, 0x00, 0x00, 0x00, 0xfc, 0xff, 0xff, 0xff,\n",
            "  0x04, 0x00, 0x04, 0x00, 0x04, 0x00, 0x00, 0x00\n",
            "};\n",
            "unsigned int g_model_len = 7400;\n"
          ]
        }
      ]
    }
  ]
}